0	The proceedings contains 130 papers from the Proceedings of the 2003 winter simulation conference. Topics discussed include: spreadsheet simulation; tips for successful practice of simulation; control variate techniques for Monte Carlo simulation; towards simulation-based business process management; applications of simulation models in finance and insurance; non-stationary queue simulation analysis using time series; a meta-theoretic approach to modeling and simulation; and a taxonomy of visualization techniques for simulation in production and logistics.
1	The proceedings contain 73 papers. The special focus in this conference is on Virtual Enterprises. The topics include: Towards establishing trust relationships among organizations in VBES; trust building in collaborative networked organizations supported by communities of practice; measuring collaboration performance in virtual organizations; towards a conceptual model of value systems in collaborative networks; network analysis by the codesnet approach; assessment of collaborative networks structural stability; a decision support framework for collaborative networks; enabling virtual organizations in a technological district; ontology engineering in virtual breeding environments; assessing the value of mediators in collaborative business networks; a computer-assisted VO creation framework; collaboration opportunity finder; an ontology-based approach for selecting performance indicators for partners suggestion; multiple criteria partner selection in virtual enterprises; fundaments of virtual organization e-contracting; agent-based contracting in virtual enterprises; a lawful framework for distributed electronic markets; towards learning collaborative networked organizations; identification of forms and components of VO inheritance; a generic strategic layer for collaborative networks; virtual power producers integration into MASCEM; agent-based architecture for virtual enterprises to support agility; towards an architecture modeling language for networked organizations; business modelling for knowledge networks; an estimation model for business benefits in horizontal collaborative networks; examining the antecedents to innovation in electronic networks of practice; support for power in adaptation of social protocols for professional virtual communities; virtual customer communities; the impact of customer participation on business ecosystems; social network analysis of team dynamics and intraorganizational development in an aerospace firm; the tacit dimensions of collaborative network traffic; collaborative services to maintain electronic business relationships; towards seamless interoperability in collaborative networks; ambient intelligence and simulation in health care virtual scenarios; collaboration within the tool-and-die manufacturing industry through open-source modular ERP/CRM systems; a cartography based methodology for collaborative process definition; interactive user-centered business process management services; workflow technology supporting the operation of virtual ISPs; introducing a collaborative business model for European ERP value chains of SMEs; enhancing enterprise collaboration by using multifaceted services; application of the fusion approach for assisted composition of web services; semantic integration of business applications across collaborative value networks; collaborative environments work; a knowledge search framework for collaborative networks; distributed design of product oriented manufacturing systems; virtual organisation in cross domain engineering; collaboration and adaptation in scheduling; virtual organizations for municipalities; engineering methodology for organisation networks; a procedure for the analysis of industrial networks; the evaluation of coordination policies in logistics services markets and business models for collaborative planning in transportation.
2	The proceedings contain 38 papers. The special focus in this conference is on Electronic Government. The topics include: Government as a launching customer for einvoicing; transformational government citizens’ Services Adoption: A conceptual framework; the eGovernment Services Delivery of the Italian Municipalities; The state of IT governance: Patterns of variation at the central government level in Norway; Information strategies for open government in Europe: EU regions opening up the data on structural funds; market, network, hierarchy: Emerging mechanisms of governance in business process management; computing and information technology challenges for 21st century financial market regulators; eGovernment trends in the web 2.0 era and the open innovation perspective: An exploratory field study; a scenario-based approach towards open collaboration for policy modelling; building theoretical foundations for electronic governance benchmarking; open government data: A stage model; enrolling local strategic actors in public portal development; inter-organizational Cooperation in Swiss eGovernment; scarcity, exit, voice and violence: The state seen through eGovernment; a conceptual model for G2G relationships; coverage of egovernment security issues in mass media; a context-aware inter-organizational collaboration model applied to international trade; KPI-supported PDCA model for innovation policy management in local government; On the relevance of enterprise architecture and IT governance for digital preservation; Interoperability, enterprise architectures, and IT Governance in Government; Connecting eGovernment to Real Government - The Failure of the UN eParticipation Index; exploring information security issues in public sector inter-organizational collaboration; ambiguities in the early stages of public sector enterprise architecture implementation: Outlining complexities of interoperability; integrity of electronic patient records.
3	The proceedings contain 68 papers. The topics discussed include: corporate culture in line with business process orientation and its impact on organizational performance; agent assignment for process management: goal modeling for continuous resource management; measuring the understandability of business process models - are we asking the right questions?; what you see and do is what you get: a human-centric design approach to human-centric process; an exploratory study of IT-enabled collaborative process modeling; business process compliance tracking using key performance indicators; temporal specification of business processes through project planning tools; supporting context-aware process design: learnings from a design science study; mining context-dependent and interactive business process maps using execution patterns; towards robust conformance checking; and run-time auditing for business processes data using constraints.
4	The proceedings contain 13 papers. The special focus in this conference is on Execution, Modeling and Management. The topics include: Resource allocation with dependencies in business process management systems; parent-child relation between process instances; hybrid approach for flexible case modeling and execution; software process performance improvement using data provenance and ontology; estimating the cost for executing business processes in the cloud; identifying variability in process performance indicators; checklist-based inspection technique for business process models; activity matching with human intelligence; process model comparison based on cophenetic distance; unlocking the potential of the process perspective in business transformation; focusing business improvements using process mining based influence analysis; factors affecting the sustained use of process models and a model-driven approach for domain specific process design and monitoring.
5	The proceedings contain 25 papers. The topics discussed include: improving strategic scanning information analysis: an alternative measure for information proximity evaluation; semantic business process representation to enhance the degree of BPM mechanization - an ontology; work level related human factors for enterprise architecture as organisational strategy; an interactive video system for learning and knowledge management; enterprise capability modeling: concepts, method, and application; organisational theory: did it outgrow management theory? a case study of the African oil and gas industry; threats and opportunities for information systems outsourcing; adoption of new technological innovation by SMMEs in South Africa - information accessibility a key to successful technology uptake; business model management system design: manifesto, requirements, and prototype; and KPI evaluation of the business process execution through event monitoring activity.
6	The proceedings contain 398 papers. The topics discussed include: how different types of is assets account for synergy-enabled value in multi-unit firms: mapping of critical success factors and key performance indicators; information systems for sustainability reporting - a state of practice; leading effect of social media for financial fraud disclosure: a text mining based analytics; a framework for disruptive innovation diffusion; and a study on the relation between business process management maturity and innovation.
7	The proceedings contain 43 papers. The special focus in this conference is on Conceptual Modeling, Ontologies, Requirements Engineering, Advanced Conceptual Modeling, Semantic Annotations and Business Process Management. The topics include: Improving the correctness of some database research using ORA-semantics; a conceptual modeling framework for business analytics; translating Bayesian networks into entity relationship models; key performance indicator elicitation and selection through conceptual modelling; an ontological approach for identifying software variants; the role of ontology design patterns in linked data projects; bridging the it and OT worlds using an extensible modeling language; possibilistic cardinality constraints and functional dependencies; exploring views for goal-oriented requirements comprehension; keys with probabilistic intervals; on referring expressions in information systems derived from conceptual modelling; multi-level modeling with most general instances; pragmatic quality assessment for automatically extracted data; achieving system-wide constraint representations; an efficient and simple graph model for scientific article cold start recommendation; keyword queries over the deep web; probabilistic evaluation of process model matching techniques; context-aware workflow execution engine for e contract enactment; annotating and mining for effects of processes; detecting drift from event streams of unpredictable business processes; modeling structured and unstructured processes; an holistic approach for research modeling; comparison and synergy between fact-orientation and relation extraction for domain model generation in regulatory compliance; development of a modeling language for capability driven development; applying conceptual modeling to better understand the human genome and stepwise refinement of software development problem analysis.
8	The proceedings contain 13 papers. The special focus in this conference is on Business Process Management. The topics include: From openness to change to patients’ satisfaction: A business process management approach; process performance measurement system characteristics: An empirically validated framework; quasi-inconsistency in declarative process models; decision support for declarative artifact-centric process models; optimized resource allocations in business process models; predicting critical behaviors in business process executions: When evidence counts; counterfactual reasoning for process optimization using structural causal models; a java-based framework for case management applications; earth movers’ stochastic conformance checking; discovering automatable routines from user interaction logs; preface.
9	The proceedings contain 17 papers. The special focus in this conference is on Perspectives in Business Informatics Research. The topics include: Deriving Key Performance Indicators from Business Process Model; the Unexpected Benefits of Paying for Information: The Effects of Payment on Information Source Choices and Epistemic Thinking; the Snippets Taxonomy in Web Search Engines; model-Driven Context Configuration in Business Process Management Systems: An Approach Based on Knowledge Graphs; can I Help You? – The Acceptance of Intelligent Personal Assistants; understanding the Habits: Inertia in Flipped Classroom; patient Acceptance of Health Cards and Health Insurance Information Systems; comparison of Different Requirements for Digital Workplace Health Promotion; blockchain Awareness Among Computer Science Students: A Preliminary Study; researching Participatory Modeling Sessions: An Experimental Study on the Influence of Evaluation Potential and the Opportunity to Draw Oneself; automated Formal Verification of Model Transformations Using the Invariants Mechanism; multi-criteria Ranking Based on Joint Distributions: A Tool to Support Decision Making; towards Ecosystemic Stance in Finnish Public Sector Enterprise Architecture; data Mining Methodologies in the Banking Domain: A Systematic Literature Review; multi-component Infrastructure for e-Lectures: A Viable Solution for Small and Medium-Sized Organizations.
10	The proceedings contain 36 papers. The topics discussed include: cognitive BPM: business process automation and innovation with artificial intelligence; process mining on event graphs: a framework to extensively support projects; process mining as a strategy of inquiry: understanding design interventions and the development of business processes; visualization of environmental performance indicators (EPI) on business process models: a hospitality industry perspective; the role of culture in business process management adoption; ensemble predictive process mining – taking predictive process mining to the next level; business process sketch recognition; compliance to data protection and purpose control using process mining technique; the design and validation of a process data analytics methodology for improving meat and livestock value chains; the business process management game; and action logger: enabling process mining for robotic process automation.
11	The proceedings contain 34 papers. The topics discussed include: abstracting low-level event data for meaningful process analysis; industry 4.0: business process management maturity model for the digitalized interorganizational value chain; a conceptualization of process mining impacts; a causal approach to prescriptive process monitoring; interactive resolution and prevention of inconsistencies in business rule management; integrating explainable machine learning and predictive process monitoring; hybrid process modeling and mining; representativeness of event data in conformance checking; designing a method for defining and monitoring business model performance indicators; and a resource manager for advanced resource management and allocation in processes.
12	The proceedings contain 23 papers. The special focus in this conference is on Business Process Management. The topics include: Large Language Models for Business Process Management: Opportunities and Challenges; a Reference Data Model to Specify Event Logs for Big Data Pipeline Discovery; the Impact of Leadership on Business Performance. The Role of Process Performance; from Automatic Workaround Detection to Process Improvement: A Case Study; business Process Management Maturity and Process Performance - A Longitudinal Study; conversational Process Modelling: State of the Art, Applications, and Implications in Practice; process Mining and the Transformation of Management Accounting: A Maturity Model for a Holistic Process Performance Measurement System; towards a Theory on Process Automation Effects; zooming in for Clarity: Towards Low-Code Modeling for Activity Data Flow; Resource Allocation in Recommender Systems for Global KPI Improvement; optimizing the Solution Quality of Metaheuristics Through Process Mining Based on Selected Problems from Operations Research; steady State Estimation for Business Process Simulations; adding the Sustainability Dimension in Process Mining Discovery Algorithms Evaluation; trusted Compliance Checking on Blockchain with Commitments: A Model-Driven Approach; preface; declarative Choreographies with Time and Data; Foundations of Collaborative DECLARE; predicting Unseen Process Behavior Based on Context Information from Compliance Constraints; execution Semantics for Process Choreographies with Data; detecting Weasels at Work: A Theory-Driven Behavioural Process Mining Approach; The Dpex-Framework: Towards Full WFMS Support for Decentralized Process Execution.
13	The proceedings contain 24 papers. The special focus in this conference is on AI4BPM, BP-Meet-IoT, BPI, BPM and RD, BPMS2, BPO, DEC2H, and NLP4BPM. The topics include: Declarative Guideline Conformance Checking of Clinical Treatments: A Case Study; improving Declarative Process Mining with a Priori Noise Filtering; text-Aware Predictive Process Monitoring with Contextualized Word Embeddings; PET: An Annotated Dataset for Process Extraction from Natural Language Text Tasks; supporting Event Log Extraction Based on Matching; automated Intelligent Assistance with Explainable Decision Models in Knowledge-Intensive Processes; the Label Ambiguity Problem in Process Prediction; situation-Aware eXplainability for Business Processes Enabled by Complex Events; assessing the Suitability of Traditional Event Log Standards for IoT-Enhanced Event Logs; method to Identify Process Activities by Visualizing Sensor Events; a Holistic Framework for IoT-Aware Business Processes; vAMoS: eVent Abstraction via Motifs Search; preface; Constraints for Process Framing in AI-Augmented BPM; mining for Long-Term Dependencies in Causal Graphs; what Can Database Query Processing Do for Instance-Spanning Constraints?; effects of Concurrency in Complex Service Organizations: Evidence from Electronic Health Records; PYP4Training - Ludifying Business Process Training; on Current Job Market Demands for Process Mining: A Descriptive Analysis of LinkedIn Vacancies; combining Process Mining and Optimization: A Scheduling Application in Healthcare; defining Process Performance Measures in an Object-Centric Context; design-Time Support for Fragment-Based Case Management.
14	The proceedings contain 27 papers. The special focus in this conference is on Business Process Management. The topics include: Inferring Missing Entity Identifiers from Context Using Event Knowledge Graphs; process Channels: A New Layer for Process Enactment Based on Blockchain State Channels; action-Evolution Petri Nets: A Framework for Modeling and Solving Dynamic Task Assignment Problems; context-Based Activity Label-Splitting; verifying Resource Compliance Requirements from Natural Language Text over Event Logs; from Text to Performance Measurement: Automatically Computing Process Performance Using Textual Descriptions and Event Logs; agent Miner: An Algorithm for Discovering Agent Systems from Event Data; interactive Multi-interest Process Pattern Discovery; Increasing RPA Adoption: An Experiment on Countermeasures for Status Quo Bias; can I Trust My Simulation Model? Measuring the Quality of Business Process Simulation Models; stochastic-Aware Comparative Process Mining in Healthcare; on the Cognitive Effects of Abstraction and Fragmentation in Modularized Process Models; not Here, But There: Human Resource Allocation Patterns; a Novel Multi-perspective Trace Clustering Technique for IoT-Enhanced Processes: A Case Study in Smart Manufacturing; the Impact of Process Complexity on Process Performance: A Study Using Event Log Data; Deviation from Standards and Performance in Knowledge-Intensive Processes: Evidence from the Process of Selling Customized IT Solutions; benevolent Business Processes - Design Guidelines Beyond Transactional Value; PEM4PPM: A Cognitive Perspective on the Process of Process Mining; event Abstraction for Partial Order Patterns; incremental Discovery of Process Models Using Trace Fragments; approximating Multi-perspective Trace Alignment Using Trace Encodings; POWL: Partially Ordered Workflow Language; polynomial-Time Conformance Checking for Process Trees; investigating the Influence of Data-Aware Process States on Activity Probabilities in Simulation Models: Does Accuracy Improve?; dyLoPro: Profiling the Dynamics of Event Logs.
15	nan
16	nan
17	nan
18	Mr TAN is a Strategic Services Consultant specializing in Business-IT Planning, Programme & Project Management (PPM) and PMO/Business-IT process automation (BPM). A First Class degree holder from Imperial College, UK, he has more than 30 years of consulting experience, helping MNC clients in Business-IT Strategy Formulation and Implementation, Business Process Re-engineering, Change Management, PPM-based Performance Management and, e-Commerce Strategy and Implementation. He was previously the Vice President, Technology of Citibank N.A. Singapore. As Managing Partner of Andersen Worldwide for Mauritius and East Africa, Mr TAN had successfully built, nurtured and transformed a 35-person team into 160-person strong consulting and system implementation outfit over a 18-month period with over 100m backlog and recurring fees. Mr TAN is a passionate PPM consultant who sets up PMO for his clients and trains and mentors their PMs, benchmarks & QAs their PPM processes, and helps them to institutionalize their PPM practices via KPI-centric PPM/PMO automation to achieve integrated, near real-time PPM monitoring and controlling.
19	Purpose: Multidisciplinary business process management (BPM) research can reap significant impact. We can particularly benefit from incorporating accounting concepts to address some of the key BPM challenges, such as value-creation and return on investment of BPM activities. However, research which addresses a relationship between BPM and accounting is scarce. The purpose of this paper is to provide a detailed synthesis of the current literature that has integrated accounting aspects with BPM. The authors profile and thematically describe existing research, and derive evidence-based directions to guide future research. Design/methodology/approach: A multi-staged structured literature review approach to search for the two broad themes, accounting and BPM, supported by NVivo (to manage the papers and the coding and analysis processes) was designed and followed. Findings: The paper confirms the dearth of work that ties the two disciplines, despite the synergetic multidisciplinary results that can be attained. Available literature is mostly from the management accounting perspective and relates to describing how performance management, in particular performance measurement, can be applicable to process improvement initiatives together with tools such as activity-based costing and the balanced scorecard. There is a lack of research that examines BPM in relation to any financial accounting perspectives (such as external reporting). Future research directions are proposed together with implications for practitioners with the findings of this structured literature review. Research limitations/implications: The paper provides a detailed synthesis of the existing literature on the nexus between accounting and BPM. It summarizes the implications for practitioners and provides directions for future research by identifying key gaps and opportunities with a sound contextual basis for extension and new work. Originality/value: Effective literature reviews create strong foundations for future research and accumulate the otherwise scattered knowledge into a single place. This is the first structured literature review that provides a detailed synthesis of the research that ties together the accounting and BPM disciplines, providing a basis for future research directions together with implications for practitioners. © 2018, Emerald Publishing Limited.
20	With the proliferation of business process reforms in organizations, the need for process-centric performance measurement systems is discussed in several studies. However, although there is considerable research on Performance Measurement Systems (PMSs) in general business contexts, research on performance measurement in process-centric contexts (e.g. within the BPM field) is scarce, and the characteristics of such process performance measurement systems (PPMSs) still remain poorly conceptualized, hindering their design and implementation. PPMSs are different from traditional performance measurement systems as the data gathered, and the information generated and disseminated are focused on processes, rather than on functions. This paper presents a PPMS characteristics framework, resulting from a multi-staged study design. Initially 38 PPMS characteristics were identified through a structured literature review which were then re-specified and confirmed with two in-depth case studies. The study findings resulted in an empirically supported PPMS characteristics framework, consisting of 30 PPMS characteristics grouped within 7 core themes, namely; (1) Quality characteristics; (2) Measurement Scope; (3) Contextual features considered in designing PPMS; (4) Relationship to organizational systems and structures; (5) Efficiency of information gathering and use; (6) Feedback and reporting; and (7) Potential uses of feedback generated. This is the first evidence-based synthesis of PPMSs characteristics and it provides a clear conceptualization and an understanding of what aspects a PPMS should comprise. The resulting framework will assist practitioners in designing and redesigning measurement systems in process centric contexts, which could in turn better support processes such as identifying improvement needs, measuring improved processes, benchmarking and controlling the processes, process maturity assessments, and benefits realization. The findings will also facilitate future research on PPMSs. © Springer Nature Switzerland AG 2019.
21	The business process reengineering is causing a wave of restructuring and reorganization of companies that largely rely on computer engineering and the potential of information and communications technology. Most reengineering researchers argue that information and communications technology (ICT) have the capacity, through their intrinsic qualities, to change the organization; this is more to computerize the existing but to redefine the work organization and sequencing of tasks and rethink the process. In this research, we present a case study of reengineering of a platform of cross docking (PCD) using the Supply Chain Operation Reference Model (SCOR) in a car assembly unit. This paper tends to dismantle the relationship between information technology (IT) and process reengineering, also, the success of integration of ICT such as EDI (Electronic Data Interchange), RFID (Radio Frequency Identification) as an approach to achieve the level of performance expected by the logistics chain studied. After presenting the different readings about the process reengineering and the impact of ICT on the performance, we will model the PCD processes by using SCOR and BPMN 2.0. The purpose of this modelling is to understand at first the functioning of the platforms of cross docking and the interactions between the upstream processes and the downstream of his customers and his suppliers. In the second stage, this modelling allowed to detect the weaknesses in the processes, further to a lack of traceability in the piloting of the internal flows. We proposed the integration of the technology RFID for landing in these weaknesses. We feigned several scenarios before and after the integration of the RFID to validate our hypotheses on the relevance of the solution RFID.
22	Abstract The aim of business process compliance (BPC) is to ensure that business processes are executed in accordance with a prescribed set of rules. In practice, the evidence would suggest that achieving this goal is challenging. Penalties and subsequent remediation costs in the Australian banking industry amounted to over A$10bn between 2017 and 2022. The research community has identified many challenges, but the industry perspective is typically missing from that research. The study takes advantage of recent events in the Australian banking industry that saw detailed regulatory reports made public, highlighting the challenges the industry faces trying to maintain compliance. The study supplements these reports with BPC-related insights from practitioners and consultancy groups to develop an industry perspective on the challenges. Consolidating the two perspectives presents a comprehensive view of BPC’s challenges and the differing emphasis that each stakeholder group places on the challenges. Process mining may provide a pathway to reconciling these different perspectives. Both the BPC literature and industry have promoted process mining’s potential to address the challenges. To explore this proposition, the study details the features of representative commercial process mining software and then maps these features to the challenges. The resultant conceptual map is used to analyze known and novel BPC challenges. It outlines the limitations that must be addressed, from both a research and industry perspective, to maintain and improve compliance.
23	In the past few decades, the recognition and adoption of Business Process Management (BPM) has increased at a phenomenal pace. Organizations are increasingly devoting resources towards development and use of BPM techniques and technologies to model, analyze, improve and implement business processes. However, the existing procedures for collecting information to create business process models generally lead to misunderstanding or ambiguity between model and domain experts. We propose a framework to automate collection of such information and build models directly from users' inputs captured through interactive web-forms. The framework also allows users to align processes with strategic business objectives, critical success factors, key performance indicators and functions. Further, processes can be tagged with appropriate maturity level, types and tiers. A dashboard then provides real-time reports which help decision makers to monitor organization's performance, make better decisions, and standardize/optimize processes across the organization. © 2019 IEEE.
24	nan
25	Information is one of the most important factors in business success, hence the importance of the Business Intelligence (BI) domain in order to simplify the decision making and make it more relevant. Decisional systems have been used for several years to help decision-makers access, analyze and extract value from the data that their organisation accumulated through the years. The success gained by these types of systems caused the establishment of a well-known architecture and development chain, and the proliferation of tools and methodologies that have proven their value. Nonetheless, in some use cases, the classical decisional architecture shows some shortcomings. In fact, the traditional storage and processing models in Business Intelligence systems are not sufficient anymore when confronted with data that becomes more and more massive, varied and with a high velocity. This is where Big Data solutions can be of great use. In fact, these solutions have proven their efficiency when dealing with enormous constantly increasing amounts of data with a changing schema. Our goal in this article is to show the various manners to integrate big data solutions into the decisional world, and to help architects choose which architecture corresponds better to their needs, by taking into consideration the environmental, technical and functional constraints they are faced with.
26	Process modeling is an important and delicate step, and it is among reasons that cause failure in the implementation or the improvement of any type of system. Indeed, process modeling is based on the inter-relationship between the processes that make up the system. There are various standards of process modeling; each one presents several aspects and concepts in relation with the process. While taking into account the specific characteristics of each case of modeling, this diversity makes the choice of the model very complicated. In this paper, we use the concepts of the MDE approach to create our process meta model extended for cycles. We generate this meta model out of several transformations of the Process Structure View meta model extended for lifecycles and the concept view meta model, using the Seven Views approach. The meta model proposed will facilitate the task to the process managers in terms of collecting requirements; proposals and solutions of improvement, through a repository containing all the information collected at the theoretical modeling, and updated during each cycle. The objective of this paper is to propose a generic process meta model, extended for cycles, that considers the requirements dimension, using Seven Views approach. This meta model will be valid for all type of information systems and for all type of cycles (lifecycles and improvement cycles).
27	It is increasingly important that Service Level Agreements (SLAs) are taken into account when business processes are exposed as services in a Service Oriented Architecture. SLAs define expected service behavior and nonfunctional properties of the service. The fact that the service provider has to offer certain guarantees concerning SLA properties has an impact on the business process lifecycle. In this paper we introduce a stepwise approach for management of SLA-Aware service compositions based on process performance requirements specified as Key Performance Indicators. The approach is based on the process lifecycle known from Business Process Management and comprises a modeling, configuration and execution phase. We incorporate existing work on SLA modeling, QoS aggregation, and QoSbased service selection, and identify several problems specific to SLA-Aware business processes. © 2012 Newswood Limited. All rights reserved.
28	Reservoir management guidelines are an enabler of, production sustainability, assurance to reservoir health and high ultimate recovery. Monitoring the compliance of the field production against the set of reservoir management guidelines is one of the key processes for ADNOC, being a governing body of major U.A.E. hydrocarbon producing fields. With the business need to ramp up production, field maturation, and the associated operational challenges, it is critical for ADNOC to effectively monitor and regulate its field production plans to assure the long-term production sustainability. In this regard, ADNOC has developed a robust framework that is implemented through an automated analytics platform that enables different ADNOC technical teams to effectively monitor and report the compliance status of each hydrocarbon barrel from produced from ADNOC assets. The paper highlights the features of the workflow implemented, the management of change strategy and the business value created. The automated process allows the consolidation of a variety of well, reservoir and field-level data. The analytical platform enables integrated analysis, KPI calculation and interactive visualization. The framework assesses the compliance based on three governing parameters: well technical rate, gas-oil ratio (GOR), and bottom hole flowing pressure. The compliance analysis is carried out on a monthly basis where the monthly back allocated production data for each well is compared with the set of operating guidelines in an automated data analytics and visualization environment. A pragmatic compliance tolerance is considered in the calculations to accommodate the measurement inaccuracies, as well as the operational limitations while allowing flexibility to exclude nonconformity with valid reasons. The overall process is governed through an automated business process management (BPM) platform, which seamlessly regulates the predefined subroutines among different stakeholders to report and track different corrective actions in a timely manner. The framework implementation has strengthened the overall compliance governance process; and has been instrumental to properly manage asset production capacity in a systematic manner. This has subsequently enabled the preparation of a prompt action plan and has improved the operating efficiency of more than 3% within the first six months of implementation, through restoring, compensating and increasing the effective capacity of overall ADNOC Production. The approach has demonstrated great value both in terms of process alignment, as well as from the production assurance standpoint at a country level, and allows the organization to have an established system, which provides: • Consistent compliance monitoring standards • Minimal subjectivity • Complete process governance • Quick turnaround time • Auditable history The aim of this paper is to publish a stepwise guide for any operators who might be interested to adopt and implement a similar approach to assure the long-term production sustainability and health of their assets. © 2019, Society of Petroleum Engineers
29	This paper demonstrates a successful case story of how harnessing digitalization has significantly improved the Management of Inactive wells. An integrated web-based application was developed in house and fully deployed across the Company. It has demonstrated an immense added value by bringing key stakeholders in an automated and collaborative environment to standardize and improve the existing well reactivation cycle and mitigating well & facilities integrity threats. Inactive Strings Management System (ISMS) is tailored made for multiple disciplines such as production, petroleum, well integrity, facilities and reservoir engineers, as well as Corporate Units and Management, all connected through standards automated workflows. The new solution is composed by 13 main modules that covers the whole well reactivation cycle: a) Data Entry b)Validation, c) Endorsement, d) Live Well Inventory, e) Tracking and Monitoring, f) Well Problem & Status, g) Dashboards, h) Well history, i) Well Prioritization, j) Manager Approval, and k) Level 2 KPI's. 1) Managing Problematics Wells, and m) Project Related. The Inactive String Management Tool has proved to be vastly beneficial. Since its implementation in December 2021, it has successfully supported the reactivation of around 810 strings, and monitoring over 4800 operating strings, with an associated cumulative oil rate gain of 490,000 barrels, translated into a profit of around $23 MM (USD), and shortened the well reactivation cycle by 20%. The solution had led to major improvements on the current business and system processes by addressing major challenges including data integrity issues, lack of automation, systems integration, poor tracking of well reactivation actions, and most importantly, absence of a systematic approach to prompt multidisciplinary well revision by having a unique planform to manage the inactive strings, thru standardization of best practices and lessons learned across Assets. It has increased the well problem visibility and accountability of key stakeholders to firm, maturate and accelerate well reactivation actions in an automated and collaborative environment, reducing silos, ensuring alignment, sharing knowledge and information more effectively. Improved resources planning and production gain without jeopardizing well and facilities integrity. This solution is part of the Oil and Gas 4.0 company digital transformation strategy, encourages collaboration across departments, fostering a digital culture to rapidly react to business changes. It has laid down the foundation to sustain growth and a competitive edge in the digital age by applying deeper and more targeted analytics that enable better business decision-making, such as predictive analytics, artificial intelligence, and business process management. Copyright © 2022, Society of Petroleum Engineers.
30	Abstract Research and development are central to economic growth, and a key challenge for countries of the global South is that their research performance lags behind that of the global North. Yet, among Southern researchers, a few significantly outperform their peers and can be styled research “positive deviants” (PDs). In this paper we ask: who are those PDs, what are their characteristics and how are they able to overcome some of the challenges facing researchers in the global South? We examined a sample of 203 information systems researchers in Egypt who were classified into PDs and non-PDs (NPDs) through an analysis of their publication and citation data. Based on six citation metrics, we were able to identify and group 26 PDs. We then analysed their attributes, attitudes, practices, and publications using a mixed-methods approach involving interviews, a survey and analysis of publication-related datasets. Two predictive models were developed using partial least squares regression; the first predicted if a researcher is a PD or not using individual-level predictors and the second predicted if a paper is a paper of a PD or not using publication-level predictors. PDs represented 13% of the researchers but produced about half of all publications, and had almost double the citations of the overall NPD group. At the individual level, there were significant differences between both groups with regard to research collaborations, capacity development, and research directions. At the publication level, there were differences relating to the topics pursued, publication outlets targeted, and paper features such as length of abstract and number of authors.
31	Existent solutions for work process automation in companies were analyzed. Problem-solving techniques of internal document management were suggested to improve the efficiency of team-work.
32	Process Model Matching (PMM) refers to the automatic identification of corresponding activities between a pair of process models. Recognizing the pivotal role of PMM in numerous application areas a plethora of matching techniques have been developed. To evaluate the effectiveness of these techniques, researchers typically use PMMC’15 datasets and three well-established performance measures, precision, recall and F1 score. The performance scores of these measures are useful for a surface level evaluation of a matching technique. However, these overall scores do not provide essential insights about the capabilities of a matching technique. To that end, we enhance the PMMC’15 datasets by classifying corresponding pairs into three types and compute performance scores of each type, separately. We contend that the performance scores for each type of corresponding pairs, together with the surface level performance scores, provide valuable insights about the capabilities of a matching technique. As a second contribution, we use the enhanced datasets for a comprehensive evaluation of three prominent semantic similarity measures. Thirdly, we use the enhanced datasets for a comprehensive evaluation of the results of twelve matching systems from the PMM Contest 2015. From the results, we conclude that there is a need for developing the next generation of matching techniques that are equally effective for the three types of pairs. © Springer Nature Switzerland AG 2018.
33	Process Model Matching (PMM) aims to automatically identify corresponding activities from two process models that exhibit similar behaviors. Recognizing the diverse applications of process model matching, several techniques have been proposed in the literature. Typically, the effectiveness of these matching techniques has been evaluated using three widely used performance measures, Precision, Recall, and F1 score. In this study, we have established that the values of these three measures for each dataset do not provide deeper insights into the capabilities of the matching techniques. To that end, we have made three significant contributions. Firstly, we have enhanced four benchmark datasets by classifying their corresponding activities into three sub-types. The enhanced datasets can be used for surface-level evaluation, as well as a deeper evaluation of matching techniques. Secondly, we have conducted a systematic search of the literature to identify an extensive set of 27 matching techniques and subsequently proposed a taxonomy for these matching techniques. Finally, we have performed 432 experiments to evaluate the effectiveness of all the matching techniques, and key observations about the effectiveness of the techniques are presented. © 2013 IEEE.
34	Abstract Reducing waiting times in end-to-end business processes is a recurrent concern in the field of business process management. The uptake of data-driven approaches in this field in the past two decades, most notably process mining, has created new opportunities for fine-grained analysis of waiting times based on execution data. As a result, a wide range of approaches for waiting time identification and analysis on the basis of business process execution data have been reported in the literature. In many instances, different approaches have considered different notions of waiting time and different causes for waiting time. At present, there is a lack of a consolidated overview of these manifold approaches, and how they relate to or complement each other. The article presents a literature review that starts with the question of what approaches for identification and analysis of waiting time are available in the literature, and then refines this question by adding questions which shed light onto different causes and notions of waiting time. The survey leads to a multidimensional taxonomy of data-driven waiting time analysis techniques, in terms of purpose, causes, and measures. The survey identifies gaps in the field, chiefly a scarcity of integrated multi-causal approaches to analyze waiting times in business processes, and a lack of empirically validated approaches in the field.
35	Recently, robotic process automation (RPA) has become increasingly adopted by different institutions in an endeavour to improve business performance. However, banking and financial institutions are still considered a slow-developing sector lacking sufficient experience with different aspects of process automation. Therefore, the main aim of this work is to examine how RPA adoption can affect the performance of banking processes by conducting a case study on the mortgage loan application process of a bank located in Saudi Arabia. A well-established methodology inspired by the business process management (BPM) lifecycle has been followed. We utilise the Bizagi (BPM) Suite to model and analyse AS-IS and TO-BE scenarios of the process. UiPath software has been used to build and configure the RPA bot. The simulation results revealed that the adoption of the RPA within the mortgage loan application process has reduced the overall cycle time of the process by approximately 14 days. Copyright © 2021 Inderscience Enterprises Ltd.
36	In this paper we consider a business case of an Enterprise Resource Planning (ERP) system vendor who needs to introduce qualitative features without making great investments in the legacy source code. We propose to extend legacy ERP system’s functionality by applying the Leading System paradigm so that business process management can be introduced. This enables business process awareness and provides opportunity for qualitative feature set introduction in a legacy ERP system. As a result, Key Performance Indicator (KPI) acquisition, modeling and analysis from the process aware legacy ERP system becomes possible. The main focus in this paper is on lessons learned about a suitable prototype architecture for KPI acquisition, modeling and analysis, and about best practices for KPI analysis from log data of business process execution. © Springer International Publishing Switzerland 2015.
37	This paper presents a novel taxonomy of the critical success factors in enterprise resource planning (ERP) implementation process. ERP benefits cannot be fully realised unless a strong alignment and reconciliation mechanism is established between technical and organisational imperatives based on the principles of process orientation. It is suggested in the taxonomy that measurement takes place in a balanced perspective, and for the purpose of providing useful information that can enable the decision making process and, which can help deliver the corporate objectives and therefore lead the business competitively forward. Upon this premise, the taxonomy is based on a comprehensive analysis of ERP literature combining research studies and organisational experiences. The taxonomy reflects the essential features of ERP systems, as being built based on the principles of business process management. Furthermore, it illustrates that ERP benefits are realised when a tight link is established between implementation approach and business process performance measures. © 2002 Elsevier Science B.V. All rights reserved.
38	Semantic Business Process Management (SBPM) has been proposed as an extension of BPM with Semantic Web and Semantic Web Services (SWS) technologies in order to increase and enhance the level of automation that can be achieved within the BPM life-cycle. In a nutshell, SBPM is based on the extensive and exhaustive conceptualization of the BPM domain so as to support reasoning during business processes modelling, composition, execution, and analysis, leading to important enhancements throughout the life-cycle of business processes. An important step of the BPM life-cycle is the analysis of the processes deployed in companies. This analysis provides feedback about how these processes are actually being executed (like common control-flow paths, performance measures, detection of bottlenecks, alert to approaching deadlines, auditing, etc). The use of semantic information can lead to dramatic enhancements in the state-of-the-art in analysis techniques. In this paper we present an outlook on the opportunities and challenges on semantic business process mining and monitoring, thus paving the way for the implementation of the next generation of BPM analysis tools. © Springer-Verlag Berlin Heidelberg 2007.
39	Abstract Process mining, a family of techniques for analyzing large amounts of data collected on business processes, has gained significant practical and academic importance. Extant process mining research mainly examines technical aspects. Only recently has research started to investigate organizational aspects of process mining, such as how organizations use process mining to create business value. On an individual level, research has examined the analysis strategies of individual process mining analysts. So far, however, the literature does not provide a holistic investigation of individual process mining use, including individuals’ behavior, cognition, and affective states. Yet, understanding individual process mining use is pivotal for realizing its organizational value. To address this shortcoming, this paper examines the individual use of process mining employing a multiple case study with process mining users from six large organizations in a post-adoption context, i.e., in organizations that have several years of experience with process mining. Based on the configuration of how process mining users act, think, and feel in practice, four distinct process mining user categories were identified: (1) process mining influencers, (2) power users, (3) process participants, and (4) strategic users. For practitioners, the findings provide insights into the actual process mining use of individuals and what shapes their use patterns. This information enables tailoring process mining training and algorithms to specific user categories.
40	Purpose: The purpose of this study is to highlight how the digitalization of a public university through a structured Business Process Management (BPM) approach allows for a significant performance improvement, even in a bureaucratized context not inclined to process thinking. Design/methodology/approach: The used research methodology centers on a single case study conducted at an Italian public university. The selected process has been examined and redesigned within the BPM lifecycle framework. The AS-IS and TO-BE state, i.e. before and after the organizational change, have been modeled according to BPMN2.0 notation and evaluated through quantitative and qualitative techniques. Findings: The authors first carried out a literature review to identify pertinent performance indicators suitable for assessing a BPM project within a public organization. Secondarily, applying the BPM framework to the case study enabled significant improvements in the quality of the process. Third, the authors analyzed the impact on people and the organization and how to soothe the transition to a digitalized process. Originality/value: The study’s findings can contribute to the existing body of knowledge on BPM as a digitalization approach in the public sector. The case study is the first of its kind in the higher education context. Its value also resides in highlighting the efficacy of using BPM as a guiding tool for making organizational and technical decisions during the implementation phase within the specific context of this paper. © 2024, Emerald Publishing Limited.
41	The selection and the use of performance measurement have received considerable interest in recent years. In addition, it is crucial not only to track the process behavior and to derive the key performance indicators but also to understand all necessary concepts involved in the BP and incorporate domain knowledge of the field. The improvement of business processes is based on comprehensive measurement, data understanding, task design, and relevant result interpretation of organization's performance. In this context, in order to make relevant decisions and to provide a consistent understanding of the field, we present a new ontology based on a real business process to create semantic relationships between all terms. After that, we were based on data mining technique to extract the most important information from data measurement. An example of implementation of our proposed contribution as well as its validation on a real case study in the healthcare domain is presented. © 2017 IEEE.
42	The main goal of our study is the ordering of performance criteria and the evaluations of the performance of an Emergency Department (ED). More precisely, this paper deals with the problem of decision-making in the selection of the most important KPIs that have significant contribution when many conflicting criteria exist using the Analytic Hierarchy Process (AHP) method. The application of AHP method in solving multiple criteria decision making is illustrated by our concrete case of the emergency department in Farhat Hached hospital, using Expert Choice (EC) software, which is based on the AHP method. The finally obtained results were analyzed.
43	Organizations need to continually improve and review their critical business processes. In addition, it is crucial not only to track the business process (BP) behavior and to derive key performance indicators (KPIs) but also to understand all necessary concepts and incorporate domain knowledge of the field. The purpose of this paper is to gain a deeper understanding of the interrelationships between all concepts and performance measurement raw data to extract their real meaning. In order to meet these challenges, first, we explore several qualitative and quantitative indicators for measuring the performance of BPs. Second, we develop a new ontology for the representation of these performance indicators. Then, we are based on data mining techniques to extract the most important information from data measurement and to discover all necessary relationships between indicators.
44	Supply chains are vulnerable to an array of exogenous disruptions, including operational contingencies, natural disasters, terrorism, and political and geopolitical instability. In order to ensure resilience to these disruptions, supply chains can use mitigation strategies to minimize risk and maximize recovery. Modeling approaches can be utilized to determine the most appropriate mitigation strategies for a specific scenario; however, there is currently no recognized modeling framework which can be applied to all supply chain sectors. This paper describes the key disruption risks to supply chains; the resilience and optimization strategies and performance metrics employed by supply chains to mitigate these risks; and the applications of simulation modeling in supply chain management. We present a hybrid framework for using agent-based modeling, alongside early warning systems, many objective optimization and option awareness analysis, to manage exogenous risks for a non-specific supply chain.
45	Liquefied Natural Gas (LNG) industry is a typical example for which various business models, strategies, and affiliated interests exist, making it highly complex in terms of operations. The extended supply chain, from liquefaction to regasification, combined with multilateral contractual relationships that crossover, make efficient operation a challenging task. Considering barriers such as the volume of transactions, communication hurdles, etc., and the lack of contemporary management tools by shipping companies contrary to other industries, the paper proposes a model structure based on Business Process Modelling (BPM). The proposed BPM concept offers a holistic view of company organization and operations, as well as enables control of key performance indicators. Implementing intelligent computer systems to model an inter-organizational business environment to highlight and overcome such problems, is the ultimate goal of the study. This paper offers a coherent perspective of business process visualization across the midstream section of the LNG supply chain, including roles, tasks and resources. The research highlights commonly used business models, the contractual framework, and the physical processes. The volume of the information leads to knuckle points and dysfunctions related to time, transparency and work assignment. It is underlined that the occurring issues relate to the nature of LNG projects, business policies, safety and compliance issues, document transaction load and mishandling, disputes over SPAs, as well as to subjects of goodwill and partnership, unstandardized procedures executed empirically, and concurring office intervention. The aim of the study is the identification of the aforementioned problems that prevent an LNG shipping company from extracting the added value from its operation. Copyright © 2020 Society of Naval Architects and Marine Engineers (SNAME)
46	The sports industry continues to show a drastic increase in its influence around the world. When mentioned, the first sector of the industry that comes to mind is the entertainment industry, with multiple million-dollar deals globally. However, the recreational sector is also growing at a significant rate, which means SMEs in this industry should try to follow this trend. This research focuses on the application of three tools that optimizes the circuit assembly time, increasing the productivity of a recreational center by allowing to expand the number of available shifts for the customers. The model presents the use of standard work as a measure to create patterns in the set-up process, 5s for the redistribution of the sporting materials, and systematic layout planning for the accommodation of the circuits and boxes. The validation method used was Arena Software and resulted in an increase of 10.82% of the productivity indicator, providing an effective service management model to be replicated in other companies. Furthermore, an economic and financial evaluation was carried through, as a validation method for the expansion of the number of available shifts, where the NPV for the proposed model resulted in USD 87,107, meanwhile the IRR achieved was 70%, and a cost-benefit indicator of 1.726.
47	Healthcare organizations are increasingly pushed to improve the quality of care service taking into account the increasing complexity in patient treatment and the continuous reduction of available resources. The adoption of Business Process Management (BPM) practices is thus becoming a key enabler for the improvement of healthcare processes (HPs). Accordingly, methods and tools are required to address behavioral and performance aspects from the early phases of the process lifecycle in order to improve the quality of healthcare, reduce costly reworks and increase the effectiveness of BPM approaches. This paper specifically addresses the specification and analysis phases of the process lifecycle and introduces a model-driven method for healthcare process simulation. The proposed method is based on a model transformation approach that takes as input the process specification in BPMN, appropriately extended to include the performance properties of the process, and yields as output the corresponding process simulation code, ready to be executed. In order to illustrate the method and its effectiveness, the paper describes an example application to a process dealing with the hip fracture for elderly patients.
48	nan
49	A growing number of business process management software vendors are offering simulation capabilities to extend their modeling functions and enhance their analytical proficiencies. Simulation is promoted to enable examination and testing of decisions prior to actually making them in the "real" environment. In this paper, we illustrate how to optimize simulation models, by presenting two examples of simulation optimization using OptQuest®. In the first case, we construct a discrete event simulation model of a hospital emergency room to determine a configuration of resources that results in the shortest average cycle time for patients. In the second case, we develop a simulation model to minimize staffing levels for personal claims processing in an insurance company. We then summarize some of the most relevant approaches that have been developed for the purpose of optimizing simulated systems and conclude with a metaheuristic black box approach that leads the field of practical applications.
50	Abstract In recent years, significant disruptive events have stressed the global business environment and supply chains worldwide, and these events have become more disturbing and frequent. Consequently, organisations have been facing many troubles in different echelons of their supply chains, such as high inventory stockouts or unplanned supply and recovery costs, significantly affecting their performance and stability. Accordingly, strategists must acknowledge enterprise and supply chain resilience as a vital competence in organisational strategies and ploys to guide decision-makers when dealing with disruptive events. This work aims to help organisations develop a powerful approach for testing and improving a decision-making process to minimise stockouts, through a simulation game that considers essential supply chain components, such as suppliers, products, and disruptive events, coexisting in a dynamic system. Upon implementing the proposed game within an organisation, the main expected outcomes include: (i) enhanced decision-making capabilities; (ii) increased awareness and preparedness to address disruptive events; (iii) improved practical understanding of resilient supply chain management practices; (iv) cost-effective training and awareness-building; and (v) repetitive learning opportunities, thereby enhancing supply chain management and resilience. The game’s simplicity is crucial to ensure that this tool remains accessible and practical for its intended audience, as excessive complexity may potentially discourage its use.
51	SMEs in the textile sector face many problems in their production flows, mainly due to the lack of production management systems caused by poor management of the production chain. Therefore, a diagnostic analysis is carried out in a textile SME to evaluate and define the deficiencies and factors that affect its competitiveness, which began with the analysis of the current situation of the company, where it was established the existence of poor-quality management, high waiting times and lack of procedures. Therefore, the use of lean manufacturing tools such as Jidoka, Single Minute Exchange of Die with respect to the production line and process management for the measurement and control of operations in the production area is proposed. The incorporation of these tools in block allows to decrease the rates of defective products, the excess of operative work and the set-up of the machines for the change of model. The main result of the research was that production increased to 0.091 und/PEN.
52	This work contributes to the results of the TEKNE projec, a project aimed at developing a framework for Business Process Management (BPM), supporting the designer with a set of performance indicators. The indicators drive the designer in estimating if the process comply to the objectives and when necessary enable re-engineering of the process. In particular this paper discuses how to derive performance indicators directly from requirements expressed in a Business Rules (BR) format. © 2008 Springer-Verlag Berlin Heidelberg.
53	This paper is intended to provide a critical literature review on supply chain performance measurement. The study aims at revealing the basic research methodologies/approaches followed, problem areas and requirements for the performance management of the new supply chain era. The review study covers articles coming from major journals related with the topic, including a taxonomy study and detailed investigation as to the methodologies, approaches and findings of these works. The methodology followed during the conduct of this research includes starting with a broad base of articles lying at the intersection of supply chain, information technology (IT), performance measurement and business process management topics and then screening the list to have a focus on supply chain performance measurement. Findings reveal that performance measurement in the new supply era is still an open area of research. Further need of research is identified regarding framework development, empirical cross-industry research and adoption of performance measurement systems for the requirements of the new era, to include the development of partnership, collaboration, agility, flexibility, information productivity and business excellence metrics. The contribution of this study lies in the taxonomy study, detailed description and treatment of methodologies followed and in shedding light on future research. © 2010 Taylor & Francis.
54	Abstract Manual exploratory literature reviews should be a thing of the past, as technology and development of machine learning methods have matured. The learning curve for using machine learning methods is rapidly declining, enabling new possibilities for all researchers. A framework is presented on how to use topic modelling on a large collection of papers for an exploratory literature review and how that can be used for a full literature review. The aim of the paper is to enable the use of topic modelling for researchers by presenting a step-by-step framework on a case and sharing a code template. The framework consists of three steps; pre-processing, topic modelling, and post-processing, where the topic model Latent Dirichlet Allocation is used. The framework enables huge amounts of papers to be reviewed in a transparent, reliable, faster, and reproducible way.
55	The BPM-SOA combination is being advocated as the best approach for enterprises to reach the desired business agility and responsiveness to changing business requirements as it brings the service-based business processes employing loosely-coupled services. However, in order to have a certain business, the behavior and non-functional properties of these services such as response time, throughput and availability should be guaranteed and this can be specified by Service Level Agreements (SLAs). In this regard, our work expresses SLAs for the enterprise domain in a machine understandable format. we propose an ontology-based representation model of SLA and utilize the business services performance requirements specified as Key Indicators (KPIs and KQIs) to define SLA parameters. The purpose is to make it possible to monitor business processes based on SLA in order to assure compliance with business requirements and targeted objectives. In general, this model can help automate the process of SLA representation, monitoring and taking actions in case of violations in SOA and business process domains. At the end, an SLA monitoring prototype system is proposed to show how our model can be deployed. © 2012 IEEE.
56	The analysis of clinical pathways from event logs provides new insights about care processes. In this paper, we propose a new methodology to automatically perform simulation analysis of patients' clinical pathways based on a national hospital database. Process mining is used to build highly representative causal nets, which are then converted to state charts in order to be executed. A joint multi-agent discrete-event simulation approach is used to implement models. A practical case study on patients having cardiovascular diseases and eligible to receive an implantable defibrillator is provided. A design of experiments has been proposed to study the impact of medical decisions, such as implanting or not a defibrillator, on the relapse rate, the death rate and the cost. This approach has proven to be an innovative way to extract knowledge from an existing hospital database through simulation, allowing the design and test of new scenarios.
57	Business process management is an integral part of many organizations in doing their day-to-day business operations considering that they help organizations transfer their business critical information from one organizational entity to another in the form of automated state transitions. The data (or event logs) that have been generated during these transitions hold valuable insights for improving organizational business processes, highlighting problem areas and visualizing the actual vs the formal procedures. The goal of this paper is to summarize the development of a hybrid analytical approach that utilizes both SQL and NO-SQL based back-end platforms in harmony in order to carry out process mining for a participation bank in Turkey. For this purpose, first we have developed a hybrid analytical software infrastructure that is backed by MS SQL Server and Hadoop platform components in order to discover key business processes of the organization based on event data. We then established a process mining framework that visualizes the process performance indicators and proposes workflow design changes and carries out statistical tests for identifying performance fluctuations by particularly using an in-memory parallel processing framework, named Apache Spark. © 2019 The Authors. Published by Elsevier B.V.
58	The objective of this study is to model and improve the performance of the integrated information, business and production process of a powder coating manufacturing by fuzzy simulation. In real situations particularly in business processes, the probability distributions are not known or imprecise and conventional modeling approaches may be questionable. Fuzzy simulation is capable of modeling uncertainties and vagueness. The results of fuzzy simulation approach are compared with conventional simulation by t-test. It is shown the performance of the actual system is modeled and improved by the integrated fuzzy simulation approach of this study. Hence, the results are more reliable than conventional simulation. The integrated approach of this study is capable of evaluating customer lead-times in six dimensions. Furthermore, the integrated fuzzy simulation approach considers conventional customer lead-time (from when the customer places an order) in addition to five other customer indices. This is the first study to model and improve the integrated information, business and production process by fuzzy simulation. The integrated approach of this study identifies major bottlenecks of production process and business process concurrently. It also produces several dimensions of customer satisfactions, allows the effects of business process re-engineering and information technology to be evaluated before actual implementation. In addition, by integrated modeling of this study the hidden and concurrent effect of business and production processes are identified and improved via fuzzy simulation.
59	In real situations particularly in business processes, the probability distributions are not known or imprecise and conventional modeling approaches may be questionable. Fuzzy simulation is capable of modeling uncertainties and vagueness. This paper introduces a novel approach based of fuzzy business process simulation (FBPS) and data envelopment analysis (DEA) for re-engineering, assessment and optimization of a purchasing management system. An actual purchasing system is studied and various data were collected through standard methods. The users of the purchasing management verified that the goals of a re-engineering model are to create a process-oriented approach in order to reduce purchasing process cycle time, faster customer response time and lower cost. The results of fuzzy simulation approach are compared with conventional simulation by t-test. It is shown the performance of the actual system is modeled and improved by the fuzzy simulation approach of this study. The results of fuzzy simulation are more accurate and similar to real situations than previous results by conventional simulation. In addition, DEA is used to identify optimal solution among proposed alternatives. This is the first study that introduces an integrated FBPS-DEA for optimization of purchasing management systems.
60	Recently, much research work has focused on the design of complex infrastructures for Business Process Management (BPM).Process Intelligence (PI) has emerged as a branchn of the BPM domain that deals with improving and standardizing process inspection and analysis, aiming at improving the speed and the effectiveness of business operations. Currently, PI shows several limitations, e.g. due to the fact that only a limited part of the information collected by BPM systems is actually used.The novel idea of the metric life cycle implemented in our approach is based on the definition of "check points", allowing to better understand the role that each metric can or should cover within a BPM process, and providing an important upgrade in the assessment definition.
61	Patient wait times and care service times are key performance measures for care processes in hospitals. Managing the quality of care delivered by these processes in real-time is challenging. A key challenge is to correlate source medical events to infer the care process states that define patient wait times and care service times. Commercially available complex event processing engines do not have built in support for the concept of care process state. This makes it unnecessarily complex to define and maintain rules for inferring states from source medical events in a care process. In this paper, we introduce a state monitoring engine for inferring and managing states based on an application model for care process monitoring. The research is validated with a case study developed in collaboration with a large community hospital.
62	nan
63	Business process management (BPM) in the public sector is proliferating globally, but has its contextual challenges. Ad hoc process improvement initiatives across governmental departments are not uncommon. However, as for all organisations, BPM efforts that are coordinated across the organisation will reap better outcomes than those conducted in isolation. BPM education plays a vital role in supporting such organisation-wide BPM efforts. This teaching case is focused on the sustainable development and progression of enterprise business process management (E-BPM) capabilities at the Federal Department of Human Services: a large Australian federal government agency. The detailed case narrative vividly describes the case organisation, their prior and present BPM practices and how they have attempted BPM at an enterprise level, capturing pros and cons of the journey. A series of student activities pertaining to E-BPM practices is provided with model answers (covering key aspects of BPM governance, strategic alignment, culture, people, IT, methods, etc.). This case provides invaluable insights into E-BPM efforts in general and BPM within the public sector. It can be useful to BPM educators as a rich training resource and to BPM practitioners seeking guidance for their E-BPM efforts.
64	Business Process Management (BPM) is well known for improving the competitiveness and sustainability of a business, and is widely applied. But, BPM practices in SMEs are alarmingly low, regardless of the potential positive impacts BPM brings. This is due to: limited resources, absence of a cross-functional mindset and lack of strategic clarity. Adopting BPM as a management paradigm across the enterprise [hereafter referred to as Enterprise-BPM (E-BPM)] reduces operational inefficiencies and supports innovative practices essential for success, which is the key to SMEs. However, SMEs lack the required know-how, and hence, BPM education/training plays a vital role in supporting this transformation. Teaching cases are recognized as a useful form of education to bring real life to the classroom, and more and more BPM teaching cases are emerging. However, there is a shortcoming in teaching cases addressing E-BPM, and teaching cases addressing E-BPM in SMEs are to date non-existent. This teaching case, especially developed to address this gap, is based on a Norwegian conference venue operating in the Norwegian market. This narrative describes the organization, the context for deploying BPM on enterprise-level and related challenges.
65	Abstract The critical role played by cross-border logistics (CBL) systems in sustaining fast, efficient and responsive global supply chains is widely recognised. However, scholarly research focusing on CBL systems is limited, which means that theoretical frameworks and methodological approaches available for analysing and improving CBL operations are underdeveloped. As such, coordination among diverse stakeholders, meeting regulatory requirements, adapting to a rapidly evolving technological environment, and limited capacity for investing in high-value assets, all remain ongoing challenges hindering the smooth and swift flow of cargo across borders. With a view to addressing these challenges and research gaps, this paper develops a reference model for analysing and improving CBL-specific processes. Seven underlying process dimensions have been identified following a rigorous methodological approach for the modelling, analysis and improvement of CBL operations. The efficacy of the reference model is demonstrated using two purposive case applications. The reference model also helps identify potential technological interventions to improve operations and benchmark CBL systems, operations and processes.
66	This research aims to find a suitable forecasting model for Thailand's total crude palm oil production. The monthly total crude palm oil production in Thailand was gathered from the Office of Agricultural Economics, Ministry of Agriculture, and cooperatives from January 2010 to December 2022. The data were divided into two sets. The first set, from January 2010 to December 2021, was used for constructing and selecting the forecasting models. The second one, from January 2022 to December 2022, was used to compute the accuracy of the forecasting model. Since the total crude palm oil production has trend and seasonal variation, the research used the Holt-Winters method with different initial settings for trend and seasonal influence, the Bagging Holt-Winters method, and the Box-Jenkins method to construct the forecasting models. The minimum mean square error (MSE) and residuals have normal distributions used to select the appropriate forecasting model, and the mean absolute percentage error (MAPE) was used to compute the efficiency of the forecasting model.According to the three forecasting methods results, the Box-Jenkins method was suitable for forecasting Thailand's total crude palm oil production. The ARIMA(2,1,2)(0,1,1)12 model was the best model for predicting Thailand's total crude palm oil production and yielded the MAPE =13.49%
67	A basic assumption underlying any process improvement initiative is that it will have a positive impact on the organization. Therefore, it can become easy to assume that process change will in fact deliver benefits to business. This paper takes a practice-based look at some fundamental assumptions about process improvement that can be as fallacious as they can be true. The argument is supported by case scenarios. Also, some ways are suggested to manage around these fallacies to achieve net benefits rather than no impact or negative impacts on the business. Four basic fallacies are considered: that process improvement leads to business improvement; that process change equates to process improvement; that software processes are non-lethal; and the vision of the enterprise as an automated process. The paper concludes that the future success of process improvement as a management strategy is dependent upon the capability of organizations to capture material gains.
68	Modern communication service providers (CSPs) continuously innovate their product offerings, and adapt engagement services for sales and care processes to increase customer base, maximize customer lifecycle value (CLV) and reduce customer churn in order to stay ahead of the competition and remain profitable. These telecom companies chiefly need an ability to introduce right product offerings at the right time, identify what to cross-sell and upsell to whom, and make timely course correction on engagement services. The current practice of meeting these needs in experience-centric and intuition-driven manner is turning out to be ineffective in the increasingly dynamic business environment. This paper proposes a multi-modelling based simulatable digital twin that enables in-silico quantitative exploration of design space to help human experts arrive at the right product offerings and engagement services. This paper describes our approach and illustrates its utility using a real-life case study.
69	Business process (BP) models are usually defined manually by business analysts through imperative languages considering activity properties, constraints imposed on the relations between the activities as well as different performance objectives. Furthermore, allocating resources is an additional challenge since scheduling may significantly impact BP performance. Therefore, the manual specification of BP models can be very complex and time-consuming, potentially leading to non-optimized models or even errors. To overcome these problems, this work proposes the automatic generation of imperative optimized BP models from declarative specifications. The static part of these declarative specifications (i.e. control-flow and resource constraints) is expected to be useful on a long-term basis. This static part is complemented with information that is less stable and which is potentially unknown until starting the BP execution, i.e. estimates related to (1) number of process instances which are being executed within a particular timeframe, (2) activity durations, and (3) resource availabilities. Unlike conventional proposals, an imperative BP model optimizing a set of instances is created and deployed on a short-term basis. To provide for run-time flexibility the proposed approach additionally allows decisions to be deferred to run-time by using complex late-lanning activities, and the imperative BP model to be dynamically adapted during run-time using replanning. To validate the proposed approach, different performance measures for a set of test models of varying complexity are analyzed. The results indicate that, despite the NP-hard complexity of the problems, a satisfactory number of suitable solutions can be produced. © 2013 World Scientific Publishing Company.
70	This paper presents a study about the mapping of the EUDability of End-User Development (EUD) tools with the Computational Thinking (CT) skills of users. This mapping provides an approach to evaluate the suitability of a EUD environment in supporting people performing their daily work while managing and exploiting EUD tools. EUDability is a construct encompassing different dimensions that need to be assessed through a careful scrutiny by human-computer interaction experts, while CT skills should mirror those dimensions from the point of view of assessing the level of ability of users in managing problems with a computational thinking attitude. Moving from the healthcare domain, we present two cases: a tool for geriatric professionals supporting them in the preparation of cognitive exercises for elderly patients; and a tool for pharmacists, which empowers them to create robot programs related to the preparation of personalized medications. These cases have been exploited to show how to unify the EUDability assessment with the CT skills assessment. In particular, the application of the EUDability evaluation method for each tool, as well as the administration of the Computational Thinking Scale to domain experts are shown. The results of the two assessments are reported and discussed, together with the limitations of the present study. The results show the goodness of fit of the proposed EUD tools in the healthcare domain.
71	Discrete event simulation (DES) techniques cover a broad collection of methods and applications that allows imitating, assessing, predicting and enhancing the behavior of large and complex real-world processes. This work introduces a modern DES framework, developed with SIMIO simulation software, to optimize both the design and operation of a complex beer packaging system. The proposed simulation model provides a 3D user-friendly graphical interface which allows evaluating the dynamic operation of the system over time. In turn, the simulation model has been used to perform a comprehensive sensitive analysis over the main process variables. In this way, several alternative scenarios have been assessed in order to achieve remarkable performance improvements. Alternative heuristics and optimization by simulation can be easily embedded into the proposed simulation environment. Numerical results generated by the DES model clearly show that production and efficiency can be significantly enhanced when the packaging line is properly set up.
72	The execution of business processes produces lots of events that can be used by complex event processing systems to analyze and improve the processes. Typically, events are stored in an event log repository that can be used to identify meaningful patterns of events, such that it is possible to react to them during process execution. However, in many cases it is beneficial to deal with those events before they actually occur to avoid an undesirable outcome, e.g., machine failure or poor performance indicator. Therefore, we present a system architecture connecting the operation of a process engine with a proactive framework. The framework forecasts events, provides the best corresponding action and generates appropriate business rules that can be used by the process engine to make optimal decisions during process runtime. An elaborated example demonstrates the utility of our concept.
73	Business process management is directly affected by how effectively decision making is designed and coordinated. The recent Decision Model and Notation (DMN) standard prescribes that decision processes should be modeled and executed complementary to business processes. One of the challenges that companies face is that many business situations require decision making dealing with huge amounts of input data, but there exist no guidelines on how to prioritize inputs acquisition so that the associated costs are minimal. In this paper, we propose an approach for executing process-level decisions based on prioritization of input data through conversion of decision logic into optimal decision trees. As optimization criteria, our algorithm uses excluding of pre-existing data about a process instance from inputs to be acquired, costs associated with inputs acquisition, and predictions about decision outcomes. We demonstrate the approach on a real-world decision process by showing how to minimize and prioritize questions asked by a bank to a loan applicant so that associated costs are minimal.
74	Industrial enterprises have gradually moved their goals towards production of physical products supplemented by intangible services to differentiate themselves in a compatible market. The study of these services, their set up, and the evaluation of their efficiency is a rising research domain. In the frame of Model Driven Service Engineering Architecture (MDSEA), a service system is modeled from different point of views (static and dynamic) at the different MDSEA levels: Business Service Model (BSM), Technology Independent Model (TIM), and Technology Specific Model (TSM). Simulation is a dynamic feature of MDSE and which explains the need of coherent M&amp;S formalisms for simulation activities. Accordingly, this paper presents the simulation of service systems based on DEVS models. It defines a transformation approach of BPMN models into DEVS simulation models based on the metamodel approach, and describes the enrichment of obtained DEVS models through performance indicators (time and costs).
75	Cooperation between different enterprises to provide product and related services has become a must in order to set up win-win alliances and benefit better from market opportunities. This evolution has encountered several problems, like interoperability when trying to exchange data between heterogeneous systems. This paper shows how a model-driven approach can be an answer to service system implementation and interoperability problems. In particular it details the necessity to provide transformation mechanisms from conceptual description here Extended Actigram Star (EA*) models to more technical models such as BPMN 2.0 models. At the end the paper describes a last transformation to G-DEVS simulation models in order to validate, thanks to simulation, some behavioral properties of the BPMN model before going to implementation.
76	nan
77	Predictive Process Monitoring (PPM) aims to improve operational business processes through the prediction of future behavior and process-related performance indicators. It includes a set of techniques to predict the future behavior of business processes based on knowledge of previously executed process instances. The need for rapid intelligent support in business process management brings growing attention to the field of PPM. A variety of machine learning (ML) based PPM techniques have been proposed by researchers to tackle several PPM-related prediction tasks, such as next activity, time, risk, or outcome. However, adopting such a PPM technique involves many complex tasks, including the selection and parametrization of a machine learning algorithm. Additionally, the novel domain lacks a set of guidelines on how to implement the methods to enable a broad and non-expert user group to benefit from it. As a remedy, this paper proposes a procedure model, which can serve as a step by step framework during the implementation and application of PPM. We conclude our work by demonstrating the applicability of our procedure model and by outlining our case study-based evaluation concept. © 2020 IEEE.
78	Abstract With a steady increase of regulatory requirements for business processes, automation support of compliance management is a field garnering increasing attention in Information Systems research. Several approaches have been developed to support compliance checking of process models. One major challenge for such approaches is their ability to handle different modeling techniques and compliance rules in order to enable widespread adoption and application. Applying a structured literature search strategy, we reflect and discuss compliance-checking approaches in order to provide an insight into their generalizability and evaluation. The results imply that current approaches mainly focus on special modeling techniques and/or a restricted set of types of compliance rules. Most approaches abstain from real-world evaluation which raises the question of their practical applicability. Referring to the search results, we propose a roadmap for further research in model-based business process compliance checking.
79	nan
80	Abstract Driven by technological progress, business analytics is gaining momentum while paving the path for next-generation business process management. Especially, embedded real-time analytics offers new opportunities for business process intelligence and value creation. However, there are several obstacles that organizations face in their adoption process. A key challenge is to identify business processes that are suitable for embedded analytics and hold relevant value potential. Our research addresses this need by introducing an exploratory BPM method, namely a process selection method. Applying action design research and situational method engineering, we iteratively built, used, evaluated, and refined the theory-ingrained method artifact. The method provides organizations with guidance in selecting operational business processes, for which a reengineering project should be initiated.
81	nan
82	This paper presents the architecture of a workflow analysis and design environment (WADE) that will provide robust support for simulation-based design of next-generation workflow systems. The architecture's utility is illustrated by showing its use to design and analyze material ordering and control system workflow.
83	The software industry is moving towards a software factory business model, usually involving several centres collaborating on company contracts. The expected benefits of using specialized teams at lower cost locations are increased productivity and reduced costs. The tasks of project and process management have as a consequence become more complex. Managing such large structures requires more collaboration in development processes to enable rapid reaction to project needs, and support for the variety of technologies, methods, and levels of quality required by the different projects. This situation demands new practices and management support tools. This paper presents Zentipede, a tool for software process management. Its focus is on lightening, or even automating, management tasks by using Business Process Management (BPM) techniques. The tool does not force any particular practice on a company, but encourages it to model the practices which will finally be automated. Also, it supports process-to-product traceability. © 2010 Springer-Verlag.
84	This paper presents a framework for analyzing and predicting the performances of a business process, based on historical data gathered during its past enactments. The framework hinges on an inductive-learning technique for discovering a special kind of predictive process models, which can support the run-time prediction of a given performance measure (e.g., the remaining processing time/steps) for an ongoing process instance, based on a modular representation of the process, where major performance-relevant variants of it are modeled with different regression models, and discriminated on the basis of context variables. The technique is an original combination of different data mining methods (ranging from pattern mining, to non-parametric regression and predictive clustering) and ad-hoc data transformation mechanisms, allowing for looking at the log traces at a proper level of abstraction, in a pretty automatic and transparent way. The technique has been integrated in a performance monitoring architecture, meant to provide managers and analysts (and possibly the process enactment environment) with continuously updated performance statistics, as well as with the anticipated notification of likely SLA violations. The approach has been validated on a real-life case study, with satisfactory results, in terms of both prediction accuracy and robustness. © Springer International Publishing Switzerland 2014.
85	nan
86	nan
87	Revenue management (RM) is the process of understanding and anticipating customer behavior in order to maximize revenue raised from the sale of perishable resources available in limited quantities. While RM systems have been in operation for quite some time, they cannot take into account the full dynamic and stochastic nature of the problem, hence the need to assess them via simulation. In this paper we introduce RMSim, a discrete-event and object-oriented Java library designed to simulate large-scale revenue management systems. RMSim supports all control policies, arrival processes and customer behavior models hitherto proposed. It can therefore be used to calibrate parameters of the model and to optimize the control policy. A key feature of RMSim is that the network RM system can be altered without having to modify the source code of the library. Performance, flexibility and extensibility are the main goals behind the design and implementation of RMSim.
88	This tutorial defines what a digital twin is and outlines its four required characteristics. Digital twins are developed to derive insights to control entities and processes in the digital world with simulation as one of the key technologies lying at the heart of this development. The resulting insights are used to prescribe actions in the physical world to fix future problems before they happen. This tutorial describes the key digital twin development functions together with the digital twin enabling technologies with focus on the use of simulation for process twin development. The corresponding functions and technologies are displayed on several different digital twin development frameworks with the potential to serve as guides for practitioners interested in developing digital twin solutions. We conclude with an example of a supply chain digital twin use case and the role of simulation and AI in the twin development.
89	Model-driven engineering relies on collections of models, which are the primary artifacts for software development. To enable knowledge sharing and reuse, models need to be managed within repositories, where they can be retrieved upon users’ queries. This article examines two different techniques for indexing and searching model repositories, with a focus on Web development projects encoded in a domain-specific language. Keyword-based and content-based search (also known as query-by-example) are contrasted with respect to the architecture of the system, the processing of models and queries, and the way in which metamodel knowledge can be exploited to improve search. A thorough experimental evaluation is conducted to examine what parameter configurations lead to better accuracy and to offer an insight in what queries are addressed best by each system.
90	Purpose – The purpose of this paper is to provide a method for analysing and improving the operational performance of business processes (BPs). Design/methodology/approach – The method employs two standards, Business Process Modelling Notation (BPMN 2.0) and Business Processes Simulation (BPSim 1.0), to measure key performance indicators (KPIs) of BPs and test for potential improvements. The BP is first modelled in BPMN 2.0. Operational performance can then be measured using BPSim 1.0. The process simulation also enables execution of reliable “what-if” analysis, allowing improvements of the actual processes under study. To confirm the validity of the method the authors provide an application to the healthcare domain, in which the authors conduct several simulation experiments. The case study examines a standardised patient arrival and treatment process in an orthopaedic-emergency room of a public hospital. Findings – The method permits detection of process criticalities, as well as identifying the best corrective actions by means of the “what-if” analysis. The paper discusses both management and research implications of the method. Originality/value – The study responds to current calls for holistic and sustainable approaches to business process management (BPM). It provides step-by-step process modelling and simulation that serve as a “virtual laboratory” to test potential improvements and verify their impact on operational performance, without the risk of error that would be involved in ex-novo simulation programming. © 2016, © Emerald Group Publishing Limited.
91	The article aims to present the results of research on the importance of IT systems in the integration of knowledge management and business process management in organisations operating on the Polish market. We consider this issue in the context of the impact of the elements examined on the quality of the processes carried out, the effectiveness of the business, and customer satisfaction. The research was conducted in Poland in 2020 on a sample of 107 enterprises with a range of international (48%), national (39%), regional (6%), and local (6%). Among the organisations surveyed were manufacturing and service companies operating in various industries. The dominant group of respondents were large enterprises (55%), medium-sized enterprises accounted for 22%, small enterprises - 19%, and micro-enterprises - 4%. The article indicates the industries in which IT systems are used to the greatest extent in business process management and knowledge management. The respondents referred to the role (significance) of improving the availability of knowledge resources for the benefit of improving the quality of processes implemented, optimising key performance indicators (KPIs), costs, and time, as well as increasing customer satisfaction. The results indicate statistically significant relationships between the variables studied - business process management and knowledge management (with the use of IT systems), and the quality of processes, their effectiveness, and the level of customer satisfaction. © 2022 International Association for Computer Information Systems
92	Networks of interdependent organizations cooperate to produce goods or, nowadays, services that are of value to their markets as well as to the participating organizations. Such co-operations can be supported by corresponding business processes which are based on SOA technology. Developing and managing SOA-based business processes in such service networks necessitates a comprehensive architecture which is on the one hand grounded on solid design principles, and on the other hand capturing best-practices and experiences. Such an architecture is currently lacking. This paper outlines a first attempt to develop and validate an architecture for developing, monitoring, measuring and optimizing SOA-enabled business processes in service networks. A case study from the telecommunications industry is analyzed, and different aspects of service networks are addressed. © 2008 Springer Berlin Heidelberg.
93	Process Performance Management (PPM) comprises the planning, monitoring, and control of process performance. Even though numerous methods and concepts for managing process performance do exist, many service companies develop their own PPM approaches and systems to monitor and control their service processes. However, they are often unaware of the factors which really are important when applying PPM. Therefore this paper aims to identify which factors are critical for the successful application of PPM for services. The findings of a multiple-case study research provide a first understanding of the causal relationships and, as a result, 'process knowledge/models' and 'information quality' appear to be important success factors of PPM for services.
94	In this paper, a method for hybrid short- to long-term planning of available resources for operations is presented, which is based on a known or deterministically forecasted but highly variable demand. The method considers quantitative measures such as the performance and the availability of resources, ergonomically relevant KPI and ultimately process costs in order to serve as a pragmatic planning tool for operations managers in SMEs. Specifically, the method enables exploiting the ergonomic advantages of available flexible automation technology (e.g. AGVs or picking robots), while assuring that these do not represent a capacity bottleneck. After presenting the method along with the necessary assumptions, mainly concerning the availability of data for the calculations, we report a case study that quantifies the impact of throughput variability on the selection of different process alternatives, where different teams of resources are used.
95	Business areas' managers should have access to business process indicators of their organizations to be capable of obtaining and analyzing information at real time during critical situations. However, the monitoring approaches commonly provided to such managers usually address only indicators at the level of the services implementing the business processes, which are technical measures directed to Information Technology (IT) managers. This paper introduces the StrAli-BAM (Strategic Alignment with Business Activity Monitoring) approach to assist strategic alignment between business and IT through monitoring non-functional business process requirements based on Quality of Service (QoS) levels. StrAli-BAM aims to enable business areas' managers to monitor the execution of business processes by focusing on the indicators that are really sensitive to the execution of business processes. StrAli-BAM consists of: a non functional requirement monitor and an infrastructure for SOA event-based execution and monitoring. This paper was performed following the research method of project science. The proposed approach is evaluated via a proof of concept in an online shopping scenario with non-functional response time requirement monitoring.
96	Abstract The notation of a modeling language is of paramount importance for its efficient use and the correct comprehension of created models. A graphical notation, especially for domain-specific modeling languages, should therefore be aligned to the knowledge, beliefs, and expectations of the targeted model users. One quality attributed to notations is their semantic transparency, indicating the extent to which a notation intuitively suggests its meaning to untrained users. Method engineers should thus aim at semantic transparency for realizing intuitively understandable notations. However, notation design is often treated poorly—if at all—in method engineering methodologies. This paper proposes a technique that, based on iterative evaluation and improvement tasks, steers the notation toward semantic transparency. The approach can be efficiently applied to arbitrary modeling languages and allows easy integration into existing modeling language engineering methodologies. We show the feasibility of the technique by reporting on two cycles of Action Design Research including the evaluation and improvement of the semantic transparency of the Process-Goal Alignment modeling language notation. An empirical evaluation comparing the new notation against the initial one shows the effectiveness of the technique.
97	A business process (BP) consists of a set of activities which are performed in coordination in an organizational and technical environment and which jointly realize a business goal. In such context, BP management (BPM) can be seen as supporting BPs using methods, techniques, and software in order to design, enact, control, and analyze operational processes involving humans, organizations, applications, and other sources of information. Since the accurate management of BPs is receiving increasing attention, conformance checking, i.e.; verifying whether the observed behavior matches a modelled behavior, is becoming more and more critical. Moreover, declarative languages are more frequently used to provide an increased flexibility. However, whereas there exist solid conformance checking techniques for imperative models, little work has been conducted for declarative models. Furthermore, only control-flow perspective is usually considered although other perspectives (e.g.; data) are crucial. In addition, most approaches exclusively check the conformance without providing any related diagnostics. To enhance the accurate management of flexible BPs, this work presents a constraint-based approach for conformance checking over declarative BP models (including both control-flow and data perspectives). In addition, two constraint-based proposals for providing related diagnosis are detailed. To demonstrate both the effectiveness and the efficiency of the proposed approaches, the analysis of different performance measures related to a wide diversified set of test models of varying complexity has been performed. © 2014 Elsevier Ltd. All rights reserved.
98	This paper focuses on organizational performance measurement. It offers an overview of the literature on organizational performance measures, approaches and frameworks. Analysis indicates that organizational performance measurement is well recognized as an important part of the business process management literature. The purpose of this paper is to propose a performance measurement guideline. Defining an appropriate guideline helps to clarify and systemize this field, but also represents a critical step for business practitioners since it could influence the success of organizational performance measurement system development. © 2008 IEEE.
99	The aim of this paper is to put into practice a framework we proposed in an earlier work for evaluating on-going decision support systems. The framework serves as a base for a method to compute evaluation criteria scores using an AHP model. The paper also illustrates the automation of this method into a tool to enable GASCO company to choose between two already implemented DSSs in order to reduce IT operating cost. The evaluation covers three axes: Process, outcome and decision maker metrics. The results highlight the importance of using users' learning as a measure to determine DSS success.
100	This paper presents an application of computer simulation as a policy analysis tool for the electric utility industry. In the last decade, the amount of electricity generation capacity has remained constant while demand for electricity has been increasing. This situation puts industrial electricity users, those who use large highly varying quantities of electricity in potentially risky production and financial situations. In this paper, we describe a computer simulation model that examines the electricity requirements of a steel mill in a constrained electricity supply environment. By using simulation, we develop and analyze policies that quantify the costs and benefits of collaborative strategies for efficient electricity usage from both perspectives.
101	Despite COVID-19, the world economy still contributes to the growth of production and consumption worldwide. Waste disposal, recycling management and energy generation are challenges for many companies in developing economies, including Poland. This article aims to assess the operation of a municipal waste treatment plant (MWTP) from the perspective of green business process management (BMP) solutions. The processes implemented in the MWTP were discussed, with specific consideration of the mechanical waste processing (sorting) process, including the reuse and recycling of materials, composting, energy production (anaerobic process), landfill storage and efficiency parameters of the sorting line. A sustainable waste management system was identified; the cost as well as social and environmental perspectives were analyzed. Also, strategic goals and key performance indicators were considered. The performed analysis included costs, environmental criteria and key environmental indicators. This paper has shown the successful implementation of green BPM, with potential cost and material savings results. The findings of this case study are expected to inspire other waste management companies to adopt green BPM. The presented case study might help raise awareness and promote the implementation of green BPM in municipal plants in Eastern and Southern Europe. © The Author(s) 2024.
102	This paper delves into the integration of Intelligent Process Automation within the domain of business continuity auditing, with a focus on the Portuguese banking sector. In an era marked by rapid technological advancement, organizations are increasingly leveraging automation to reinforce operational efficiency and realize substantial cost savings. Concurrently, auditors play a pivotal role in ensuring seamless transitions amid technological transformations to safeguard business continuity. This research endeavors to bridge the realms of business continuity and intelligent automation, culminating in a comprehensive application that streamlines the audit process. The implemented solution encompasses the automation of critical audit activities, including communication, information requests, and final report submissions, liberating auditors from the chains of repetitive tasks. The incorporation of business intelligence augments this automation framework, enabling a meticulous analysis of key performance indicators within the audit department. This ensures a continuous evaluation of the efficacy of the Annual Audit Plan. Empirical validation of this initiative was achieved through surveys conducted with audit teams from four prominent Portuguese banks. The results unequivocally affirm the potential benefits of this implementation, extending invaluable support to management in the decision-making process, while concurrently alleviating auditors of routine tasks inherent to the audit process. This study not only underscores the transformative potential of intelligent process automation in the audit domain but also offers a replicable framework for organizations seeking to fortify their business continuity efforts through technological integration. The findings hold implications for businesses navigating the dynamic intersection of technology and audit practices, providing a blueprint for harnessing automation for enhanced operational resilience. © 2024
103	Cross-layer adaptation and monitoring (CLAM) is an approach to the run-time quality assurance of service-based applications (SBAs). The aim of CLAM is to monitor the different layers of an SBA and correlate the monitoring results, such that in the event that a problem occurs an effective adaptation strategy is inferred for enacting a coordinated adaptation across all layers of the SBA. An important aspect of CLAM is the definition of the appropriate Service-Level Agreements (SLAs) for third party services utilised in the different layers of the SBAs. In this paper, we present insights into how to define SLAs for CLAM, by analysing SBAs in order to differentiate the third party business, software and infrastructure services utilised by the SBA. As a case study, we apply the analytical approach to an existing platform-as-a-service framework, which has been developed as an SBA and could benefit from CLAM. The analysis reveals the different third party services and their characteristics, as a precursor to defining SLAs. The case study successfully demonstrates how distinct SLAs for business, software and infrastructure services may be applied respectively in the BPM, SCC and SI layers of an SBA, to provide a flexible monitoring and adaptation response across layers.
104	This exploratory paper presents a literature review of the business performance management (BPM) systems concept. Using a variety of sources, the concepts of business performance management systems are presented by the authors in respect to traditional theoretical management methodologies and performance measurement techniques, as well as to other enterprise systems including Business Intelligence (BI), Executive Information Systems (EIS) and Automated Scorecards. As a culmination to the review, a conceptual model is proposed, identifying the key technical enablers and business drivers affecting the adoption of modern BPM systems.
105	Procedure of formation of adaptive business process for management of efficiency of activity of the hi-tech enterprise as procedure of management of key indicators of efficiency of the business solution with use of a service-oriented technological platform of ERP system is presented in article.
106	In the pursuit of economic survival in the current competitive conditions with the aim of long-term prosperity and sustainability in the market, many companies today approach significant strategic changes in the management of their business. The purpose of this study is the design of a systematic procedure for implementing strategy changes into internal business processes for a project-oriented production type of organization. The proposed methodology contains steps where the selection and verification of key performance indicators at individual levels of management takes place. Furthermore, their monitoring and quantification of the impact of the change in strategy on internal company processes. The result of the study explains how the management can monitor and evaluate the chosen processes in accordance with the fulfilment of the chosen strategy of the company, which supports the systematic introduction of changes in the processes with the aim of sustaining the company’s performance. © 2022 by the authors.
107	nan
108	Inner source software development is the practice of using open source practices for firm-internal software development. Practitioner reports have shown that inner source can increase flexibility and reduce costs. Despite the potential benefits of inner source, there has been little research on its impact on businesses and their processes. To address this gap, we conducted a systematic literature review that identified which business processes are affected by inner source development, particularly within the accounting and management domain. Our review revealed the need for new dedicated community building processes within companies. In addition, we examined computational tools and techniques that can be used to measure inner source development. We found that existing tools and techniques are insufficiently suitable to manage inner source processes. Based on this, we propose research topics for future work on quantifying inner source.
109	nan
110	nan
111	Modern businesses use contact centers as a communication channel with users of their products and services. The largest factor in the expense of running a telephone contact center is the labor cost of its agents. IBM Research has built a new system, Contact-Center Agent Buddies (CAB), which is designed to help reduce the average handle time (AHT) for customer calls, thereby also reducing their cost. In this paper, we focus on the call logging subsystem, which helps agents reduce the time they spend documenting those calls. We built a Template CAB and a Call Logging CAB, using a pipeline consisting of audio capture of a telephone conversation, automatic speech recognition, text analysis, and log generation. We developed techniques for ASR text cleansing, including normalization of expressions and acronyms, domain terms, capitalization, and boundaries for sentences, paragraphs, and call segments. We found that simple heuristics suffice to generate high-quality logs from the normalized sentences. The pipeline yields a candidate call log which the agents can edit in less time than it takes them to generate call logs manually. Evaluation of the Call Logging CAB in an industrial contact center environment shows that it reduces the amount of time agents spend logging calls by at least 50% without compromising the quality of the resulting call documentation.
112	Human resources are assigned responsibilities over process activities (e.g. performing the work or approving the outcome). The responsibility assignments must be enforced so that suitable resources are engaged in the process at runtime. Moreover, organizations define Process Performance Indicators (PPIs) that help to monitor the progress w.r.t. target values related to the activities (e.g. execution times). Controlling how PPIs depend on resources is crucial for process managers especially when things go wrong (e.g. to alert people or adapt target values). However, this is still usually done manually. This paper presents a two-fold contribution: (i) a graphical representation of responsibilities in process models, and (ii) a procedure to automatically identify how resources are involved in the PPIs of a process. The work is driven by a use case found in industry for which a prototype has been implemented. © XXII Ibero-American Conference on Software Engineering, CIbSE 2019. All rights reserved.
113	This paper describes a novel approach for teleconsultation and telemonitoring in healthcare domain. Teleconsulting for diagnostic images involves much more than merely transmitting images and information between two points called hub and spoke. It needs to accomplish a lot of tasks, among them: rapid access to radiological reports and second opinions, remote consulting among Physicians, improved patient care, access to complex tools for post processing and computer-aided diagnosis, support for research and training projects, ties between isolated healthcare providers and busier or more experienced providers, 24-h coverage.The HINT project provides a real-time monitoring of the patient's clinical data and alerting in case of emergencies. The application is fully integrated with all IHE compliant RIS and PACS systems. The workflow management system, integrated in the platform, permits to manage a multiplicity of different scenarios in one application, allowing fast prototyping, process changing and reuse of subprocesses.
114	nan
115	Nowadays, more and more industrial organizations are using Business Process Model and Notation (BPMN) for process modeling. Data collected during business process execution are used for deriving the key performance indicators (KPI) that allow continuous tracking of the process behavior and measurement of process-specific goals. KPIs evaluation leverages on business process monitoring solutions that can be embedded into the BPM execution framework or integrated as additional facilities. This paper presents an integrated framework that allows modeling, execution and analysis of business process based on a flexible and adaptable monitoring infrastructure. The main advantage of the proposed approach is that it is independent from any specific business process modeling notation and execution engine and allows for the definition and evaluation of user-specific KPI measures. An example of implementation of the proposed execution and monitoring framework as well as its validation on a real case study in the learning domain are also presented. © 2015 IEEE.
116	Nowadays, more and more industrial organizations are using Business Process Model and Notation (BPMN) for process modeling. Key performance Indicators (KPIs) are seton such process models so to get a quantitative assessment of critical success metrics. A timely and reliable monitoring of KPIs is instrumental to Business Process (BP) management, and several frameworks are being proposed for such purpose. Business process monitoring solutions can be embedded into the Business Process Modeling (BPM) execution framework or integrated as additional facilities. This paper presents an integrated framework that allows for modeling, execution and analysis of business process based on a flexible and adaptable monitoring infrastructure. The main advantage of the proposed approach is that it is independent from any specific business process modeling notation and execution engine and allows for the definition and evaluation of user-specific KPI measures. © 2015 IEEE.
117	Currently, Business Process Model and Notation (BPMN) has becoming one of the main languages for creating a description of processes and developing executable frameworks for the management of the process itself. In this context, one important aspect of process management is the possibility of process analysis and optimization, which many times relies on real data collected during the process execution itself. This paper goes in this direction and presents a framework for performance analysis and optimization of the business process expressed in BPMN. It focuses on the collection and evaluation of time based and cost based parameters ad relies on an adaptable and flexible event based monitoring infrastructure. In particular, it implements some business process path coverage metrics useful for evidencing business process criticalities and possible improvements of the business process execution. A first validation on a case study is also presented.
118	nan
119	Ambient Assisted Living (AAL) systems are playing an important role in the modern society, by helping elderly people to live more independently and support daily activities. Knowledge models have been proposed in the past to describe AAL devices. However, models and methodologies capable to provide assistance to system designers during the development of an AAL environment are still missing. To this aim, in this work we propose an ontology to formally represents all relevant knowledge in the AAL domain ranging from goals to measures and sensors. On its top, a set of logic-based reasoning functions provides advanced support to the development process. In this way, starting from high-level goals the designer can easily retrieve which devices are needed to best meet the project specifications, leading to a cost-effective reduction of development time.
120	Business Process Management Systems are increasingly used by organizations to define, coordinate, an alyzeand improve their business environment. Business Process Management Systems and Decision Support have a large commercial potential and it is a very interesting field for research and invention. In this paper, an overview of recent patents related to Business Process Management over the past seven years is given. © 2011 Bentham Science Publishers.
121	Purpose: The purpose of this paper is to introduce a layered, comprehensive model of quality of service (QoS) for local eGovernment, and discuss its feasibility on a regional eGovernment case study. The eGovernment online services are becoming a key infrastructure for advanced countries. They allow significant efficiency gains in different sectors of society, offering benefits for individual citizens and for the community as a whole. The deployment of online services alone is not sufficient in order to qualify an eGovernment strategy. The intrinsic and perceived quality of services offered, as well as the actual impact of new functionalities, should be properly measured and taken into account. Design/methodology/approach: This paper presents an applied research study for a quality-focused evolution of a service-oriented architecture for local eGovernment portals. This investigation was based on three main layers: the perceived quality and effective impact of services (G2C layer), the effectiveness of the deployed processes (WFM layer) and finally, the system-level efficiency (G2G layer). Findings: The measurement of quality with respect to eGovernment services is a complex task which requires appropriate tools to tackle the different aspects of the problem. Specifically, active and passive tools (respectively surveys and usage analysis) should be used to evaluate the quality perceived by the users as well as the utility of the service itself. The efficiency of the back office workflow must be estimated measuring statistical and dynamical indicators. Finally, technical measures should be used to monitor the responsiveness and scalability of software implementations and deployment systems. Social implications: A better knowledge regarding (e-)Government service delivery processes, their QoS and their impact on the society can empower both citizens and local administrators, and can help them to better improve the effectiveness of local government. Originality/value: The multi-layered quality measurement architecture proposed in this paper offers local governments the capability to systematically monitor and analyse the quality of their online services. The business process management technologies allow citizens to get a better knowledge of the service delivery processes; the QoS measurements allow to improve control on them; and the eGovernment Intelligence model allows to better quantify their actual social impact. © Emerald Group Publishing Limited.
122	nan
123	This paper discusses the potential benefits of incorporating a goal-oriented perspective to Business Process Management (BPM) from a methodological point of view, with a focus on the BPM Design and Evaluation phases. To achieve this aim, we examine the current activities of the BPM lifecycle and on the basis of that, the lifecycle is increased with new activities related to the modeling of business services and goals. In the BPM design phase, we suggest the integration of business services, goals and KPI modeling to the previously modeled business processes, also describing how the existing methods in goal and KPI modeling can be used to perform such representation. In the Evaluation phase, we discuss how the previously modeled KPIs can be evaluated in terms of operational data. The information produced by the KPI monitoring enables one to verify whether the business goals are being adequately fulfilled by the enterprise architecture. Further, business services can be evaluated with respect to their ability in adequately aggregating value for the final customer. © 2013 IEEE.
124	This paper reviews the support for modeling KPIrelated concepts in several enterprise modelling approaches and enterprise architecture frameworks. The scarcity of KPI modeling in EA approaches led us to open our scope of investigation to proposals in Business Process Management (BPM) area. Inside each approach, we first describe how these efforts propose to align goal-related concepts with KPI-related concepts (if the approach presents some kind of support for goal modeling). Further, the conceptual characterization for modeling KPI-related concepts in the context of EA models is also explored. Finally, we devote some considerations on how the KPI-related concepts are used to measure the properties of the EA elements and evaluate the achievement of goals. We conclude the paper proving challenges for the conceptual representation of a KPI modeling language that aims at measuring goal satisfaction the context of EA models. © 2013 IEEE.
125	Organizational process improvement initiatives typically apply some kind of process assessment. Even partial automation of these process assessments can be beneficial. In this sense, the aim of this study is to investigate the state of the art in automated process assessment. A systematic literature mapping is performed in order to answer the research question: What are the approaches to automated process assessment? Thus, the state of the art is analyzed following the steps of protocol definition, search execution, study selection and data extraction and synthesis. We found 16 studies that directly or indirectly use some kind of automated process assessment support. The approaches reported in these studies cover most of the steps expected in typical process assessments and used nine different software tools to support these steps. The main observed results of process assessment were reduction of effort, time and complexity and automated assessment feedback. There are two major contributions of this research: a comprehensive and structured overview of the state of the art in automated process assessment, contributing to the knowledge organization of this field; and an initial guide to organizations that want to apply efforts to automate their process assessments in choosing the tools, techniques and approaches, and knowing the expected outcomes of this kind of initiative.
126	Design science research involves creating and evaluating innovative methods and approaches to be used in design practice. We present an approach to be used in the process of designing Management Support Systems (MSS). The nature of managerial work makes the design, development, and implementation of MSS a major challenge. The MSS literature suggests that determining MSS requirements and specification of MSS are the most critical phases in MSS design and development. We present an approach that can be used as a guide for MSS design, with a primary focus on MSS requirements determination and how requirements can be fulfilled using information and communication technologies (ICT). The approach builds on Quinn and associates' competing values model (CVM) of organizational effectiveness. The approach can guide MSS designers in designing MSS that support different managerial roles, i.e., the development of MSS that support managerial cognition, decision, and action.
127	Business processes' Non-Functional Requirements (NFR) can foster the strategic alignment in organizations. Our goal was to evaluate to what extent there are approaches that seek to support the modeling of business processes' NFR based on strategic goal-related information. To achieve this goal, we conducted a literature study based on systematic review concepts. As a result, we identified 19 works addressing strategic goals and business processes with NFRs. The most commonly used techniques are: i∗ and Key Performance Indicators (KPI) for modeling strategic goals and Business Process Model and Notation (BPMN) for modeling business processes. According to our analysis, no approach fully addresses business processes' NFR based on strategic goals which was our primary question in conducting this study. © Copyright 2017 by SCITEPRESS - Science and Technology Publications, Lda.
128	The unprecedented growth in service-based business processes over a short period of time has underscored the need for understanding the mechanisms and theorising the business models and business process management adopted across many organisations today. This is more evident within the Irish health sector. This research summarises a survey of the literature and argues that the inability of current Business Process Management (BPM) techniques to visualise and monitor web-enabled business processes prevents us from transforming information on network activity and infrastructures. Thus, this research sets out to propose the need to develop a framework to enhance manager's ability to monitor key performance indicators (KPIs) while improving business process restructuring practices.
129	The success of developing service networks rely on obtaining a correct understanding of the end-to-end business processes. However, there are major concerns as to the lack of research efforts to examine methods to successfully manage the complexity of service networks. The insufficient communication efforts between business and technical experts results in a dissatisfactory service delivery and the inability to predict and measure the service network performance. This literature survey is initiated with purpose of finding a novel way to represent business processes in service networks and analyses the process performance. Specifically, we discuss the need to conceive tools and techniques to manage the complexity of service networks without jeopardising the performance of service networks and provide an overview of current simulation-based modelling approaches and optimising business processes.
130	There is a need to address the significant gap in our ability to measure and monitor the Key Performance Indicators (KPIs) across service networks. The unprecedented growth in service-based business processes over a short period of time has underscored the need for understanding the mechanisms and theorising the business models and business process management adopted across many organisations today. This research presents a survey of the literature and argues that the inability of current Business Process Management (BPM) techniques to visualise and monitor web-enabled business processes prevents us from transforming information on network activity and infrastructures. This inhibits managers in anticipating change and adapting to more agile business practices in service science. Thus, this research-in-progress sets out to propose the need to develop a framework to enhance a manager's ability to monitor key performance indicators (KPIs) while improving business process restructuring practices through social network analysis (SNA). © 2010 IEEE.
131	nan
132	Current Business Process Management technologies cover all the process life-cycle but still suffer from many limitations with respect to their complexity, maintainability and degree of automation. Recent research initiatives aim at overcoming these limitations by introducing Semantic technologies in the process life-cycle. One of the steps that can benefit from this approach is the Business Process Analysis, that focuses on the delicate phase of studying, testing and evaluating existing and running systems and processes, with the aim of identifying the current system (process) state, as well as pointing out problems and bottlenecks, measuring key performance indicators and suggesting potential improvements. We believe that the use of Semantic Web can be of great help in improving and partially automating Business Process Analysis tasks. In this position paper, we explain how we envision the future of Semantic Business Process Analysis and we introduce the early results of our approach based on two different analysis methodologies, Reverse Business Engineering and Process Mining.
133	nan
134	nan
135	This paper presents a framework for analyzing and predicting the performances of a business process, based on historical data gathered during its past enactments. The framework hinges on an inductive-learning technique for discovering a special kind of predictive process models, which can support the run-time prediction of some performance measure (e.g., the remaining processing time or a risk indicator) for an ongoing process instance, based on a modular representation of the process, where major performance-relevant variants of it are equipped with different regression models, and discriminated through context variables. The technique is an original combination of different data mining methods (namely, non-parametric regression methods and a probabilistic trace clustering scheme) and ad hoc data transformation mechanisms, meant to bring the log traces to suitable level of abstraction. In order to overcome the severe scalability limitations of current solutions in the literature, and make our approach really suitable for large logs, both the computation of the trace clusters and of the clusters’ predictors are implemented in a parallel and distributed manner, on top of a cloudbased service-oriented infrastructure. Tests on a real-life log confirmed the validity of the proposed approach, in terms of both effectiveness and scalability. © IFIP International Federation for Information Processing 2016.
136	nan
137	We provide summaries of over 150 alignment articles. The information is intended to assist faculty and graduate students who are conducting IT alignment-related research. The findings presented should interest practitioners also. We hope that the article will facilitate the ongoing study and practice of IT alignment.
138	Business operations are an inseparable part of overall business services and energy consumption. Multiple levels of information regarding building components (architectural, electrical and mechanical), environmental conditions (outdoor and indoor) and occupant behaviour patterns, mostly driven by everyday business processes (schedules, loads, specific business episodes related to occupancy patterns and building operations), are considered necessary for effective and efficient modelling of building energy performance. Given the trend towards low energy consumption, actively engaging occupants during the building operation is critical to achieve high energy efficiency without scarifying end users comfort. The aim of this paper is to report the design and development of an innovative energy management framework to enable the alignment of fine-grain building energy use data to the organizational operational activities, allowing thus for a holistic view over the organizational energy performance. The main principle for the proposed framework is about linking Business Process Modeling (BPM) with Occupant Behaviour patterns and Building Information Modelling (BIM), the model that contains information for the building spaces and resources in terms of material and equipment. The exchange of information among these models is essential towards energy efficient buildings. By linking core operational aspects (equipment usage) and environmental conditions (temperature, humidity and luminance) to occupants' behaviours underlying business processes and organizational structures, the aim is to enhance the comprehensiveness and easy interpretation of building energy performance metrics within an extended enterprise performance evaluation framework. © International Conference on Smart Infrastructure and Construction 2019, ICSIC 2019: Driving Data-Informed Decision-Making.
139	In this paper, an approach for inter-organizational business process management is introduced. The approach is backed by the UML modeling domain ontology among involved organizations and through the all phases in the business process management. XML Nets (a new variant of high-level Petri nets) is a formal, graphical modeling language that allows modeling both the flow of XML documents and the underlying business process. In the method, XML Nets combined with UML models for design, execution and monitoring of inter-organizational business processes. Consequently, the processes can be directly executed, improved and monitored. The approach supports the continuous improvement of inter-organizational business processes of all involved organizations on a holistic level.
140	Since the beginning of the 21st century, customer demand has been evolving more and more toward individualized items. In addition, the increase in uncertainties related to geopolitical contexts such as wars, political conflicts, and energy crises, has made the decision process more complex. To respond to these changes, companies are forced to be more flexible, agile, and resilient on the one hand and to apply the concept of mass individualization on the other hand. Knowing that there are several types of flexibility and that higher levels of flexibility generate higher production costs, one of the main challenges for companies is to select the relevant types of flexibility and the appropriate level of them for their projects and objectives. This paper focuses on modelling, measuring, and determining the appropriate level of flexibility. Since the level of flexibility is mainly related to the level of uncertainties, it is also necessary to model the historical uncertainties and their relationship with the company's objective. For this purpose, the proposed method uses the existing key performance indicators (KPIs) of the company, through which the actual levels of several flexibilities are first measured and then the appropriate levels are defined. Furthermore, by considering the interdependence between flexibilities, an aggregation model transforms the individual measures of flexibility levels into a Global Flexibility Indicator (GFI) that allows decision-makers to prioritize the most important project. In addition, this GFI can be used to model unpredictable events and set flexibility targets based on historical data and events. An application of the proposed method in the automotive industry in the context of a new product introduction is presented.
141	nan
142	Service engineering, the application of engineering disciplines to develop service-oriented enterprise systems (service systems) with predicable results, has faced a brand new array of challenges in recent years. Existing development approaches that might help addressing these challenges are scattered in separate research fields or in different units of an organization, just like the "blind men and the elephant." This article presents a 3-year action research case study with a Fortune 50 company in the financial services industry, validating an integrated service-oriented business-IT alignment framework, called the BITAM-SOA Framework, to shed light on complex service engineering issues, including the interplay between business-IT alignment approaches (alignment via architecture, via governance and via communication) and Service Oriented Architecture adoption as well as methodological challenges of service engineering. The importance of the social dimension of service engineering is illuminated. The results yield lessons learned, managerial insights and integrated methods for effective service engineering.
143	As an important part of business process management, continuous improvement is a crucial factor determining the enterprises' capability of keeping competition in rapidly changing marketplace. In this paper, we integrate the data mining technology into the workflow management system to find out the tacit business process knowledge, and put forward the concept of workflow mining. Based on this foundation, business process continuous improvement framework on workflow historical process information mining is proposed. It includes four levels: historical information acquisition, performance evaluation, structural defects identification and generation of improved model. Key techniques of each layer are discussed, and prototype system is developed to support the implementation of this method. Enterprise application shows that this system has strong flexibility and extensibility, and its structure is reasonable.
144	Shared services have become an important model for delivering support business functions centrally as services to internal users via information systems. We perceive the shared services as a digital platform for business process execution, and argue that the value of shared services can be gained from process improvements in addition to cost savings. Focusing on corporate finance and accounting functions, we propose that shared financial services improve firm performance, and such a relationship is mediated by the working capital efficiency which is one performance measurement of finance and accounting functions. We test our hypotheses with data on Chinese public firms from 2008 to 2017. Data analysis results show both direct effect of shared financial services on profitability and mediating effect of working capital efficiency. This study expands our understandings about how shared services generate business value, and provides strong empirical support for the process-oriented perspective in IT business value research. © 2020 26th Americas Conference on Information Systems, AMCIS 2020. All rights reserved.
145	The Business Process Management (BPM) lifecycle includes a redesign phase, which is an important step for stakeholders while working on the improvement of their Business Processes. Some research approaches on process improvement involve Key Performance Indicators and Process Mining, but essentially using the latter to verify if improvement efforts have been successful. In this paper, we propose a different approach for process improvement by first defining and configuring, process KPI target values, and second using Process Mining techniques to discover and analyze deviations from those values. Then, for each deviation we propose improvement solutions based on Business Process redesign patterns. Since this encompasses also an improvement cycle, we present our approach as an extension of the well-known BPM cycle. With this approach, process stakeholders will be able to quickly identify process KPI deviations based on quality, cost, time and flexibility, and resolve them by automatically applying proven redesign patterns. © 2019 The Authors. Published by Elsevier B.V.
146	Digitalized processes offer various advantages: uniform information flow, traceability of process progress, and enhanced analyzability. While these represent initial benefits from the digitalization of the process, a recurring evaluation and optimization of the process are required to sustain and improve process efficiency. For both non-digitalized and digitalized processes, the challenges for process owners are comparable. However, for digitalized processes, convenient tools facilitate process modifications. Particularly no-code digitalized processes exploit the opportunity for quick and agile process adaption with low efforts but require a structured and systematic method to ensure a quality-driven approach. This paper conceptualizes a rule-based decision support model for process improvement that takes advantage of digital traces recorded during process execution of digitalized processes. On the one hand, process mining techniques support data analysis and assist the extraction of process performance indicators as precursors to predict low process performance. On the other hand, process experts compile a list of recommendations for action in workshops and interviews to counteract low process efficiency. The approach to rule-based decision support developed in the scope of this research merges these two dimensions and constitutes an assistive tool for the continuous improvement of digitalized processes. Initial results of the model in practical application support this assessment and demonstrate further research needs. © 2022 The Authors. Published by Elsevier B.V.
147	Creating values for citizens, businesses, as well as governments is the mission for launching e-government strategies and services. The effectiveness of e-government strategies depends heavily on the cause-and-effect relationships among strategic objectives, action plans, as well as performance outcomes identified and specified during the strategy formulation, project implementation, and performance measurement processes. The goal of this paper is to propose a value-based strategic management framework and process for supporting efficient and effective planning, implementation, as well as evaluation of e-government strategies. In the proposed process, concepts and methodologies including the balanced scorecard, strategy map, and strategy gap are adapted and integrated to illustrate the constructs, activities, and procedures of e-government strategic management.
148	Enterprise telesales is most different from consumer sales by having a prolonged sales cycle, in weeks or months, in order to integrate various internal supports to validate and satisfy complex client demands and needs. Managers of such telesales centers are often challenged by the elaborate tasks of tracking the subtle progress of these pipelines of sales opportunities. Thus, an on-demand dashboard for the managers as well as the telesales representatives is a critical IT tool to address this unique problem. This paper provides insights into the Business Performance Management (BPM), a technology used in business intelligence to enable users to observe, analyze, and act upon the information at the right time. To describe a sales cycle and the tracking needs, we start with a set of Key Performance Indicators (KPIs) for a staged pipeline progression model. Based on business rules and threshold conditions for these KPIs, sets of business situations and alerts are generated for presentation. Finally, a hierarchical design is explained with drilldown capabilities for a typical reporting structure of a telesales center. The productivity of an IBM telesales center under such proactive management has been found to be six to seven times more cost effective than traditional field sales. © 2006 IEEE.
149	This paper proposes a new concept of simulation modeling for business process innovation, which is referred to as improved aspect-oriented modeling approach (i- AOMA). The model efficiently supports the design and analysis of business process management and modeling (BPMM). The i-AOMA includes two modeling approaches such as object-oriented and aspect-oriented and merges the code and data into an indivisible object. In this paper, modeling elements and performance measures of simulation models based on the i-AOMA are defined and the improved performance of systems is verified. The modeling based on the i-AOMA supports the easy generation of lots of alternative processes to meet simulation requirements such as performance and efficiency of the model in real case studies. © 2012 ICIC International.
150	The management of business processes in modern times is rapidly shifting towards being evidence-based. Business process evaluation indicators tend to focus on process performance only, neglecting the definition of indicators to evaluate other concerns of interest in different phases of the business process lifecycle. Moreover, they usually do not discuss specifically which data must be collected to calculate indicators and whether collecting these data is feasible or not. This paper proposes a business process assessment framework focused on the process redesign lifecycle phase and tightly coupled with process mining as an operational framework to calculate indicators. The framework includes process performance indicators and indicators to assess whether process redesign best practices have been applied and to what extent. Both sets of indicators can be calculated using standard process mining functionality. This, implicitly, also defines what data must be collected during process execution to enable their calculation. The framework is evaluated through case studies and a thorough comparison against other approaches in the literature. © 2017 Elsevier B.V.
151	Recently, the growth of outpatient clinic capacity has not matched the increasing demand on outpatient clinics, which has led to long waiting times for patients and overtime work for clinic staff. This has three significant negative effects on patients and staff: (1) patients' distrust of the procedures for treating outpatients increases, (2) nurses' stress from patient complaints increases, and (3) doctors' pressure to shorten treatment times while maintaining high levels of service quality increases. Presented in this paper is a simulation-based operation management method that provides the stakeholders with future visibility in outpatient departments. The future visibility is obtained from the current situation of the outpatient department using a simulation-based scheduling system and is shared by a business process management system that informs patients of their expected waiting time in order to lower the workload and pressure on clinic staff and to allow staff to manage exceptions proactively.
152	Purpose: The purpose of this paper is to identify the fundamentals of a performance measurement system (PMS), in order to ascertain if they satisfy the measurement requirements of business process management (BPM) by means of a systematic review of the literature. Design/methodology/approach: The paper uses meta-analysis to systematically review and examine existing BPM and PMS from the business, non-business and public sectors. A specific methodology using categorization concept was used to select the appropriate articles. In total, 42 relevant articles are selected and later analyzed. A subsequent content analysis of the information obtained is applied to identify the gaps in the current literature. Findings: The growing interest in PMS has produced an extraordinarily large numbers of papers on the topic. This paper found that, by and large, the PMS as advocated by various authors for over 20 years (since 1990) failed to fulfill the measurement requirements of BPM. This is alarming, considering that past critics of PMS have indicated that the weaknesses of PMS in relation to BPM applied only in isolated or specific situations such as information technology (IT). These findings dispel the notion that a PMS is a prerequisite to the introduction of an effective BP in organizations. Practical implications: This paper has identified the gaps (weaknesses) of current PMS in meeting the measurement requirements of BPM. This paper proposes a theoretical integrated framework which encompasses a management system, that combines with a measurement system and business processes, and which can be implemented using the popular value-chain methodology to measure and compare performance within BP organizations. Originality/value: The results presented contribute towards providing an updated overview of the current state of research into PMS and its relevance to BPM, in order to identify existing research gaps, issues and concerns upon which ongoing and future research efforts on this topic can be built. © Emerald Group Publishing Limited.
153	Much legal evidence is being generated by and stored in information systems. In this paper we look at evidence from an auditing point of view. Auditors rely on evidence of the party being audited, who may have a legitimate or illegitimate interest to manipulate it. To assess the quality of audit evidence, we argue for an approach called model-based auditing. It is based on a mathematically precise model of the expected relationships between the flow of money and the flow of goods or services. Such equations are used for cross verification. If the equations do not hold, either something is wrong (violation) or some underlying assumption is false (exception). To show the usefulness of the approach, we look in particular at a case study of a legal dispute about automated contract monitoring. A precise revenue model is instrumental in demonstrating that the data set does indeed constitute appropriate evidence to settle the case.
154	nan
155	Having successfully implemented the first phases of their Business Process Management (BPM) initiatives a number of organisations are just now facing the next big challenge: Maintaining the just gained flexibility through continuously measuring and improving their processes' performance. Although numerous approaches are available there is evidence that companies face severe difficulties in aligning their process-related measurement needs with the appropriate information technology (IT). This study presents and analyses the results of an extracting multiple case study. A framework of four patterns derived in the course of the analysis gives new insights in ways to design business-IT alignment in the context of process performance measurement.
156	Abstract In order to improve transparency and stabilise health care costs, several countries have decided to reform their healthcare system on the basis of diagnosis-related groups (DRG). DRGs are not only used for classifying medical treatments, but also for case-based reimbursement, hence induce active competition among hospitals, forcing them to become more efficient and effective. In consequence, hospitals are investing considerably in process orientation and management. However, to date there is neither a consensus on what capabilities hospitals need to acquire for becoming process-oriented, nor a general agreement on the sequence of development stages they have to traverse. To this end, this study proposes an empirically grounded conceptualisation of process management capabilities and presents a staged capability maturity model algorithmically derived on the basis of empirical data from 129 acute somatic hospitals in Switzerland. The five capability maturity levels start with ‘encouragement of process orientation’ (level 1), ‘case-by-case handling’ (level 2), and ‘defined processes’ (level 3). Ultimately, hospitals can reach the levels ‘occasional corrective action’ (level 4) and ‘closed loop improvement’ (level 5). The empirically derived model reveals why existing, generic capability maturity models for process management are not applicable in the hospitals context: their comparatively high complexity on the one hand and their strong focus on topics like an adequate IT integration and process automation on the other make them inadequate for solving the problems felt in the hospital sector, which are primarily of cultural and structural nature. We deem the proposed capability maturity model capable to overcome these shortcomings.
157	Business processes are the means by which organizations create value. Consequently, organizations need to continuously monitor and control their processes' performance so as to provide a consistent and predictable execution quality. A number of today's organizations, however, appear to encounter difficulties with measuring and improving their processes' performance. In this paper, we set out to identify the gap between how organizations currently approach process performance management (PPM) and what they are striving to realize in the future. The systematic gap analysis results in a set of design factors that are valuable in guiding future design efforts for useful and relevant PPM solutions.
158	Thermal comfort inside buildings is a well-studied field where human judgment for thermal comfort is collected and may be used for automatic thermal comfort estimation. However, indoor scenarios are rather static in terms of thermal state changes and, thus, cannot be applied to dynamic conditions, e.g., inside a vehicle. In this work, we present our findings of a gap between building and in-vehicle scenarios regarding thermal comfort estimation. We provide evidence by comparing deep neural classifiers for thermal comfort estimation for indoor and in-vehicle conditions. Further, we introduce a temporal dataset for indoor predictions incorporating 31 input signals and self-labeled user ratings by 18 subjects in a self-built climatic chamber. For in-vehicle scenarios, we acquired a second dataset featuring human judgments from 20 subjects in a BMW 3 Series. Our experimental results indicate superior performance for estimations from time series data over single vector input. Leveraging modern machine learning architectures enables us to recognize human thermal comfort states and estimate future states automatically. We provide details on training a recurrent network-based classifier and perform an initial performance benchmark of the proposed dataset. Ultimately, we compare our collected dataset to publicly available thermal comfort datasets.
159	nan
160	Business processes require continuous changes or interventions to remain efficient and competitive over time. However, implementing these changes-such as reordering or adding new tasks- can negatively affect the overall process performance. A longstanding problem in Business Process Management is that of forecasting ex-ante the values that process performance measures will assume after implementing changes. To achieve this, the concept of Digital Process Twins, which extends the well-established Digital Twin paradigm, paves the way for new interesting opportunities. Digital Process Twins enable enhanced what-if analysis by virtually predicting process performance under various changes, thus allowing for informed decision-making before actuating process changes in the real world. However, despite recognition as one of the new key enablers of modern process re-engineerization, a comprehensive approach to implementing Digital Process Twins is still lacking. This paper proposes a novel conceptual architecture for deploying Digital Process Twins to address this gap. Additionally, we introduce Dolly, a framework that implements such conceptual architecture using a multi-modeling approach combining domain data and process modeling along with a data-driven process simulation technique. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
161	This paper is part of a major research in Business Process Management (BPM). There are international publications that identify the evolution of this area and practical challenges in several perspectives. This paper contributes with a comprehensive survey that identifies, from a Brazilian perspective, the evolution of the academic interest and the practical challenges of the national organizations. The expected results are, first, that this work can provide evidences to answer our research question: What are the issues BPM in Brazil? In addition, we expect to contribute with an approach and instruments that can be applied in the future in a new evaluation, following the same process of this research. This first part presents the results of a key concerns classification of all the papers presented in a Brazilian's Conference: the Workshop of Business Process Management. With this first part, we aim to contribute by showing and discussing what are the academy keys concern and compare it with the BPM International Conference.
162	This article proposes an approach for real-time monitoring of risks in executable business process models. The approach considers risks in all phases of the business process management lifecycle, from process design, where risks are defined on top of process models, through to process diagnosis, where risks are detected during process execution. The approach has been realized via a distributed, sensor-based architecture. At design-time, sensors are defined to specify risk conditions which when fulfilled, are a likely indicator of negative process states (faults) to eventuate. Both historical and current process execution data can be used to compose such conditions. At run-time, each sensor independently notifies a sensor manager when a risk is detected. In turn, the sensor manager interacts with the monitoring component of a business process management system to prompt the results to process administrators who may take remedial actions. The proposed architecture has been implemented on top of the YAWL system, and evaluated through performance measurements and usability tests with students. The results show that risk conditions can be computed efficiently and that the approach is perceived as useful by the participants in the tests. © 2013 Elsevier Inc.
163	Purpose: This paper aims to argue that the polarization index (φ) represents a valid loyalty measure for evaluating changes over time. Design/methodology/approach: The brand performance measures (BPM) are a valid and useful tool for marketing managers in measuring the loyalty consumers attach, in a single time period, to a product or brand. However, the BPM reflect other attributes and not only loyalty. Over time, what might appear to be a change in loyalty may actually be a change in market size or market share. The polarization index (φ) is not biased in this manner and is more appropriate for evaluating changes over time. The study compares the results obtained with three well known BPM utilised for the analysis of loyalty - the purchase frequency, the share of category requirements and the repeat rate - with those obtained with the φ on the purchases of wine made by Italian consumers in the retail sector over two three-year periods (2003-2005 and 2006-2008). Findings: The study shows that the BPM are a fundamental source of information on the loyalty consumers attach to brands and products at one point in time. However, their strong relationship with market share risks providing results that do not reflect actual trends in loyalty. By comparison, φ provides a valid and useful analysis of the ways in which loyalty evolves over time. Originality/value: Although several researchers have studied the uses of φ on one-year and three-year periods, none observed how the index offers more valid results than the BPM over time. The paper shows that marketing managers should always compare the results obtained with the BPM with those derived from the φ before drawing conclusions on the real loyalty trends of their products and brands. © Emerald Group Publishing Limited.
164	In this position paper we focus on the diversity of sustainability measurements. Based on existing research on performance measurement, we propose a preliminary classification framework summarizing sustainability models and indicators. By describing illustrative examples, we claim that several models and indicators can be distinguished with their own peculiarities. Having such a framework is interesting for both academia and business to structure the range of models and indicators and to ultimately select the appropriate sustainability measurement approach. The proposed framework should be validated by further research. © Springer International Publishing AG 2018.
165	In many application contexts, a business process' executions are subject to performance constraints expressed in an aggregated form, usually over predefined time windows, and detecting a likely violation to such a constraint in advance could help undertake corrective measures for preventing it. This paper illustrates a prediction-aware event processing framework that addresses the problem of estimating whether the process instances of a given (unfinished) window w will violate an aggregate performance constraint, based on the continuous learning and application of an ensemble of models, capable each of making and integrating two kinds of predictions: single-instance predictions concerning the ongoing process instances of w, and time-series predictions concerning the "future" process instances of w (i.e. those that have not started yet, but will start by the end of w). Notably, the framework can continuously update the ensemble, fully exploiting the raw event data produced by the process under monitoring, suitably lifted to an adequate level of abstraction. The framework has been validated against historical event data coming from real-life business processes, showing promising results in terms of both accuracy and efficiency.
166	Business process management (BPM) supports the management and transformation of organizational operations. This paper provides a structured guideline for improving data-based process development within the BPM life cycle. We show how Industry 4.0-induced tools and models can be integrated within the BPM life cycle to achieve more efficient process excellence and evidence-based decision-making. The paper demonstrates how standards of machine learning (CRISP-ML(Q)), BPM, and tools of design science research can support the redesign phases of Industry 4.0 development. The proposed methodology is carried out on an assembly company, where the proposed improvement steps are investigated by simulation and evaluated by relevant key performance indicators. © 2021 CIRP
167	To maintain position as a major milk producer, the Indonesian milk industry should do some business development with the purpose of increasing customer service level. One strategy is to create on time release conditions for finished goods which will be distributed to customers and distributors. To achieve this condition, management information systems of finished goods on time release needs to be improved. The focus of this research is to conduct business process improvement using Business Process Reengineering (BPR). The deliverable key of this study is a comprehensive business strategy which is the solution of the root problems. To achieve the goal, evaluation, reengineering, and improvement of the ERP system are conducted. To visualize the predicted implementation, a simulation model is built by Oracle BPM. The output of this simulation showed that the proposed solution could effectively reduce the process lead time and increase the number of quality releases.
168	Background: Healthcare processes in hospitals, likewise processes in companies or governmental organizations, may accumulate problems and obstacles over time, which consequently cause the processes to become ineffective. BPM (Business Process Management) is an approach to process modeling, improvement and automating, which has been used with great success for process improvement. Methods: This work was to examine the possibility of improving healthcare process by using BPM. To implement BPM ideas, a revised TAD (Tabular Application Development) methodology was developed, representing an important contribution to BPM. The first three phases of the TAD methodology were introduced in a step-bystep approach. The first phase deals with process identification, the second develops the “as-is” model, and the third phase discusses process improvement by developing a “to-be” model. Results: We found that (a) the Surgery process is efficient and well organized; (b) patient stay in the Department could be shortened; however for humane and social reasons the leadership prefers to leave the residence time as it is; (c) the process is associated with some time-consuming activities that are performed by other departments and represent the bottleneck of the process. Conclusions: (a) BPM proved to be a suitable approach to implementing healthcare process improvement; (b) the revised TAD methodology was found to be consistent and efficient in performing BPM approach; (c) the Surgery process was found to be effective and no changes or improvements are needed; (d) concerning time-consuming activities, the leadership decided to discuss this problem with the management of the departments where the activities are carried out. © 2015, Slovene Medical Society. All rights reserved.
169	Virtual Organization (VO) is a network of autonomous organizations sharing their competitive advantage to address a specific business opportunity. Due to their autonomous and interdependent nature, management of collaboration among such organizations is a challenging task. In this paper, we present a framework for process management in service oriented virtual organizations. We propose 6 layers for the framework with multiple components within each layer. In designing the components of the framework, standard reference architecture such as Open-EDI reference model and the S3 service oriented architecture, as well as best practices such as ITIL V3 and PMBOK are used. Further, we present a distributed SOA infrastructure that facilitates peer-to-peer collaboration between organizations in a virtual organization. The infrastructure is based on creating specific service zone for each participating organization to build a virtual ESB. Compared to collaborative environment in networked organization usually supported by computer networks, the loose coupling of services, and the autonomous characteristics of service oriented architecture make it one the best approaches for implementing virtual organization.
170	Big Data is both an advantage and a challenge due to the explosive increase in the volume of large data sets. Big Data analysis derives knowledge to improve business processes and can be critical in decision making. However, for this purpose, the right strategies need to be implemented. This document provides an overview of the key concepts, issues and challenges in integrating big data with business processes.
171	Process oriented approach in quality management system has been introduced with ISO9001:2000. The international standard promotes the adoption of a process approach when developing, implementing and improving the effectiveness of a QMS to enhance customer satisfaction by meeting customer requirement. The advantage of process approach is to link all parties in scope of business of the organization from suppliers, internal departments of organization to gather to make B2B communication and integration. In this paper, the process approach is defined based on QMS requirement. Supply department was proposed for implementation of process. Purchasing process was designed as a linkage between supplier and internal company departments. Performance indicators were developed and measured accordingly. It shows that process management can improve delivery capability, quality and monitor price of supplied parts by suppliers. © (2013) Trans Tech Publications, Switzerland.
172	This research paper aims to discover research opportunities in business process management and performance measurement from a constructivist view. The nature of this research is exploratory and descriptive, and the research method was performed in a qualitative way. The process narrowed down 2142 articles, gathered from a search of scientific databases, and identified 16 articles that were relevant to the research and highly cited. The analysis found that most of the articles follow the realistic approach, and there is a need to analyse the decision-making process in an individual manner. The measurement criteria are identified by searching the scientific literature, in most cases using an ordinal scale without any integration process to present the results to the decision-maker. Regarding the management aspects, most of the articles do not follow a structured process to measure the current situation and generate improvement opportunities. © 2016 John Wiley & Sons, Ltd.
173	Background. Healthcare managers often attempt to enhance process-oriented performance. However, this remains a challenge. New approaches aimed at increasing the implementation success of process-oriented performance measurement should be investigated. Methods. This study investigates and discusses a step-by-step methodology to implement an automated and effective process-oriented performance measurement system in a hospital. The methodology is based on a framework for developing dashboards based on three steps: the demand side, supply side, and the fit between the two. An illustrative case of the process of hip surgery in the operating room of two hospitals is used. Results. A methodology has been developed to define a reliable set of process-oriented performance metrics, allowing analysis and management of the different flows in healthcare in an integrated way, several methods were investigated to automatically integrate the data gathered into a reporting infrastructure that can be used to disseminate the results. Conclusion. This step-by-step methodology allows healthcare organizations to develop and implement effective process-oriented performance measurement in an automated way. This allows the alignment of the goals of hospital management and various stakeholders with the more analytical analysis of business process management notation and hospital information system (HIS) data. © 2018, © 2018 Taylor & Francis Group, LLC.
174	Process modelling is often criticized as lacking proper alignment with business goals. Although there is literature on different proposals to address the issue, the verification of this alignment remains an obstacle during process enactment. We make use of key process indicator (KPI) in a process design method to annotate processes/activities with proper information. The method derives this information from the business goals and uses it to calculate process indicators. We demonstrate through a real example, modelled with the ARIS business process model tool, how the method produces proper indicators, which should be used during process enactment. © Copyright 2017 by SCITEPRESS - Science and Technology Publications, Lda.
175	The number of mobile devices, such as smartphones and smartwatches, is relentlessly increasing, to almost 6.8 billion by 2022, and along with it, the amount of personal and sensitive data captured by them. This survey overviews the state of the art of what personal and sensitive user attributes can be extracted from mobile device sensors, emphasizing critical aspects such as demographics, health and body features, activity and behavior recognition, and so forth. In addition, we review popular metrics in the literature to quantify the degree of privacy and discuss powerful privacy methods to protect the sensitive data while preserving data utility for analysis. Finally, open research questions are presented for further advancements in the field.
176	A key aspect in any process-oriented organisation is the measurement of process performance for the achievement of its strategic and operational goals. Process Performance Indicators (PPIs) are a key asset to carry out this evaluation, and, therefore, the management of these PPIs throughout the whole BP lifecycle is crucial. In this demo we present PPINOT Tool Suite, a set of tools aimed at facilitating and automating the PPI management. The support includes their definition using either a graphical or a template-based textual notation, their automated analysis at design-time, and their automated computation based on the instrumentation of a Business Process Management System. © 2013 Springer-Verlag.
177	Process Performance Indicators (PPIs) are a key asset for the measurement of the achievement of strategic and operational goals in process-oriented organisations. Ideally, the definition of PPIs should not only be unambiguous, complete, and understandable to non-technical stakeholders, but also traceable to business processes and verifiable by means of automated analysis. In practice, PPIs are defined either informally in natural language, with its well-known problems, or at a very low level, or too formally, becoming thus hardly understandable to managers and users. In order to solve this problem, in this paper, a novel approach to improve the definition of PPIs using templates and ontology-based linguistic patterns is proposed. Its main benefits are that it is easy to learn, promotes reuse, reduces ambiguities and missing information, is understandable to all stakeholders and maintains traceability with the process model. Furthermore, since it relies on a formal ontology based on Description Logics, it is possible to perform automated analysis and infer knowledge regarding the relationships between PPI definitions and other process elements. © 2012 Springer-Verlag.
178	A key aspect in any process-oriented organisation is the evaluation of process performance for the achievement of its strategic and operational goals. Process Performance Indicators (PPIs) are a key asset to carry out this evaluation, and, therefore, having an appropriate definition of these PPIs is crucial. After a careful review of the literature related and a study of the current picture in different real organisations, we conclude that there not exists any proposal that allows to define PPIs in a way that is unambiguous and highly expressive, understandable by technical and non-technical users and traceable with the Business Process (BP). In addition, like other activities carried out during the BP lifecycle, the management of PPIs is considered time-consuming and error-prone. Therefore, providing an automated support for them is very appealing from a practical point of view. In this paper, we propose the PPINOT metamodel, which allows such an advanced definition of PPIs and is independent of the language used to model the business process. Furthermore, we provide an automatic semantic mapping from the metamodel to Description Logics (DL) that allows the implementation of design-time analysis operations in such a way that DL reasoners' facilities can be leveraged. These operations provide information that can assist process analysts in the definition and instrumentation of PPIs. Finally, to validate the usefulness of our proposal, we have used the PPINOT metamodel at the core of a software tool called the PPINOT Tool Suite and we have applied it in several real scenarios. © 2012 Elsevier Ltd.
179	Process performance indicators (PPIs) allow the quantitative evaluation of business processes, providing essential information for decision making. It is common practice today that business processes and PPIs are usually modelled separately using graphical notations for the former and natural language for the latter. This approach makes PPI definitions simple to read and write, but it hinders maintenance consistency between business processes and PPIs. It also requires their manual translation into lower-level implementation languages for their operationalisation, which is a time-consuming, error-prone task because of the ambiguities inherent to natural language definitions. In this article, Visual ppinot, a graphical notation for defining PPIs together with business process models, is presented. Its underlying formal metamodel allows the automated processing of PPIs. Furthermore, it improves current state-of-the-art proposals in terms of expressiveness and in terms of providing an explicit visualisation of the link between PPIs and business processes, which avoids inconsistencies and promotes their co-evolution. The reference implementation, developed as a complete tool suite, has allowed its validation in a multiple-case study, in which five dimensions of Visual ppinot were studied: expressiveness, precision, automation, understandability, and traceability. © 2017, The Author(s).
180	Process performance management (PPM) aims at measuring, monitoring and analysing the performance of business processes (BPs), in order to check the achievement of strategic and operational goals and to support decision-making for their optimisation. PPM is based on process performance indicators (PPIs), so having an appropriate definition of them is crucial. One of the main problems of PPIs definition is to express them in an unambiguous, complete, understandable, traceable and verifiable manner. In practice, PPIs are defined informally – usually in ad hoc, natural language, with its well-known problems – or they are defined from an implementation perspective, hardly understandable to non-technical people. In order to solve this problem, in this article we propose a novel approach to improve the definition of PPIs using templates and linguistic patterns. This approach promotes reuse, reduces both ambiguities and missing information, is understandable to all stakeholders and maintains traceability with the process model. Furthermore, it enables the automated processing of PPI definitions by its straightforward translation into the PPINOT metamodel, allowing the gathering of the required information for their computation as well as the analysis of the relationships between them and with BP elements. © 2014 Taylor & Francis.
181	nan
182	Service Level Agreements (SLA) for multi-service Information Technology (IT) outsourcing contracts contain vast amounts of textual information. The SLAs provide details about a specific service, Key Performance Indicators (KPI) to measure its performance; as well as process elements, such as activities, events, and resources that are integral in achieving performance goals. However, KPIs and the process elements may be interrelated. The knowledge of such interrelationships is often tacitly present in the SLAs. The aim of our research is to extract this hidden information from IT service contracts and analyze them to empower customers of IT services to make better performance management and incentive decisions. We apply an Ontology- Based Information Extraction (OBIE) approach in developing a prototype decision support framework, named SLA-Miner. The results, obtained from analyzing a set of Industry SLAs, demonstrate the utility of SLA-Miner in identifying KPI interrelationships, deficiencies, and impacts of various process elements on individual KPIs.
183	Healthcare is a core area for governments, increasingly interested in improving facilities to the population with fewer resources. In fact, hospitals are facing to lack of resources, long wait times, overuse of emergency services. We focus on the business analysis of an Emergency Department, by considering a wide methodological framework (BP-M*), to analyze care pathway for patients. The preliminary data analysis on the context suggests main patterns for the arrival of patients, the distribution of urgent cases as well as the typology of discharge. In this step, an UML scheme helps in the understanding of the organization. Then, a decision support framework made of several Key Performance Indicators is performed, including an exam of the cost of different activities, a what-if analysis and simulations. The latter provide information for the re-engineering of the process. As a matter of fact, by running different scenarios, managers have the opportunity to better identify bottlenecks and to explore better performance solutions. © 2017, World Scientific and Engineering Academy and Society. All rights reserved.
184	Littering is an environmental problem that affects citizens' economy, safety, and health. Natural and rural areas are often targets of abandoned littering, while urban areas often accumulate more waste than can be disposed of in a timely manner. Minimizing littering and waste is a critical sustainability challenge requiring the cooperation of different professionals and agencies. In this paper, we report our vision and preliminary proposal for a model-driven approach to address the automated localization and identification of abandoned waste. Our solution envisages the usage of digital process twins to enable the specification of cost-effective and self-adaptive procedures fed by data crowdsourced from the real world.
185	Performance indicators and metrics are essential management tools. They provide synthetic objective measures to monitor the progress of a process, set objectives, and assess deviations, enabling effective decision-making. They can also be used for communication purposes, facilitating the sharing of objectives and results or improving the awareness of certain phenomena, thus motivating more responsible and sustainable behaviors. Given their strategic role, it is of paramount importance, as well as challenging, to guarantee that the intended meaning of an indicator is fully shared among stakeholders and that its implementation is aligned with the definition provided by decision makers, as this is a precondition for data quality and trustworthiness of the information system. Formal models, such as ontologies, have been long investigated in the literature to address the issues. This article proposes a comprehensive survey on semantic approaches aimed to specify conceptual definitions of indicators and metrics, illustrating also the advantages of these formal approaches in relevant use cases and application domains.
186	Little attention has been spent on the adaptation and implementation of theoretical Business Performance Measurement (BPM) models to specific industry and company contexts leading to a limited practical value of such models. This article, aimed at industrialists, reports on research carried out on performance measurement for the metal finishing industry. The purpose of this research was threefold: first, to analyse the interplay of strategy, Management Control Systems (MCS) and BPM to establish linkages between these dimensions; second, to render generic BPM models more readily accessible for practitioners; and third, to develop a BPM design process linking individual industry (in this case, metal finishing) class characteristics to generic BPM models. The BPM design process developed, empirically validated for the metal finishing industry, helps to narrow the gap between theory and practice in MCS and BPM. Future research should be able to apply the concept to other industry classes. Industrial practitioners can use our BPM design process for implementing a suitable BPM model within their management control systems and industry context. © 2019, © 2019 Institute of Materials Finishing Published by Taylor & Francis on behalf of the Institute.
187	The goal of operational Business Intelligence (BI) is to help organizations improve the efficiency of their business by giving every "operational worker" insights needed to make better operational decisions, and aligning day-to-day operations with strategic goals. Operational BI reporting contributes to this goal by embedding analytics and reporting information into workflow applications so that the business user has all required information (contextual and business data) in order to make good decisions. EII systems facilitate the construction of operational BI reports by enabling the creation and querying of customized virtual database schemas over a set of distributed and heterogeneous data sources with a low TCO. Queries over these virtual databases feed the operational BI reports. We describe the characteristics of operational BI reporting applications and show that they increase the complexity of the source to target mapping defined between source data and virtual databases. We show that this complexity yields the execution of "mega queries", i.e., queries with possible a 1,000 tables in their FROM clause. We present some key optimization methods that have been successfully implemented in SAP Business Objects Data Federator system to deal with mega queries.
188	Supply chain transformation is an emerging service area in the market which aims at helping clients improve their operational efficiency and reduce costs. As a generic technique for the analysis of complex and dynamic systems, simulation could play an important role in this field. This paper presents a case study showing how simulation could be the key enablement for a supply chain transformation project. A methodology and tool developed by IBM China Research Lab has been applied in this joint project with a world-class supplier of home improvement tools. By applying simulation, the client is provided an insightful view about their business processes and inventory allocation strategy, which serves as the basis for the transformation implementation. Financial results show that simulation has addressed the key issues and provided the client accountable evaluation results for decision-making.
189	The IBM Supply-chain Network Optimization Workbench (SNOW) is a software tool that can help a company make strategic business decisions about the design and operation of its supply chain network. The tool supports supply chain analysis with integrated network optimization and simulation capability. Mathematical programming models are used to first help identify some cost-effective scenarios from a large number of candidates. Optimization results are then converted to simulation models automatically for more detailed analysis with taking into account operational policies and uncertainties. The tool was applied to analyze both IBM's internal supply chains and external clients' supply chains. The combination of optimization and simulation demonstrates great value in real business cases.
190	As next-generation experimental and observational instruments for scientific research are being deployed with higher resolutions and faster data capture rates, the fundamental demands of producing high-quality scientific throughput require portability and performance to meet the high productivity goals. Understanding such a workflow's end-to-end performance on HPC systems is formidable work. In this paper, we address this challenge by introducing a Workflow Roofline model, which ties a workflow's end-to-end performance with peak node- and system-performance constraints. We analyze four workflows: LCLS, a time-sensitive workflow that is bound by system external bandwidth; BerkeleyGW, a traditional HPC workflow that is bound by node-local performance; CosmoFlow, an AI workflow that is bound by the CPU preprocessing; and GPTune, an auto tuner that is bound by the data control flow. We demonstrate the ability of our methodology to understand various aspects of performance and performance bottlenecks on workflows and systems and motivate workflow optimizations.
191	Productivity increases in administration remained partially untapped during recent years. At the same time, the pressure on existing professions is being exacerbated by demographic trends in industrialized countries. This reveals the potential offered by process automation in the administrative area. Technological progress can help to overcome this situation. In the recent past, Robotic Process Automation (RPA), automating simple and rule-based tasks, gained traction. RPA alone is not sufficient for more complex tasks. Therefore, supplementing or substituting AI-based technologies such as Machine Learning up to fully autonomous AI solutions, which we refer to as Intelligent Automation at its highest level, can be adopted. While RPA is regarded as an established technology, Intelligent Automation is still in its infancy. Therefore, research on successful practical examples is necessary for its dissemination. To this end, this paper conducts a qualitative multiple case study analysis based on guided semi-structured interviews aiming to identify success factors in the adoption of Intelligent Automation. To unravel the key factors, a framework comprising 45 success factors is introduced. This framework, along with its novelty to the scientific community, has the potential to facilitate practical implementation of Intelligent Automation. Yet, our investigation revealed that the identified use cases in the analyzed companies haven't reached the maturity level expected for Intelligent Automation. Consequently, the findings pertain to the early stages of Intelligent Automation development. This study distinguishes itself from prior research by incorporating additional cases from various institutions and sectors, utilizing a study design rooted in a broader scientific knowledge base. Given that a limited number of companies could be recruited despite extensive systematic acquisition efforts, this subject area deserves further research efforts.
192	In today's global business environment, the importance of customer service, cost-competitiveness, and quality are key factors in determining an organization's success, or undesirable failure. Organizations try to optimize their processes to maximize their profits and make the very process faster. Users usually work with documents in the process. Working with documents makes the process more slowly, since the documents are important to be scanned and attached to the form. This work presents the optimization of such processes. It is achieved by automatic integration of Business Process Management and Electronic Document Management Systems. Improvements and results achieved by proposed integration are presented in this research. The model that is created enables monitoring of defined Key Performance Indicators in the identification process of the bottlenecks in the process. The process can be optimized by increasing the number of resources on the activities that are a bottleneck in the process. Such a solution has been tested in the process of opening a bank account. © 2016 IEEE.
193	Business process management is the process of modifying or adjusting an organization's business process in order to achieve higher productivity or lower costs. Each company or organization has a value creating process that usually involves people, machines and information. One of the main problems with such processes is that it is very difficult to predict how much of each resource is actually needed. In light of the above, the objective of this paper is to implement a methodology that is capable of optimizing the allocation of resources to tasks in a given business process. In this paper, the genetic algorithm was used for optimization. The idea is that once the units are properly presented, the optimal schedule of users should be determined using the genetic algorithm. The fitness function includes Key Performance Indicators of process: waiting time and cost of the resource. Since al the users are not qualified in performing all the tasks in the process, the algorithm has to consider minimal and the maximal available number of users for each activity. The usability of this approach is tested in the process of credit requirement. Finally, the results are compared to the current work process. © 2016 IEEE.
194	Organizations use business process management to identify opportunities to reduce costs, increase service or product quality, etc. In this paper, a way to improve businesses processes using process mining techniques and standard methods of businesses process improvement is presented. Process mining has been used to fix the disadvantages of the existing standard methods. The presented approach is tested on a real process. After the process model is acquired using process mining analysis, business process improvement is proposed through a detailed analysis. Also, key performance indicators which are used to measure process performances, and a process model with a new resource allocation, which is improved from the aspect of the predefined key performance indications, is proposed. The experimental results have shown how the process can be improved with a better resource allocation. © 2017 IEEE.
195	In order to adapt to ever-changing customer needs and satisfy them, good Business Process Management (BPM) in Small and Medium-sized Enterprises (SMEs) is crucial. The target group of this research is production SMEs whose BPM can be monitored respecting the values of key performance indicators (KPIs). This paper shows how improving the performance of the observed business processes can improve the level of customer satisfaction. This improvement should lead to the sustainability of SMEs in the market. In this paper, evaluation of business processes performance is defined as a multi-criteria decision problem. The relative importance of considered KPIs and their imprecise values are described by linguistic expressions, which are then modeled by triangular in-tuitionistic fuzzy numbers (TIFNs). Calculation of KPI weights is done by using the fuzzy analytic hierarchy process (FAHP). Evaluation of BPM success is conducted respecting the obtained KPI weights and KPI values. An optimal solution for BPM success improvement, respecting customer satisfaction indicators, is calculated using the Artificial Neural Network (ANN) and Genetic Algorithm (GA) approaches. By applying the proposed model, managers of production SMEs can deter-mine the management initiatives that will improve their business and the sustainability of their companies. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.
196	Today's successful IT service providers need to continuously improve the transparency of their service provision. The selection and negotiation of key performance indicators is an important component in establishing transparency. In this workshop contribution we aim at characterizing the role of key performance indicators in management system, in general, and IT service management systems, in particular. We discuss the theoretical background of process-oriented quality management systems, i.e., the management school of cybernetic feedback-control systems. We express our opinion that a purely mechanical application of quality management systems comes at the risk of misunderstanding or overlooking important parts of the functioning of a successful enterprise. Against the background of these findings we can understand mainstream IT governance and IT service management systems as process-oriented quality management systems. As part of the discussion, we reconsider the mainstream IT planning instruments of total cost of ownership and total economic impact and extend them by a means to incorporate probabilistic risk assessment.
197	During the operation phase of a virtual enterprise (VE) different kinds of unexpected problems usually take place and they should be properly handled in order to keep the VE goals. However, the nature of a VE imposes new requirements as decisions should be taken in a distributed and decentralised manner due to members' autonomy and independence. Besides quality, agility in the decision-making is a must to guarantee success. For that, this paper presents a framework that provides a supporting methodology for guiding VE members along the diverse steps in the problem resolution, including assistance in their discussion. The framework relies on Business Process Management (BPM) and Service Oriented Architecture (SOA) approaches, and the methodology on project management reference models (focused on changes management). A discussion about the problem is driven by a semi-automated protocol conducted by a Distributed Collaborative Decision Support System for the Management of VE Evolution (DSS-VE). The protocol delineates a sequence of steps to be taken but is flexible to cope with partners' heterogeneity and VE uniqueness. The impact of decisions can be evaluated via a distributed toolbox, containing a set of techniques for performance measurement and evaluation analysis.
198	nan
199	nan
200	Organizations aim to achieve operational excellence to reduce costs and improve the quality of their business processes. Business process management (BPM) enables continuous improvement of business processes. Business process management systems (BPMS) serve as an entry point to BPM activities and afford firms to manage, execute, and automate business processes. This study follows an action design research approach to design a BPMS in use together with a medium-sized German fashion company. We concurrently evaluated the artifact-in-use by tracking performance indicators that are aligned with the company’s objective. As a result of our formalization of learning, we propose seven design principles for using BPMSs to achieve continuous improvement of business processes. These design principles comprise user management, process modeling, automation, logging, monitoring, integration, and case handling. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.
201	nan
202	Purpose - Extensive literature on business process management suggests that organisations could enhance their overall performance by adopting a process view of business. However, there is a lack of empirical research in this field. The purpose of this paper is to investigate the understanding of the process view and process maturity levels in a transition economy and to test the impact of process orientation maturity level on organisational performance. Design/methodology/approach - Empirical investigation combined an exploratory-confirmatory approach using factor analysis and structural equation modelling. Findings - The investigation confirms the impact of business process orientation on organisational performance in a transition economy. The link is even stronger than in the original investigation. The results show that business process orientation leads to better non-financial performance and indirectly to better financial performance. Practical implications - The research confirms that business process orientation is advantageous for companies since it has a positive influence on organisational performance. The finding that the impact on financial performance is indirect through non-financial performance suggests that the companies have to take that view of performance into consideration as well. Originality/value - The paper is valuable for academics and practitioners because the impact of business process orientation on organisational performance has been confirmed for a transitional economy. Its originality is in the measurement of organisational performance, for which a more detailed specification of organisational performance based on the balanced scorecard concept that includes non-financial performance measures has been used. © Emerald Group Publishing Limited.
203	Performance evaluation and execution management of service-oriented workflows became quite important in order to avoid performance degradation. Performance measurement is crucial to ensure that workflow execution remains feasible and that SLA violations due to overload are avoided. Network calculus as a well-known system theory for deterministic queuing systems can be used to describe the worst-case performance behavior of a workflow in order to plan workflow control in advance. Concerning business processes with high repetition rates the workflow controller has to be able to serve all incoming requests with an optimal composition of Web services. Thus, this paper presents a formal worst-case calculation model using the concepts of network calculus. Furthermore, optimization problems based on the worst-case scenario are introduced in order to minimize the worst-case delay and to maximize the throughput of the Web services invoked with minimal costs.
204	One major challenge for service-oriented workflows in digital ecosystems is capacity planning for cross-organizational Web service workflows in order to avoid performance degradation. In order to analyze the execution capacity of Web service workflows and to plan the workflow control, queuing theory can be used to describe the average performance behavior of a workflow. By addressing capacity planning of Web service workflows, resource usage becomes more and more important. Capacity planning and performance measurement are crucial to ensure that the workflow execution remains feasible and SLA violations due to overload are avoided. Thus, this paper presents a capacity planning approach for Web service workflows based on queuing theory to support capacity planning decisions. Further we describe an optimization algorithm how to achieve an optimal utilization of the invoked Web services at minimal costs.
205	Software industry has been shifting from traditional, plan-based software development to agile software development. Agile seems able to prescribe on how to develop a working software faster, but is still unable to give answer what product should be developed. This paper aims to investigate why large companies should adopt Lean startup to seek for radical innovation. This understanding could be used as a basis to confront disruptive innovation where the problem and the solution are both unknown. A single case study was conducted in a large software company. Eight practitioners with different roles were interviewed. We identified the characteristics of internal startups and the lessons learned on practising Lean Startup inside the large software company.
206	Abstract In recent years, process mining has emerged as the leading big data technology for business process analysis. By extracting knowledge from event logs in information systems, process mining provides unprecedented transparency of business processes while being independent of the source system. However, despite its practical relevance, there is still a limited understanding of how organizations act upon the pervasive transparency created by process mining and how they leverage it to benefit from increased process awareness. Addressing this gap, this study conducts a multiple case study to explore how four organizations achieved increased process awareness by using process mining. Drawing on data from 24 semi-structured interviews and archival sources, this study reveals seven sociotechnical mechanisms based on process mining that enable organizations to create either standardized or shared awareness of sub-processes, end-to-end processes, and the firm’s process landscape. Thereby, this study contributes to research on business process management by revealing how process mining facilitates mechanisms that serve as a new, data-driven way of creating process awareness. In addition, the findings indicate that these mechanisms are influenced by the governance approach chosen to conduct process mining, i.e., a top-down or bottom-up driven implementation approach. Last, this study also points to the importance of balancing the social complications of increased process transparency and awareness. These results serve as a valuable starting point for practitioners to reflect on measures to increase organizational process awareness through process mining.
207	The bullwhip effect (BWE), a well-known phenomenon in supply chain management since it was first identified in 1958, is causing significant economic damage after disruptions. While the role of human factors in BWE has been widely recognized, however, the impact of different replenishment policies on BWE mitigation has not been thoroughly investigated. This paper presents a study on the impact of reach-based Kanban systems on the BWE in supply chains containing suppliers with intrinsically non-reducible long cycle times, such as those in the semiconductor industry. Our findings suggest that a reach-based replenishment system acts as a BWE accelerator after significant disruptions, which can end up in line downs downstream. We propose a change to absolute stock targets for replenishment policies during disruption to mitigate this aspect of the BWE root cause for supply chain with long cycle time suppliers to reduce the risk of line downs.
208	Organizations always need to continually improve and review their critical business processes (BP), especially in the healthcare field. This improvement requires an efficient mean to support the management and the analysis of healthcare processes, to collect all relevant indicators designed for both effective management and process improvement and to understand all interesting results based on data instance logs that reflect the performance of business processes. In order to meet these challenges, we propose a novel approach for managing business process performance enabling the evaluation and optimization of BPs. This approach is illustrated through a real case study in the emergency department of “Farhat Hached” hospital in Sousse (Tunisia). © Springer International Publishing AG 2017.
209	In healthcare organizations, decision making is both a crucial and a challenging task. Therefore, it's necessary to collect all relevant indicators designed for both effective management and process improvement. These indicators need to reflect not only the performance of business process but also the satisfaction of patients toward the ED (emergency department). In this paper, we concentrate on the selection of the relevant performance measures related to health care process and illustrate the usefulness of the retained measures through a real case study in the emergency department of "Farhat Hached" hospital in Sousse (Tunisia). Thus, this work contributes to the improvement of the healthcare process and helps managers to optimize its performance. © 2017 The Authors. Published by Elsevier B.V.
210	The continuous process improvement(CPI) needs to take into account the clients feedbacks in order to have more performance in service delivery and quality of production. This paper presents the first elements of a new solution to use the social networks data by measuring key performance indicators (KPI) to improve the quality of business processes(BP). In this work is described the first step to modify the classic BPM lifecycle by adding the SN data. © 2015 IEEE.
211	The aim of this study is to design, build and validate a scale for the measurement of Saudi industrial Organizations' SC Management Practices (SCMP), and also to evaluate its efficiency at various SCM measurements. The analysis identified 20 constructs of (SCMPs) based on a comprehensive literature review; namely Strategic Partnership of Suppliers (SPS), Customer Relationship (CR), Information Sharing (IS), Information Quality (IQ), Postponement (PST), Agreed Vision and Goals (AVG), Sharing of Risks and Rewards (SRR), Lean Manufacturing (LM), Total Quality Management (TQM), Organizational Culture (OC), Information and Communication Technology (ICT), Benchmarking and Performance Measurement (BPM), Agile Manufacturing (AM), Outsourcing (OUT), Just In Time Manufacturing (JIT), Green SC Management (GSCM), Reverse Logistics (RL), Vendor Managed Inventory (VMI), Radio Frequency Identification (RFID), and SC Integration (SCI), and four SCM performance structures in particular namely; Flexibility Perspective (FLP), Efficiency Perspective (EFP), Customer’s Perspective (CSP), Product Innovation Perspective (PIP). A survey tool based on the existing literature was developed and relevant data were collected from 351 Industrial Saudi organizations on this tool. In the data analysis the validation of the instrument is mainly carried out with confirmatory factor analysis in terms of unidimensionality, durability, convergent validity, discriminant validity, nomological validity, and the associated validity criteria. A parsimonious instrument that makes an important contribution to the SCM literature is generated by the results of this research. The instrument will allow an enterprise to incorporate various SCMPs, to keep track of the implementation status, and then to evaluate SCM performance to the SCM dimensions. © 2022 Growing Science Ltd. All rights reserved.
212	Process mining is applied in literature to many case studies in various domains. It represents an explorative procedure, very helpful to the domain experts for analyzing data from multiple perspectives. In this paper, we concentrate on extracting knowledge from event logs related to a health care process that is recorded by a Business Process Management System and mining Key Performance Indicators content associated to process instances data. Thus, this work contributes to the evaluation and the enhancement of the healthcare process using Process mining tool. © 2019 The Authors. Published by Elsevier B.V.
213	Predictive business process monitoring is concerned with predicting the process-related Key Performance Indicators (KPIs) and forecasting the future behavior of the process in realtime. Despite the amount of work contributed by researches to this field of research, the performance of existing solutions is not desirable for practical settings. Indeed, these approaches are typically context-unaware and lack generality. However, in real-life use cases, business processes are not isolated from the surrounding working environment, and thus they are influenced by many contextual events, such as events generated by IoT devices. To the best of our knowledge, there is no comprehensive study addressing the integration of contextual events with the process prediction. This paper proposes a holistic context-Aware methodology for predictive process monitoring by incorporating IoT data. Moreover, we present a systematic method to integrate the contextual events in the runtime process using Business Process Management System} (BPMS) capabilities. We also introduce a predictive model based on Deep Neural Networks (DNN) to forecast the next activity. Finally, we evaluate our solution using a case study in the aviation industry.  © 2020 IEEE.
214	Companies are increasingly embedded in B2B environments, where they have to collaborate in order to achieve their goals. Such collaborations lead to inter-organizational business processes that may be commonly supported through the exchange of electronic data interchange (EDI) messages (e.g., electronic purchase orders, invoices etc.). Despite the appearance of XML, traditional approaches to EDI, such as EDIFACT and ANSI X.12, still play an overwhelmingly dominant role. However, such traditional EDI standards lack a notion of process. In other words, the exchanged business documents are typically not embedded in the context of other exchanged business documents. This has two shortcomings: (1) the inability to apply proven business process management (BPM) methods, including process mining techniques, in such settings; and (2) the unavailability of systematic approaches to business intelligence (BI) using information from exchanged EDI messages. In this article, we present the EDImine Framework for enabling (1) the application of process mining techniques in the field of EDI-supported inter-organizational business processes, and (2) for supporting inter-organizational performance evaluation using business information from EDI messages, event logs and process models. As an enabling technology, we present a method for the semantic preprocessing of EDIFACT messages to exploit this potentially rich source of information by applying state of the art BPM and BI techniques. We show the applicability of our approach by means of a case study based on real-world EDI data of a German consumer goods manufacturing company. © 2015, Springer-Verlag Berlin Heidelberg.
215	nan
216	Business process management (BPM) aims to help organizations manage their business processes. Startups differ from established firms as they go through different phases of prospecting, developing, and exploiting the new venture. Startups begin to focus on the organization of their processes after they reach the exploiting (scale-up) phase. Digital startups are unique as information technology (IT) becomes the business model itself. These unique characteristics raise a question: how do digital startups at the scale-up phase manage their business processes? To answer the question, two case studies on digital startups in logistics providers are conducted. The case studies are designed to be inductive in nature. Grounded Theory Method (GTM) is used for data collection and analysis. Data is collected via interviews and supporting documents. The BPM capability provides the basis to create guiding questions for the interviews. The interview results are analyzed with a grounded theory approach of open, theoretical, and selective coding. To derive a new theory, cross-case analyses are conducted. Findings from two digital startups allow us to identify important categories that play a role in how digital startups manage their activities: industry and stakeholders, digital offerings, organic structure, process management, performance measurement, employee training and culture. We further theorize that the competitive nature of startups makes them customer-centric and focus on agility. Digital startups continuously improve their product and conduct adaptive process experimentation involving a cycle of process identification, IT-based process implementation and process adaptation. The supporting capabilities that enable the process management of digital startups are agile people and culture and organic structure. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
217	This paper illustrates strategies, methods, and techniques that have been successfully utilized to model and deploy collaborative solutions to help teams and individuals within and across companies execute business processes efficiently and consistently, whilst ensuring adherence to norms, standards and agreed guidelines for the benefits of shareholders and contractual parties. Cases are presented related to Integrated Reservoir Management, E&P Technical Information Management, and Surface Rights Management for O&G operations. Whilst some contextual aspects of information technology are mentioned in this paper, the focus rather lies in the aspects of value delivery through process governance, workflow automation efficiencies, process improvement, and reduction of time to learn how things must be done on a day to day basis by newcomers. Business process management (BPM) is a technique that brings efficiency and effectiveness to the execution of processes. Rather than replacing big systems, companies are looking at technologies that facilitate implementing operating processes on a workflow orchestration platform that establishes a controlled environment to execute defined activities efficiently. The convergence of business process modeling, business rules engines, process performance monitoring and human workflows has led to adoption of integrated systems leveraging BPM platform solutions. Wide market availability of BPM platform solutions makes possible chosing from diverse types of architecture, functionality, usability and integration capabilities to meet the information management requirements of an operating company. However, adherence to Business Process Modelling Notation (BPMN) and to data and integration standards, is critical to balance governance of processes with agility and flexibility to adapt workflows, especially in companies that require to scale-up workflows initially created for the needs of one functional or organizational area across and into others. Using standards is critical in cases where collaborative workflows require integration and interaction with data, calculations, and transactions performed in existing back office and/or Petrotechnical systems. Successful BPM implementations are those that become adopted by business users and create incremental value. This requires a systematic approach to process improvement opportunity identification, creating realistic business cases, defining and tracking process performance metrics, communicating value and strategic alignment lead by management, and effective management of change. Copyright 2017, Society of Petroleum Engineers.
218	Medical billing is a long chain of processes that cut across different sectors and institutions, evolving into a multimillion-dollar industry. Despite the emergence of institutional involvement in the practice, the parties involved face many challenges that hinder the successful management of the diverse process. Process mining uses computer-based tools and techniques to analyze business processes and ensure best practices for improving business operations as it has a track record of success in improving business processes and procedures. As research on process driving problem solving continues to grow, there is a need to start applying the tools and techniques to specific domain areas and bridge the gap between research, development and application. We demonstrated how process mining techniques can be applied to medical billing using the L * life cycle model from a structured perspective. We developed a handmade comprehensive medical billing process flow using domain knowledge reference and established some time perspective Key Performance Indicators (KPIs) of the billing process. We then explored the hospital billing event log generated from an enterprise resource planning (ERP) system to see how the “as-is” from the event log deviate from the generally known knowledge-based (handmade) model. Taking each trace of the event log as patient visit, we discover that about 63 % of all the visit were billed and also about 3 % billed got regretted. The event log used in this research does not capture the complete activity flow for a real-world medical billing system. Hence, we were not able to directly compare the process map with the model and give precise operational support
219	We present a formal method to execute Business Activity Monitoring (BAM) on a Small or Medium Sized Business (SMB) that is undergoing re-engineering towards process-based workflow operations. On these enterprises, real-time access to critical performance indicators improves the speed and effectiveness of their overall logistical machinery. Businesspeople will be defined as actors in uncertain and conflictive situations. The dynamics of real-life negotiation poses challenges when creating models of how people interact and settle down strategic differences. We offer a functional analogy between collaborative strategies in a soccer match and B2B processes that feed on BAM data. We characterize negotiations using Q-Learning on actions that feed on BAM knowledge when searching for a common goal. We present Soccer and BAM-B2B demo software. Along the way, we pay special attention to the needs of SMB's, both in Mexico, and abroad, and thus concentrate on designing future products for Business Process Management (BPM). © 2004 IEEE.
220	The performance of business processes is evaluated and monitored with the aim of identifying whether strategic and operational goals are being achieved. Most approaches about performance measurement have been defined over traditional highly repetitive and well-structured processes. However, cur- rent organizational and business needs have encouraged the appearance of customizable processes to manage collections of process variants derived from a process, and loosely specified processes to manage non-repeatable and unpredictable processes. However, current techniques of performance measurement have not evolved to the same pace that business processes, thus generating a gap between processes and the measurement of their performance. The thesis introduced in this paper, is focused on enhancing the performance measurement of business processes by means of the improvement of existing techniques for the definition of process performance indicators and their applicability to different types of processes. With this purpose a set of artifacts, including a metamodel, notations, tools and methodologies will be developed. They will be validated by means of case studies based on real scenarios. © 2017 ACM.
221	Knowledge-intensive Processes (KIPs) are processes whose execution is heavily dependent on knowledge workers performing various interconnected knowledge-intensive decision-making tasks. Among other characteristics, KIPs are usually non-repeatable, collaboration-oriented, unpredictable, and, in many cases, driven by implicit knowledge, derived from the capabilities and previous experiences of participants. Despite the growing body of research focused on understanding KIPs and on proposing systems to support these KIPs, the research question on how to define performance measures thereon remains open. In this article, we address this issue with a proposal to enable the performance management of KIPs. Our approach comprises an ontology that allows us to define process performance indicators (PPIs) in the context of KIPs, and a methodology that builds on the ontology and the concepts of lead and lag indicators to provide process participants with actionable guidelines that help them conduct the KIP in a way that fulfills a set of performance goals. Both the ontology and the methodology have been applied to a case study of a real organization in Brazil to manage the performance of an Incident Troubleshooting Process within an ICT (Information and Communications Technology) Outsourcing Company.
222	In recent years, the most common need for companies consists in an increasingly efficient business process management and its continuous improvement. Companies are achieving this goal by implementing innovative approaches targeted on the individual project requirements. In this scenario, the present research aims to investigate, through a real pilot project, the benefits of implementing the agile project management (APM) framework based on a multi tools approach in order to re-engineering a business process (BPR). A real case study concerning a manufacturing plant is analyzed, in order to assess and highlight the effectiveness of the proposed model. © 2018
223	With the support of market demand and relevant national policies, the scientific instrument industry has shown a rapid development trend, the overall strength of China's scientific instruments has also been greatly improved, and a number of domestic scientific instruments with independent intellectual property rights are rising. However, the progress of technology hasn't brought about the growth of sales of domestic scientific instruments, and the market recognition is still relatively low. Some scientific research and institutions don't understand and daren't buy them. This study explores verification and evaluation methods to find the advantages, improve the popularity and market recognition and achieve comprehensive promotion of multi-parameter cardiac monitor. Taking multi-parameter cardiac monitor as the representative, we have developed the comprehensive verification and evaluation scheme of the instrument, carried out the performance comparison of instruments at home and abroad, formed the verification and evaluation report of domestic scientific instruments through a large number of performance comparison tests and data analysis.
224	In recent years, the digital channel of companies in the automotive retail industry has experienced considerable growth, reflected in the percentage of sales of this channel with respect to total sales. Therefore, companies that are not aligned with this growth, are those that have inefficiencies in their processes of attention to leads. Processes that consist of different procedures and essential operations that are not considered, nor are they applied efficiently, ignoring the magnitude of the impact on the company's sales. This research focuses on analyzing 4 tools to obtain a new commercial model that optimizes and improves the low conversion of leads into sales, due to inefficient lead handling processes, identified as the main problems within the company studied. The model makes use of tools such as: demand management based on Forecasting, optimization of the process as such through BPM, improvement of the CRM database through Poka Yoke, and improvement of salespeople skills under a profile standardization approach, resulting in a 15.73% improvement in the company's net profit, providing an effective commercial model with the capacity to be replicated in other companies.
225	Logistics processes in hospitals are vital in the provision of patient care. Improving healthcare logistics processes provides an opportunity for reduced healthcare costs and better support of clinical processes. Hospitals are faced with increasing healthcare costs around the world and improvement initiatives prevalent in manufacturing industries such as lean, business process reengineering and benchmarking have seen an increase in use in healthcare. This study investigates how logistics processes in a hospital can be benchmarked to improve process performance. A comparative case study of the bed logistics process and the pharmaceutical distribution process was conducted at a Danish and a US hospital. The case study results identified decision criteria for designing efficient and effective healthcare logistics processes. The most important decision criteria were related to quality, security of supply and employee engagement. Based on these decision criteria, performance indicators were developed to enable benchmarking of logistics processes in healthcare. The study contributes to the limited literature on healthcare logistics benchmarking. Furthermore, managers in healthcare logistics are provided with a list of decision parameters relevant for designing and benchmarking processes. © 2017, © 2017 Informa UK Limited, trading as Taylor & Francis Group.
226	nan
227	nan
228	Business Activity Monitoring (BAM) and Business Intelligence (BI) solutions are both intended to provide insight into the activities and performance of the enterprise. Deployment of such systems requires extensive tailoring to the enterprise, best left to experts. The dynamics of the enterprise demands a solution to the maintenance of BAM/BI solutions. This paper presents an Ontology-based BAM-Agent, called OBAMA that supports the maintenance of the system in light of changing business processes. Furthermore, for the formulation of aspects and properties to be monitored, it combines the expressive power of SQL, and TTL (a temporal trace language of first order logic). OBAMA helps in the preparation of regular assessment reports on the enterprise, taking into account key performance indicators as set by its operation manager. The paper describes the architecture, the combination of SQL, and TTL techniques for monitoring, and provides description of its kernel processes. OBAMA’s performance in a surveillance company is presented.
229	The Semantic Business Process Management (SBPM) aims at automation of the Business Process Management life cycle with use of semantics and Semantic Web services technology. The key issue to fulfil this aim is to provide an adequate machine-processable representation of processes. In this article we present one of the most important elements of process description, namely organizational ontologies. Moreover, we discuss their role in the early phases of SBPM and illustrate it with a set of application scenarios.
230	The sales process in every company is important. Therefore, every sales record must be stored in an integrated database so that tracking sales records is easy. However, there are still many sales recording practices that are still done manually, making the process of recording sales complicated and time-consuming. Therefore, it needs a sales record automation process that can track all sales recording processes that provide standardization in the form of KPIs and progress at each stage of sales records. With the growth of smart logistics, it can drastically change the business process of dashboard monitoring in a logistics company. With the smart logistic concepts and the use of business process redesign methodology, it resulted in a more simplified yet integrated automated sales monitoring system.  © 2023 IEEE.
231	Abstract Process mining has received tremendous attention from research and industry, establishing itself as a highly sought-after technology. Despite the technological maturity of process mining solutions, which has been achieved through extensive investments in research and development, organizations still face the challenge of elusive value when systematically adopting process mining. The authors attribute this dilemma to a lack of support for scaling and managing process mining project portfolios. To address this practical need and research gap, the authors propose a method for managing portfolios of so-called process mining value cases, which are defined as process mining-enabled business process improvement projects, towards an evolutionary roadmap ( mapper ). The method is designed to support organizations identify portfolios of process mining projects that generate value by improving business processes. The method was developed through a combination of design science research and situational method engineering and comprises five activities that each outline techniques, roles, and tools: strategize , identify , select , implement , and monitor . The method has been instantiated as a software prototype and iteratively evaluated for applicability and real-world fidelity by involving an expert panel of academics and practitioners. The usefulness of the artifact was substantiated through a real-world case study in a naturalistic setting.
232	Digital transformation forces companies to rethink their processes to meet current customer needs. Business Process Management (BPM) can provide the means to structure and tackle this change. However, most approaches to BPM face restrictions on the number of processes they can optimize at a time due to complexity and resource restrictions. Investigating this shortcoming, the concept of the long tail of business processes suggests a hybrid approach that entails managing important processes centrally, while incrementally improving the majority of processes at their place of execution. This study scrutinizes this observation as well as corresponding implications. First, we define a system of indicators to automatically prioritize processes based on execution data. Second, we use process mining to analyze processes from multiple companies to investigate the distribution of process value in terms of their process variants. Third, we examine the characteristics of the process variants contained in the short head and the long tail to derive and justify recommendations for their management. Our results suggest that the assumption of a long-tailed distribution holds across companies and indicators and also applies to the overall improvement potential of processes and their variants. Across all cases, process variants in the long tail were characterized by fewer customer contacts, lower execution frequencies, and a larger number of involved stakeholders, making them suitable candidates for distributed improvement © 2020 The Authors
233	Nowadays, users are more demanding with respect to the quality of service, changes in the environment are happening faster and faster and the presence of competition leads the managers of an organization to seek continuous improvement in the processes they perform in order to reduce time, avoid duplication of activities, optimize resources and increase user satisfaction. Therefore, this study seeks to develop a model based on Six Sigma that improves the administrative incident management process in a university. The type of research is applied with a pre-experimental experimental design. The instruments selected for data collection were the questionnaire and the observation form. As for the results, it was demonstrated that by implementing the Six Sigma-based model, the percentage of administrative incidents attended increased, the time of attention was reduced, the cost of attention was reduced and the percentage of satisfaction of the university's users was increased. In conclusion, a Six Sigma-based model was developed that improved the administrative incident management process, obtaining favorable results for the institution and its users.
234	As part of its strategic plan 2014-2018 Pemex Exploration and Production (PEP) has decided to modify the organizational structure in order to change from a function based structure to a new one based in process, supported on three fundamental axes: People, Processes and Technology. On this direction, it has been assigned to the Technical Resources Management Vicepresidency the responsibility to implement a strategy that will enable to improve performance into the Assets of the Marine Region. This paper presents the experiences and achievements reached by implementing the strategy of "Integrated Production Management by Processes" which goal is to create and implement a management model that will contribute to the optimization of the Asset performance, integrating through the people, management processes, workflows and information and communication technologies. The "Integrated Production Management by Processes" model, is based on five elements that work integrated and coordinated way; these are: Organizational issues. Work methodologies. Information management. Monitoring key performance indicators (KPI). Production costs management The proposal on this paper is based on developing a business process management methodology for PEMEX, by applying the 5 elements of the model to measure current performance of the production assets in order to find the existing gaps between the current management model and the Integrated Production Management by Processes and implement an action plan to close those gaps. In order to homologate and standardize the measurements in PEMEX's assets, a Capability Maturity Model was developed according to the ISO 9004-2010 and Mexican Standard NMX-CC-9004-IMNC-2009. The maturity model allows weighting each one of the 5 elements into 5 dimensionless levels. The lowest level 1 means that the asset is in the initial stage and it has the Vision of a Functional Management; on the other hand, the highest level 5 means that asset has implemented the new model and has reached a Sustainable Management. To implement the Integrated Production Management by Processes, assets need to demonstrate that Level 4 has been reached. © 2015 by ASME.
235	nan
236	Nowadays Services and Manufacturing are merging in an unique model of business featuring common drivers of profitability (i.e. customer satisfaction), common goals in operations (i.e. minimize capital investment and be rapid, responsive and flexible) and common enabling factors such as digital electronic computing and communications, better integration between operations, Business Process Re-design (BPR). Therefore, a new management area, called Business Performance Management (BPM) has developed, which is able to set an integration of planned, elaborated and collected performances through an advanced setting of data analysis and summary based on ERP systems. First data seem to confirm that BPM may produce hypothetical improvement in several fields such as banking, financial, medical, pharmaceutical, governmental and manufacturing ones. Actually, BPM represents an evolution of Business Intelligence (BI) based on the idea of Business Activity Monitoring (BAM). The aim of the integration of BAM solutions overtakes the physical boundaries of a deployment or of a department, and the idea of real time (time required for one or more data processing) is not necessarily expressed in nanoseconds but it is rather determined by the business process bill. Therefore, BPM is in general an amount of services and implements offering an explicit management process in analyzing, planning, programming, executive and monitoring areas. Both BPM and CPM (Corporate Performance Management systems) are based on parameters permitting to determine the efficiency of an aspect of the company activity objectively; these parameters have been defined Key Performance Indicators (KPI). Actually, they provide the base for strategic decisions. About 86% of the companies is expecting a competitive benefit reducing the time wasted to collecting and answering to information, while a good 74% of the companies has executive managers demanding IT manager to restrain the clue operation data receiving time. Nevertheless, today only 35% of the companies is able to exploit the benefits received from real time information. What makes the difference between the value expected from applications and the applicability of them in order to goal the planned results? Considering the target to achieve, the proposed methodology is able to link primary performance indicators with objective indicators based on decreasing hierarchical level (top-down) by analyze the existing connection between KPIs as well as the relation between one KPI and the others and identify, at the same time, the relevant coefficients using Multivariate Analysis of Variance and Neural Network Metamodels. From a methodological point of view this process is similar to the identification of the unknown function y = (x1, x2, ..., xn), where y is the dependent KPI and xi are the independent ones. For specific application System Dynamics simulation may replace metamodels to better define interconnections between independent and dependent KPI, by applying Design of Experiment to the simulation output and Response Surface Methodology. Thus, a powerful tool which can effectively support decision making and foreseeing processes is obtained. This is a necessary condition for choosing real priorities and discovering KPI's interconnections in the services business as well as in the manufacturing one. The paper presents the methodology from a theoretical point of view and brief summary of a real life applications to Supply Chain Management, a second application for the Highway maintenance management sector is briefly outlined.
237	In the last decade, organizations have devoted enormous time and effort to the development of business performance measurement (BPM) systems. Many articles have been written on how to design and implement these types of systems. However, few studies have addressed the issue of why some organizations are better able to 'manage through measures, than others. In other words, why do some organizations struggle to ensure that action follows measurement, whilst others systematically use their metrics to inform their decision-making processes, and their subsequent actions? This paper aims to contribute to a more complete understanding of the use of BPM systems by reviewing the performance measurement literature developed in the management arena. It differs from previous examinations of performance measurement and management control systems in that it uses a broader scope and follows a new method of literature review applied to management research, namely, systematic review. The paper focuses on the thematic analysis of the review only. The insights extracted from the literature are articulated and presented in a management framework. In addition, the paper identifies different gaps in the literature that require further research.
238	Purpose - Scholars in the field of performance measurement tend to use the term business performance measurement (BPM) systems without explaining exactly what they mean by it. This lack of clarity creates confusion and comparability issues, and makes it difficult for researchers to build on one an each other's work. The purpose of this paper is to identify the key characteristics of a BPM system, by reviewing the different definitions of a BPM system that exist in the literature. This work aims to open a debate on what are the necessary and sufficient conditions of a BPM system. It is also hoped that a greater level of clarity in the performance measurement research arena will be encouraged. Design/methodology/approach - The performance measurement literature is reviewed using a systematic approach. Findings - Based on this research, a set of conditions of a BPM system has been proposed from which researchers can choose those which are necessary and sufficient conditions for their studies. Research limitations/implications - The analysis in this paper provides a structure and set of characteristics that researchers could use as a reference framework to define a BPM system for their work, and as a way to define the specific focus of their investigations. More clarity and precision around the use of the BPM systems phrase will improve the generalisability and comparability of research in this area. Originality/value - By reviewing the different definitions of a BPM system that exist in the literature this paper will hopefully stimulate a debate on the necessary and sufficient conditions of a BPM system and encourage a greater level of clarity in the performance measurement research arena. © Emerald Group Publishing Limited.
239	nan
240	We provide a descriptive review of the main approaches for carrying out simulation optimization, and sample some recent algorithmic and theoretical developments in simulation optimization research. Then we survey some of the software available for simulation languages and spreadsheets, and present several illustrative applications.
241	nan
242	The main aim of the proposed research is to identify factors that create an environment conducive to successful Business Process Management (BPM) adoption. Factors predicting successful BPM adoption have been identified within the TOE (Technology-Organization-Environment) framework using a literature review and methodology for constructing conceptual frameworks. The following factors are proposed: top management support for previous projects of organizational change, complexity of BPM system and notation, satisfaction with existing systems, business-IT alignment level, perceived strategic benefits of using BPM, extent of coordination, organizational readiness, performance measurement, culture conducive to organizational change, and, perceived environmental pressure. Study results have the potential to fill the research gap by contributing to the development of a theoretical model of BPM adoption that has not been proposed in studies thus far. In practical aspects, the proposed study can influence the understanding of the factors predicting successful BPM adoption.
243	The main aim of the proposed research is to identify factors that create an environment conducive to successful Business Process Management (BPM) adoption. The research methodology includes two triangulated approaches: the first - the process of theorization based on a literature review and procedure for analysis of qualitative data; and the second - the process of acquiring knowledge from experts based on assumptions of the Delphi technique and coding of acquired qualitative data. Factors predicting successful BPM adoption have been identified within the TOE (Technology-Organization-Environment) framework. The following factors are proposed: complexity of BPM system and notation, satisfaction with existing systems, technology readiness, top management commitment, leadership, perceived strategic benefits, extent of coordination, organizational readiness, performance measurement, culture and communication, employee competency and commitment, market pressure, and, regulatory and legal pressure. Study results have the potential to fill the research gap by contributing to the development of a theoretical model of BPM adoption that has not been proposed in studies thus far. In practical aspects, the proposed study can influence the understanding of the factors predicting successful BPM adoption and is the first step towards the development of a measuring instrument allowing the assessing of an organization’s readiness to adopt BPM. © 2019, Springer Nature Switzerland AG.
244	This article discusses the problem of the effective work of managers of industrial enterprises, which is the basis of economic development in modern Russia. The authors suggest that the management of the system of performance indicators in managers in the conditions of realization of various business processes can reduce the risk of crises in the enterprise, and improve the efficiency of labour management and productivity in the company in a whole. According to the authors, improving the efficiency of management in the conditions of implementation of the various business processes of industrial enterprises is an integral element of the overall strategic development of the company. The article presents the results of work performance assessment of managers in the implementation of business process management. In this article there is developed performance business process management on the example of the metal cutting enterprise management levels: the corporate level, the first operational level, the second operational level, and the line level. For these indicators the performers are defined and criteria are given. © 2016, International Journal for Quality Research.
245	Intelligent techniques have been used in the marketing and sales sectors of business to improve analysis, increase revenues and save time. In customer-centric institutions, one of the areas in which intelligent techniques and data mining algorithms have been used is the personalization for enhanced CRM (Customer Relationship Management) performance. However, with a growing number of customers, the diversity of products on offer, the complex behavior of customer groups and the continuous change of personalization parameters, producing a tailored personalized recommendation that predicts their future needs is a challenging task.In this paper, we propose multi dimension personalization framework architecture to improve personalized targeting. The framework presented improves on the automation of existing systems by using multiple supervised and unsupervised data mining techniques, and enhances the level of targeting by considering more effective dimensions in multiple stages of the framework. A theoretical case study explaining the practical working and perceived advantages of the new framework is presented.
246	The paper provides a Delphi study to verify the framework to implement sustainability initiatives in the business processes. The Delphi technique seeks to obtain consensus on the opinions of experts, termed panel members, through a series of questionnaires. As part of the process, the responses from each round are fed back in summarized form to the participants who are then given an opportunity to respond again to the emerging data. The study successfully obtained a consensus in the phases and steps of the conceptual framework and provided feedback from the specialists. According to them, leadership, people and cost were identified as the main challenges related to the sustainability adoption by the organisations and key performance indicators (KPIs), Lifecycle assessment (LCA) and triple bottom line (TBL) were identified as the main methods to assess al the sustainability dimensions in terms of business processes. © IEOM Society International.
247	The management of processes and systems is a complex and time-consuming activity for organizations and also an ongoing Information Technology (IT) challenge. Among the different approaches for bringing flexibility to the business processes and systems are Service-Oriented Architecture (SOA) and Business Process Management (BPM). The SOA approach has become popular providing services and interfaces, enabling integration of heterogeneous and distributed platforms and BPM leverages the cycles of improvements, control and evaluation of business processes. BPM and SOA should work together aiming at improving business processes and evolving systems architecture. One main problem to apply BPM and SOA is the lack of established processes and this work proposes a software process line in order to simplify variability control and enable the instantiation of new development process applying BPM and SOA. It also aims at developing an environment to support the proposed software process line in order to automate the process, integrating industrial tools with one specifically developed to perform the transformation of UMA models into BPM notation. The main contribution of this work is the definition of the software process line for engineering service-oriented products. It is highly relevant to software industry since software process lines lacks experiments, practices and tools.
248	Objective To mitigate the effect of caregiver shortage, collaborative networks in Norwegian municipalities are exploring the possibilities provided by e-health and welfare technologies. However, extracting benefits from such technologies depends on many factors. Methods In this study, an extensive literature review is performed to compare e-health and other sectors in terms of the critical success factors in collaborative business process management. Using the dynamic capabilities view as a general theoretical lens, and a process orientation framework for operationalization, these factors are then conceptualized and validated in a cross-sectional study of cases in the Norwegian municipal e-health sector. Results The study contributes to e-health research by identifying the key factors that influence performance. These factors are significantly driven by government policies and regulations. Our findings challenge the assumption that welfare technology networks can be built from the bottom up without government intervention. Regulatory interventions are needed, to obtain process performance metrics and foster viable, long-term business models for the participating institutions. Conclusion The findings have an impact on research and practice, especially in local public management, for predicting and prescribing future development in this context. There are indications of significant gaps in government policies and regulations. Further research should examine whether and how these findings transcend the chosen context. © 2017 Fellowship of Postgraduate Medicine
249	Process mining practices are mainly activity-oriented and they seldom consider the (often conflicting) goals of stakeholders. Involving goal-related factors, as often done in requirements engineering, can improve the rationality and interpretability of mined models and lead to better opportunities to satisfy stakeholders. This paper proposes a new Goal-oriented Process Enhancement and Discovery (GoPED) method to align discovered models with stakeholders’ goals. GoPED first adds goal-related attributes to traditional event characteristics (case identifier, activities, and timestamps), selects a subset of cases with respect to a goal-related criterion, and finally discovers a process model from that subset. We define three types of criteria that suggest desired satisfaction levels from a (i) case perspective, (ii) goal perspective, and (iii) organization perspective. For each criterion, an algorithm is proposed to enable selecting the best subset of cases were the criterion holds. The resulting process models are expected to reproduce the desired level of satisfaction. A synthetic event log is used to illustrate the proposed algorithms and to discuss their results. © 2019, Springer Nature Switzerland AG.
250	Process mining helps infer valuable insights about business processes using event logs, whereas goal modeling focuses on the representation and analysis of competing goals of stakeholders and systems. Although there are clear benefits in mining the goals of existing processes, goal-oriented approaches that consider logs during model construction are still rare. Process mining techniques, when generalizing large instance-level data into process models, can be considered as a data-driven complement to use case/scenario elicitation. Requirements engineers can exploit process mining techniques to find new system or process requirements in order to align current practices and desired ones. This paper provides a systemic literature review, based on 24 papers rigorously selected from four popular search engines in 2018, to assess the state of goal-oriented process mining. Through two research questions, the review highlights that the use of process mining in association with goals does not yet have a coherent line of research, whereas intention mining (where goal models are mined) shows a meaningful trace of research. Research about performance indicators measuring goals associated with process mining is also sparse. Although the number of publications in process mining and goal modeling is trending up, goal mining and goal-oriented process mining remain modest research areas. Yet, synergetic effects achievable by combining goals and process mining can potentially augment the precision, rationality and interpretability of mined models and eventually improve opportunities to satisfy system stakeholders. © 2019, Springer-Verlag London Ltd., part of Springer Nature.
251	nan
252	This paper presents the analysis of process-oriented information technology. Process information technology can be defined as all information technology that a company uses in order to reach the highest possible level of process orientation. It includes information technology for managing business processes and information technology for performance measurement. The paper identifies and describes process information technology and it examines the influence based on actual research done in Croatian businesses, information technology has on levels of business process orientation. Information technology has a favourable effect on process orientation, according to the research. It has been established that information technology is the least valued aspect of process orientation and that corporate informatization in the Republic of Croatia is still insufficient. The adoption and usage of process information technology in Croatian enterprises are crucial, according to the aforementioned data.
253	This paper presents a holistic methodology and associated toolset for business process modelling and analysis. The importance of integrating performance measurement (PM) indicators and tools in business process management has been identified in the literature as well as contemporary approaches that attempt to give a solution to this problem. However, most of these approaches propose solutions based on theories and techniques used in other disciplines or research fields which approach the issue of performance measurement in BPR from their individualistic perspective. In the majority of cases the proposed theories and techniques prove to be inadequate to measure performance holistically and integrate, organizational, human resource management, process management and workflow management concepts. The resulting methodology and toolset is based on business analysis ratios that define and measure key performance indicators in qualitative and quantitative terms and identify the relationships between them. These ratios allow enterprises to achieve a performance evaluation tool for continuous improvement in their attempt to respond and adapt quickly to turbulent markets. The performance measurement toolset (called ADJUST) is used for (1) planning different reorganization scenarios for the achievement of desired performance, (2) for assessing real time performance and (3) reporting deviations from desired planned performance. In order to monitor and assess real time performance the ADJUST software tool provides interfaces to three kinds of management tool categories, namely: Process management tools (PMT): business models, cycle time, primitive cost, etc. Human resource management (HRM) tools: job descriptions, performance measures, etc. Workflow management (WFM) tools: transactions, business rules, workflow models, etc. The ADJUST business analysis engine is based on employee effort analysis and provides meta-analysis of data analysed in PMT and HRM tools. Data like activity sequencing, cycle times, primitive costing, etc. from PMT tools are analysed in ADJUST in order to assess the percentage of high-business and low value added activities, mission-non mission activities, concentration analysis, etc. Knowledge management elements are integrated to job descriptions and associated with performance measures and workflow elements. Similarly, job descriptions and performance measurement data that are provided by HRM tools are analysed further in terms of cost to manage, principal-agent analysis etc. In the case of WFM tools the ADJUST system provides not only meta-analysis of workflow processes, transactions and document flows but also dynamic monitoring of their performance in real time. © 2011 John Wiley & Sons, Ltd.
254	Real-life event logs, reflecting the actual executions of complex business processes, are faced with numerous data quality issues. Extensive data sanity checks and pre-processing are usually needed before historical data can be used as input to obtain reliable data-driven insights. However, most of the existing algorithms in process mining, a field focusing on data-driven process analysis, do not take any data quality issues or the potential effects of data pre-processing into account explicitly. This can result in erroneous process mining results, leading to inaccurate, or misleading conclusions about the process under investigation. To address this gap, we propose data quality annotations for event logs, which can be used by process mining algorithms to generate quality-informed insights. Using a design science approach, requirements are formulated, which are leveraged to propose data quality annotations. Moreover, we present the “Quality-Informed visual Miner” plug-in to demonstrate the potential utility and impact of data quality annotations. Our experimental results, utilising both synthetic and real-life event logs, show how the use of data quality annotations by process mining techniques can assist in increasing the reliability of performance analysis results.
255	nan
256	Organisational and government concerns about environmental sustainability (ES) are on the increase. While a significant amount of research from a wide range of domains has addressed various ES challenges, intuitively, Business Process Management (BPM), with its focus on process improvement and process performance measurement, has much to offer the ES field. In this paper we aim to understand the BPM research contribution to ES, including specific Environmental Performance Indicators (EPI), and the BPM concepts that have been utilized in the ES context. To this end we conduct a systematic literature review to capture prior research focused on BPM and ES, coding the articles according to their contribution to EPIs and other ES concepts, while also contrasting their focus with main challenges identified in industry reports. Our study identifies which EPIs have been addressed in prior BPM research and highlights areas of future contribution. © 2015 Shahrzad Roohy Gohar & Marta Indulska.
257	Environmental sustainability (ES) is a source of competitive advantage for organizations. However, from socio-technical systems (STS) perspective, a multitude of complex factors is involved in transforming organizations towards environmental sustainability. To facilitate such transformation, all components of an STS, including people, processes, systems and technology, need to be considered. With processes at the core of STS functionality, organizational transformations towards sustainable practices should consider business process management (BPM) as an enabler. ES in BPM research is an emerging topic. To better understand ES objectives, practices, and challenges from a process-oriented perspective, we look to the hospitality industry given it is one of the largest business sectors world-wide. Specifically, in this paper we report on a qualitative study that aims to identify ES efforts and challenges in the Australian hotel industry, exploring the extent to which a process orientation exists to assist with these efforts. Findings indicate an absence of process-oriented initiatives in relation to ES in this context. © 2019 Gohar & Indulska.
258	The climate change phenomenon, directly or indirectly, affects industries and nations. Governments and organizations have been challenged to identify their environmental impacts to address environmental sustainability issues. A promising, yet under-studied in this context, theme of information systems (IS) literature that has the potential to help with identifying, quantifying and managing environmental impacts is business process management (BPM). With its focus on continual process performance improvement, the capacity of BPM to contribute to Environmental Sustainability (ES) needs to be further explored. Yet, contributions from the BPM research community and the impact of these contributions appear to be fragmented. In this paper, we present a systematic literature review to explore BPM contributions to ES, with a focus on environmental performance indicators (EPIs) as well as relevant organizational factors related to ES and BPM. In doing so, we identify and explore ‘Green BPM’ contributions and suggest ways to advance BPM research in the context of ES. ©
259	nan
260	Business process management (BPM) broadly covers a lifecycle of four distinct phases: design, configuration, enactment, and analysis and evaluation. Most BPM tool suites impose a strict separation between these phases, i.e., in each phase different languages and tools are used and the transition between phases is indirect and costly. This paper presents an environment for integrating all phases of the BPM lifecycle in which business process (BP) types and their instances can be modeled, visualized, managed and automatically synchronized, using a shared representation of models and code. The environment extends the capabilities of BP models to be used not only for specifying BPs but also for: (1) enactment—creating instance objects that capture BP operational data; (2) monitoring BP instances as they progress; (3) visualizing performance indicators of executed BPs at runtime; and (4) navigating from a BP type model to its respective instance population. As opposed to existing tools, the proposed environment does not require regenerating the workflow schema when BP designs change, nor does it require additional adaptations to support monitoring. Thereby, we facilitate a continuous and dynamic BPM environment, where workflow specifications can be changed at runtime. Our solution integrates a meta-programming language called eXecutable Modeling Facility (XMF) and the multi-perspective enterprise modeling framework (MEMO). © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.
261	In order for current e-Businesses to mature from hastily assembled systems and applications, formal processes must be put in place for planning and budgeting, pricing and costing, and for establishing quality of service and service–level assurances. There are many challenges that e-Businesses face in formalizing these processes. The most important problem is to bridge the semantic disconnect between business objectives and the information system performance objectives. Next, the characterization of the e-Business infrastructure is extremely complex, given the variety of applications and system configurations at a web site and the traffic it receives. Finally, e-Businesses need to associate and apply traditional economic factors, such as depreciation and usage to applications, operating systems, and databases. In this paper, we propose an approach for defining and quantifying effective e-Business capacity that allows us to translate quality of service objectives into the number of users that a web site can support. This approach is based on inducing online models using machine learning and statistical pattern recognition techniques. As a consequence, the approach is flexible: it adapts to any site configuration and environment. The concept of e-Business capacity allows us to naturally answer planning and operational questions about the information system infrastructure needed to support the e-Business. The questions range from indicating which performance measures in the system are "important" to simulating "if-then" scenarios
262	During the last ten years the approach to business management has deeply changed, and companies have understood the importance of enforcing achievement of the goals defined by their strategy through metrics-driven management. The DW process, though supporting bottom-up extraction of information from data, fails in top-down enforcing the company strategy. A new approach to BI, called Business Performance Management (BPM), is emerging from this framework: it includes DW but it also requires a reactive component capable of monitoring the time-critical operational processes to allow tactical and operational decision-makers to tune their actions according to the company strategy. The aim of this paper is to encourage the research community to acknowledge the coming of a second era in BI, to propose a general architecture for BPM, and to lay the premises for investigating the most challenging of the related issues. Copyright 2004 ACM.
263	nan
264	The institutional mission declared by an organization can be taken as baseline for management as well as a mechanism for communicating its objectives and organizational strategies. In a complementary fashion, performance indicators support the evaluation of the processes aimed to execute companies specific strategies. Thus, the present study sought, through an empirical quantitative approach, test the hypothesis of the performance indicators used by a company is associated with the content of the mission it declares. A sample of 85 Brazilian companies listed in BM&FBovespa's IbrX Index was used. Data has been extracted from the mandatory reference reports issued annually by companies and from its institutional sites. For examination of the data, the technique of content analysis was used in order to identify the characteristics present in the missions reported by the companies studied. Further, the logistic regression was used to test the association between the variables studied. In the context analyzed, no evidence of association between the characteristics of the missions reported by the companies and the performance indicators used by them was observed in the results. The results found contradict, in part, the logic and theory of organizations management control, especially regarding the congruence amongst the objectives that must be pursued, including the alignment of what an organization declared as being relevant in its mission with the indicators it uses to evaluate its performance. Finally, Business Process Management (BPM) is discussed as a fundamental support for the definition of performance indicators in order to guarantee the alignment to the organization's strategic objectives.
265	Purpose: This paper aims to examine the relationship between business process management (BPM) and company performance. The research focuses on the instrumental aspect of core business processes and its controlling activities in small and medium-sized companies (SMEs) to identify the relationship to company performance. Design/methodology/approach: The results presented in this paper are based on a survey of Slovene SMEs. A questionnaire was distributed to 3007 SMEs via e-mail and a response rate of 5.42% was achieved. The financial data of companies over a six year period as derived from the publicly available financial reports of SMEs along with an industry-specific financial risk measure and other financial data were used for the company risk-adjusted performance measures of relative residual income (ROE-r) and risk-adjusted ROE (ROE-a) calculation. Findings: The results show that instrumental aspects of core business process controlling activities are related to risk-adjusted company performance measures ROE-r and ROE-a. Companies with lower ROE-r and ROE-a have been perceived to be more focused on the instrumental aspect of BPM. Presumably due to the small sample, the results of a non-parametric Mann–Whitney U test did not statistically confirm the developed hypothesis: “the instrumental aspect of controlling as a core process management activity has a statistically significant impact on company risk-adjusted performance measures such as ROE-r and ROE-a.” Despite this, the results show a possible negative correlation between risk-adjusted performance measures and BPM, which opens possibilities for further research. Research limitations/implications: The main limitation of the purposed study model is that the paper have studied only control activities of core business processes and relate it to company risk-adjusted performance measures. The study has been limited by the SME sample and the use of a survey as a research instrument. An additional limitation of the research is the degree of reliability implied by the assumptions of the models used to estimate the required return on equity and risk. Results concern investors, managers and practitioners to start BPM improvement initiatives, to set BPM priority measures and to set priority management decisions and further actions. Originality/value: This paper presents the unique findings from an investigation of the instrumental aspects of BPM practices and their relationship to company risk-adjusted performance measures in SMEs. This paper developed a measurement instrument for measuring the instrumental aspects of BPM use. An additional original contribution is the use of company risk-adjusted performance measures such as ROE-r and ROE-a, which take into account the required profitability of companies in different industries according to the risk and allows comparable results of companies from different industries. The approach is innovative and interesting as regards researching the factors that affect the profitability of companies that operate in different industries. © 2021, Dušan Gošnik and Igor Stubelj.
266	Knowledge Management (KM) is a new scientific discipline which facilitates organisations to better perform in their highly competitive environment. Universities are learning organisations in the centre of the knowledge triangle. They are faced with the need to better manage their knowledge resources and to facilitate their transfer to all interested stakeholders. Similar to companies, universities are developing at different speeds, and some are lagging behind in adopting KM strategic approach. The goal of this paper is to provide guidance to university staff in developing their KM strategy roadmap on bases of the Balanced Scorecard approach and integrating it in the overall strategy.
267	Knowledge Management (KM) is a new scientific discipline which facilitates organisations to better perform in their highly competitive environment. Universities as learning organisations in the centre of the knowledge triangle are faced with the need to better manage their knowledge resources and to facilitate their transfer to all interested stakeholders. Similar to companies, universities are developing at different speeds, and some are lagging behind in adopting KM strategic approach. The goal of this paper is to provide guidance to university staff in developing their KM strategy and integrating it in the overall organisational strategy.
268	nan
269	Globalization, digitalization and disruptions recently driven by the Covid19 pandemic are affecting today's supply chains and thus are challenging companies in maintaining their businesses. Resulting uncertainties lead to potential over- and undercapacities and therefore to economic inefficiencies in companies. Engaging in intercompany networks can be a way to circumvent inefficiencies by sharing resources via electronic markets. Here, negotiation mechanisms can be used to allocate the exchanged goods tailored to the needs and payment conditions of the network participants. Ensuring trust and enabling cooperation between the participants in such a virtual ecosystem is a major challenge and essential for raising its potentials. Lacks of trust within the single transaction phases impede the negotiation process and in worst case the maintaining of the network. For this reason, Distributed Ledger Technologies (DLT) and their inherent consensus-building functionalities as well as abilities to utilize smart contracts deserve closer investigation. The aim of this paper is to provide a literature review of DLT functionalities coping with behavioral uncertainties, with a closer view on the context of supply chain. The paper examines, to what extend the integration of DLT provides a beneficial contribution to solving trust problems occurring in intercompany negotiations.
270	Workflow technology promises an increase in efficiency in the execution of business processes. The technology is widely accepted, but often the high costs exceed the promised benefits. Thus, it is desirable to calculate the profitability prior to investing into workflow technology. After an investment into workflow management systems (WFMS), it has to be verified whether the expected benefits have been realized or not. In this paper we present a method that covers both, the cost-benefit-ratio calculations specially customized for WFMS and the calculation of the realized savings. The profitability analysis is based on simple measurable performance indicators that consider the tangible calculation of costs as well as the quantitative and qualitative benefits. Long time practical experience in implementing and operating workflow management supported the design of the method. The method presented in this paper has been successfully used in the IT company of a banking corporation. © 2009 IEEE.
271	Purpose - This paper aims to automate the supply chain operations reference (SCOR) model as an enabler for process-oriented supply chain business intelligence. Design/methodology/approach - The hypothesis is the following: SCOR model automation is possible using data that is directly extracted from integrated enterprise systems. To test the hypothesis, an alignment product that allows the SCOR model to be automated with information that is directly extracted from the Oracle E-Business Suite was developed. Findings - In order to achieve the full benefits from the SCOR model, effective business process management and the SCOR key performance indicators (KPIs) must be implemented and used. Unless data collection to support KPI construction is automated, it is difficult to institutionalize the SCOR model as a measurement and benchmarking framework. We have demonstrated that automated support for KPIs is feasible and achievable. Research limitations/implications - The E-Business Suite is a single enterprise solution, but we assert that the same procedures could be followed with other enterprise solutions or even applied in a legacy system environment. Originality/value - The developed solution described in the paper can immediately be applied to the design, development, and deployment of corporate performance management systems. © Emerald Group Publishing Limited.
272	nan
273	Process mining is to extract knowledge about business processes from data stored implicitly in ad-hoc way or explicitly by information systems. The aim is to discover runtime process, analyze performance and perform conformance verification, using process mining tools like ProM and Disco, for single software repository and processes spanning across multiple repositories. Application of process mining to software repositories has recently gained interest due to availability of vast data generated during software development and maintenance. Process data are embodied in repositories which can be used for analysis to improve the efficiency and capability of process, however, involves a lot of challenges which have not been addressed so far. Project team defines workflow, design process and policies for tasks like issue tracking (defect or feature enhancement), peer code review (review the submitted patch to avoid defects before they are injected) etc. to streamline and structure the activities. The reality may not be the same as defined because of imperfections so the extent of non-conformance needs to be measured. We propose a research framework `Nirikshan' to process mine the data of software repositories from multiple perspectives like process, organizational, data and time. We apply process mining on software repositories to derive runtime process map, identify and remove inefficiencies and imperfections, extend the capabilities of existing software engineering tools to make them more process aware, and understand interaction pattern between various contributors to improve the efficiency of project.
274	nan
275	During the last decades information technology (IT) management has changed significantly. Starting from being a costly and rare resource in its very beginnings IT has evolved into a vital enabler for almost any kind of business today. This development demands for highly flexible management concepts allowing the business to actively control and govern IT performance. A meanwhile widely used approach for multi-dimensional performance measurement in the context of IT management is the Balanced Scorecard (BSC). With this article we aim at investigating the state of the art of IT BSC use through a comprehensive literature analysis. Moreover, we evaluate the adaptability of the different types of this concept to the most recent developments in IT management. Our findings suggest that two new scorecards need to be derived: the IT BSC for services and service portfolios.
276	An effective information system improves the profitability of organizations. However, it appears that there is a need for an alignment approach that allows the continued operation of information system. In our work, we focus particularly on the operational alignment. Moreover, we deal with the topic of alignment by analyzing three levels: business requirement, business process, and software system. In this paper, we present an overview of this topic's concepts. Then, we analyze approaches related to our work by defining a set of criteria. Finally, we present the main idea of our proposed approach.
277	To be competitive and flexible, companies engage in collaborations to develop and share their competences in order to cope with the dynamic environment. Collaborative business process evaluation helps to reflect the actual functioning of business process and their performance level. In this perspective, research in assessing collaborative business process performance presents relevant guidelines in order to adapt IT solutions when business requirements evolve. In this paper, we present an analysis and assessment approach for collaborative business processes in the service-oriented architecture in order to maintain their performance in competitive markets. Our approach proposes an evaluation method using execution traces of business process combined with a high-level assessment method using key performance indicators. Our main objectives are to track the execution of collaborative business process and to analyze the performance trajectory of a business process regarding the business performance level. To collect and structure the performance knowledge (execution and measurement), we create an ontological model-based knowledge repository in order to enrich the semantics of an evaluation business process. The precise track of execution data in our approach is able to identify events that disrupt the proper functioning of processes at the runtime. From an industrial case study, we can conclude that our ontological approach can target the performance assessment of collaborative business processes effectively. © 2015 Elsevier B.V.
278	Recently, strong interests in the real-time performance management are increasing to gain competitive advantages in the rapidly changing business environment. For better business performance or continuous process improvement of an enterprise, real-time measurement and analysis of the performance of managerial activities is essential. Business activity monitoring (BAM) which provides real-time access to key performance indicators or business processes is one of core elements for successful business process management (BPM) system. Since performance measurement cannot be managed independently of business processes, BAM system needs to monitor performance metrics in terms of business process. This paper proposes BAM system design framework integrated with the process-based performance measurement model (PPMM), in which monitored KPIs are closely related with business processes. The proposed PPMM consists of three sub-models: KPI model, process model, and K-P model. To show the applicability of proposed framework, BAM system prototype was also developed using a real case. This paper is expected to be a practical help to the practitioners who are planning and executing the BAM system implementation for continuous process improvement.
279	Many enterprises have recently been pursuing process innovation or improvement to attain their performance goals. To align a business process with enterprise performances, this study proposes a two-stage process analysis for process (re)design that combines the process-based performance measurement framework (PPMF) and business process simulation (BPS). The two-stage analysis consists of macro and micro analyses of business processes. At the early stage of business process analysis (BPA), macro process analysis is conducted to identify the influence of a business process on a target key performance indicator (KPI) or the contribution of a target KPI to other KPIs. If target business processes that need improvement are identified through the macro process analysis and to-be processes are newly designed, micro process analysis using simulation is conducted to predict the performance. The proposed method is validated by application to a real business process within the setting of a large Korean company. By using the proposed, two-stage process analysis, company staff involved in process innovation projects can determine the processes with the greatest influence on enterprise strategy, and can systematically evaluate the performance prediction of the newly designed process. © 2008 Elsevier Ltd. All rights reserved.
280	In the diagnosis phase of business process management (BPM), the operational processes are analyzed to identify problems and to find things that can be improved. And in the process design phase of BPM, to-be process is newly designed and analyzed. Proposed in this paper is a two-stage process analysis for process (re)design using the process-based performance measurement framework (PPMF) and process simulation. A two-stage process analysis consists of macro analysis and micro analysis. The most influencing business process on specific strategic level KPI is selected at the macro analysis stage. Afterwards, the performance of selected process is reviewed, and new to-be process is redesigned. The performance prediction of new process is conducted using process simulation at the micro analysis stage. By using the proposed two-stage process analysis, company practitioners involved in the process innovation can easily and efficiently find the most influencing processes upon enterprise strategy, and evaluate the performance prediction of newly designed process.
281	Advances in the adoption of business process management platforms have led to increasing volumes runtime event logs, containing information about the execution of the process. Business users analyze this event data for real-time insights on performance and optimization opportunities. However, querying the event data is difficult for business users without knowing the details of the backend store, data schema, and query languages. Consequently, the business insights are mostly limited to static dashboards, only capturing predefined performance metrics. In this paper, we introduce an interface for business users to query the business event data using natural language, without knowing the exact schema of the event data or the query language. Moreover, we propose a bootstrapping pipeline, which utilizes both event data and business domain-specific artifacts to automatically instantiate the natural language interface over the event data. We build and evaluate our prototype over datasets from both practical projects and public challenge events data stored in Elasticsearch. Experimental results show that our system produces an average accuracy of 80% across all data sets, with high precision ( 91%) and good recall ( 81%).  © 2020 IEEE.
282	Troubles in speaking, hearing, and understanding occur routinely in any kind of conversational setting. The natural flow of conversation includes methods for “repairing” such troubles by repeating or paraphrasing all or parts of prior turns. In the case of conversational AI systems, these troubles occur due to failure of different components of the system such as the speech recognition, natural language understanding, and natural language generation. Such errors may occur infrequently, but still often enough to have a significant impact on key performance indicators (KPIs). Identifying the root cause of these errors is a complex task that requires a team to meticulously examine and interpret the interaction between the voice agent and customers. In this work, we present an interactive system, DTTool, that surfaces system-generated annotations that hint at anomalous events that lead to candidate errors that impact KPIs and demonstrate how the team could discover unknown errors using DTTool.
283	The purpose of our work is to improve the performance of business processes. Our contribution consists of proposing an approach to defining key performance indicators for a set of well-defined objectives. To test our approach, we defined a set of objectives and KPIs, and then we elaborated a survey to match the objectives to different specific KPIs. This survey is applied to the case study of a COVID-19 care process and is dedicated to the members of Farhat Hached's crisis unit. In addition, we have developed a web application dedicated to the crisis unit. This application allows to: (1) add the objectives and to manage the KPIs, (2) assign the objectives to the KPIs, (3) display a comparative table of the values of the KPIs, (4) present a histogram for each KPI. Moreover, through this prototype we can (5) know the percentage of the achievement of the objectives. Furthermore, we used the DMN, based on the Signavio tool. Indeed, the use of DMN in our work consists first in matching the objectives to the KPIs, then placing the decision rules based on the threshold values of the KPIs, entering the observed values, and finally obtaining the result about the achievement of the objectives. © 2022 CURRAN-CONFERENCE. All rights reserved.
284	Interviews held with over a thousand CEOs in 2010 and CIOs in 2011 show that organizations are expecting change and are being challenged with complexity. As CEOs and CIOs have started strategically aligning their thinking around change, future challenges, growth and complexity, organizations must now focus on driving new and better business value from the enterprise's portfolio of technology to remain successful. Technology designs and architectures need to realistically identify and represent the business's capabilities and their relationships to operations and technology. This paper presents a new concept called Actionable Business Architecture. Actionable Business Architecture builds beyond the state-of-the-art in the field of Business Architecture by providing a new perspective on the subject of managing the confluence of three key business models of strategy, operations and technology. It consumes the science and practice of strategy management, business process and case management, service orientation and industry enterprise models as the means to make the business architecture simplified and focused to support transformation.
285	nan
286	Abstract Big data is one of the most recent business and technical issues in the age of technology. Hundreds of millions of events occur every day. The financial field is deeply involved in the calculation of big data events. As a result, hundreds of millions of financial transactions occur in the financial world each day. Therefore, financial practitioners and analysts consider it an emerging issue of the data management and analytics of different financial products and services. Also, big data has significant impacts on financial products and services. Therefore, identifying the financial issues where big data has a significant influence is also an important issue to explore with the influences. Based on these concepts, the objective of this paper was to show the current landscape of finance dealing with big data, and also to show how big data influences different financial sectors, more specifically, its impact on financial markets, financial institutions, and the relationship with internet finance, financial management, internet credit service companies, fraud detection, risk analysis, financial application management, and so on. The connection between big data and financial-related components will be revealed in an exploratory literature review of secondary data sources. Since big data in the financial field is an extremely new concept, future research directions will be pointed out at the end of this study.
287	Strategic alignment between business and information technology (IT) is considered key to maximizing IT impact. Nonetheless, only seldom have exceptional achievements in performance been studied from the viewpoint of the Strategic Alignment Model (SAM). This paper describes a longitudinal case study of a Health Maintenance Organization (HMO), named here MHMO, which serves over 1.7 million members. MHMO's management decided to support strategic business via alignment of business and IT, culminating in the implementation of a business process management (BPM) system to process and display performance measurement. Applying multivariate logistic regression analysis and qualitative analysis, we analyze the improvement in MHMO's clinical performance in comparison to all the HMOs in the country between 2002 and 2005. The results clearly show a greater improvement for MHMO in the period following the BPM system implementation in 2004. Plausible drivers of this achievement are discussed, paying special attention, via the lens of the Strategic Alignment Model, to the alignment between business and IT. Besides this paper's contribution in highlighting how business and IT can be aligned to achieve ambitious strategic goals, it demonstrates the feasibility and effectiveness of measuring quality of clinical care, generally considered a complex and costly mission.
288	nan
289	Abstract Robotic process automation is a disruptive technology to automate already digital yet manual tasks and subprocesses as well as whole business processes rapidly. In contrast to other process automation technologies, robotic process automation is lightweight and only accesses the presentation layer of IT systems to mimic human behavior. Due to the novelty of robotic process automation and the varying approaches when implementing the technology, there are reports that up to 50% of robotic process automation projects fail. To tackle this issue, we use a design science research approach to develop a framework for the implementation of robotic process automation projects. We analyzed 35 reports on real-life projects to derive a preliminary sequential model. Then, we performed multiple expert interviews and workshops to validate and refine our model. The result is a framework with variable stages that offers guidelines with enough flexibility to be applicable in complex and heterogeneous corporate environments as well as for small and medium-sized companies. It is structured by the three phases of initialization, implementation, and scaling. They comprise eleven stages relevant during a project and as a continuous cycle spanning individual projects. Together they structure how to manage knowledge and support processes for the execution of robotic process automation implementation projects.
290	Sustainable development is a type of development that meets the needs of the present without compromising the ability of future generations to meet their own needs. Sustainability has recently become more and more important for businesses. This has led to what is known as Green BPM (Green business process management), in which sustainability is considered to be a business objective. The objective of this work was to carry out a systematic literature review in order to evaluate how the subject of Green BPM has evolved and how the term “Green BPM” has been conceptualised so as to propose a new definition compiled from those previously formulated; identify the impact of the incorporation of Green aspects into the BPM life cycle stages; and discover the impact of Green BPM research efforts by means of the PDCA (plan-do-check-act) model, thus identifying (1) the goals that have been proposed when Green initiatives are carried out in BPM, (2) the context in which this has been applied, and (3) the performance indicators considered. Finally, we propose a new characteristic, Process Greenability, together with its subcharacteristics, in addition to identifying the relationship between these subcharacteristics and the indicators identified to make them measurable. © 2018 John Wiley & Sons, Ltd.
291	Ports project management is crucial in economic development of archipelagic country in Southeast Asia to bridge mobilization of human and transportation activities. As such, a developing country such as the Philippines needs well-defined business processes to support ports project identification and evaluation. This paper aims to present a ports project identification and evaluation applying business process reengineering tools, which aims to enhance the efficiency and effectiveness of ports project identification and evaluation processes to its stakeholders. The paper presents the problems identified and analysis, the proposed solutions, and evaluation to aid decision-making and actions towards attainable ports project management. Practical recommendations are offered to further the proposed system design and improvement.
292	nan
293	Purpose: The purpose of this paper is to examine the way strategic approach to business process management (BPM) impacts organizational performance, both its financial and non-financial aspects, using empirical data from Croatian firms. The impact of strategic approach to BPM on process performance measurement (PPM) is examined as well. Design/methodology/approach: A questionnaire survey was conducted on a sample of 194 manufacturing and service firms in Croatia and propositions were tested using a structural equation model with SAS software. Findings: The results suggest that PPM practice is positively related to strategic approach to BPM. The impact of PPM on non-financial performance has been found, as well as the impact of non-financial performance on financial performance, thus indicating an indirect influence of PPM on financial performance. Originality/value: The paper extends the previous research that exclusively investigated impact of BPM to organizational performance. The authors extended results of previous research and found that strategic approach to BPM is an important push factor for implementation of PPM, and that PPM is an important link between BPM and improved organizational performance. © Emerald Group Publishing Limited.
294	The Internet of Things (IoT) is exploding. It is made up of billions of smart devices -from minuscule chips to mammoth machines - that use wireless technology to talk to each other (and to us). IoT infrastructures can vary from instrumented connected devices providing data externally to smart, and autonomous systems. To accompany data explosion resulting, among others, from IoT, Big data analytics processes examine large data sets to uncover hidden patterns, unknown correlations between collected events, either at a very technical level (incident/anomaly detection, predictive maintenance) or at business level (customer preferences, market trends, revenue opportunities) to provide improved operational efficiency, better customer service, competitive advantages over rival organizations, etc. In order to capitalize business value of the data generated by IoT sensors, IoT, Big Data Analytics/IA need to meet in the middle. One critical use case for IoT is to warn organizations when a product or service is at risk. The aim of this paper is to present a first proposal of IoT-Big Data-IA architectural patterns catalogues with a Blockchain implementation perspective in seek of design methodologies artifacts.
295	nan
296	The need for explainability in Business process management is tremendously increasing, especially in the age of generative AI. The number of published articles on explainable AI (XAI) has skyrocketed for five years. AI impacts the decision-making process in business analytics. Process mining as a sub-discipline of data science can play a role in explainable business decision-making. Process mining exhibits its intention in process discovery, performance measures of processes, and process improvements based on the event logs. Although the accuracy of the outcome of process mining models has been investigated at a certain level, the explainability of those is possible through the discretization of the analytic steps. As an initial step in exploring the explainability of process mining, this research conducts a technical analysis of 37 research papers submitted to the Business Process Intelligence (BPI) Challenge 2020. The main focus of this analysis aims to answer the question, "How and why a process model is produced? "To make a foundation for the research question, the notion of explainability is explored based on an Explainable AI ontology. Due to the small sample size, the study cannot identify clear trends of explainability in process mining. However, the results conclude that explainability depends on the process model's transparency and reproducibility. Moreover, further research with a large sample size is required to understand the discrete factors impacting decision-making in business process management.  © 2023 IEEE.
297	Change is a popular word since Barack Obama so successfully used it in his campaign to become president of the US. Change almost became a synonym for "yes, we can". Change, and things will improve. Suddenly change is sexy. We don't seem to suffer from resistance to change anymore. People now LIKE to change? Control usually is considered to almost be opposite to change. Control is not sexy. It is associated with accountants, budget restrictions, penalties, rules. It is considered to be counterproductive. You need it for compliance, but how easy would it be to change without control? BPM is stuck in the middle. It used to be positioned as a technology that improves efficiency, effectiveness and quality. Cheaper, faster and better. But suddenly BPM is all about Agility. BPM for change. BPM is sexy too! At the same time, BPM is considered to be a tool for compliance, risk management and a means to guarantuee SLA's, KPI's, etc. Control! So how can this be? BPM does not bring agility by itself. Nothing is more agile than processes that are not under control of any system. BPM is only called agile, because it gives more flexibility than built-in process control in legacy applications. At least, that is what we all believe (or say we believe). We call this the flexibility paradox. Process automation adds control, takes away flexibility and at the same time brings agility. © 2009 Springer Berlin Heidelberg.
298	Purpose: New maintenance hypotheses such as lean smart maintenance emphasized internal integration. Since the maintenance process is not fully integrated with other business processes, it indicates that some of the problems in the maintenance process are caused by other departments. Additionally, nothing can be managed or improved without first measuring it. In order to enhance internal integration, this study developed a model that makes use of information systems data to examine synchronization and collaboration across departments engaged in maintenance operations. Design/methodology/approach: This research connects maintenance management and business process management through information systems. A conceptual module model based on CMMS is proposed that will use data which are already available in CMMS and, using process mining, will assess the level of synchronization between departments within an organization. Findings: This conceptual model will serve as a roadmap for creating better value-added CMMS software. This system operates as a performance measurement tool in three majors, including organizational analysis, workflow analysis and eventually, a future simulation of maintenance processes. This module will serve as a decision support system, highlighting opportunities for improvement in maintenance processes. Originality/value: A practical guideline is provided for the future development of CMMSs and their enhancement to intelligence. All assumptions are based on maintenance theories, techniques for measuring maintenance performance and business process management and process mining. © 2022, Emerald Publishing Limited.
299	Process approach is a part of many organizations' management systems. Process oriented organizations focus on value added processes, their management, performance measurement, improvement and automation. However, in many higher education institutions is not process management implemented and its teaching does not always correspond with business needs and practice. This paper deals with the latter side of process management in higher education - course of process management held at Faculty of management and economics of Tomas Bata University in Zlín. The main purpose of the paper is to present the results of the research among Czech universities and their approach to BPM education and a case study of process management course and its improvement at Faculty of Management and Economics at Tomas Bata University in Zlín. To improve the course, the very aspects of process management such as customer focus or performance measurement were applied. The performed action research is then described in form of the case study.
300	There are various possibilities to evaluate the cost and time factors of processes. But these possibilities do not permit a quality assessment of business processes. For such processes, we need methods and performance measurement systems, which are not oriented solely on concrete measureable results. However, it is important to be able to assess and improve process quality. The aim of the method is to determine the quality of a process area. In addition, areas of action are discovered, in which processes can and should improve, in order to reach a more mature level. This method opens up a possibility for an organization to advance a continuous improvement of business processes with an assessment method to account for long term lasting effects. Furthermore, metrics will be established in order to measure and monitor the quality of processes and to provide a foundation which consists of a self-critical view on one's own processes. © Springer-Verlag London 2013.
301	nan
302	This study is based on government's digital transformation policy and the industry's digital development trend. Micro-Small Enterprises(MSEs) are the target customers to meet the organizational productivity management needs of key performance indicators (KPI) and project management (PjM) as the research subject, combined with management by objectives (MBO) and performance appraisal organizational management practice as a methodology, using Google's No-code smart cloud-computing service as a practical platform, integrating data input/processing/analysis/ visualization (D/IPAV®) workflows to customized develop the "Performance Visualization Cloud-computing Management System" (PVCMS) of the organization's operational data monitoring and decision-making digital dashboard. This project sets PVCMS as the core product and develops a set of indicators construction, analysis and visual monitoring that meet the performance management needs of the industry. Diagnosis and Consultant model as a solution, to follow-up actual commercialization standard operating procedure to be followed, and quick import templates for various performance management visualization modules. Its operation process is mainly divided into five stages: (1). Define performance management requirements, (2). Establish KPIs, (3). Link Indicator with performance evaluation, (4). Build performance management system, (5). Track Indicators and decision-making application.
303	Currently, business process management (BPM) is an important foundation to be able to improve competitiveness. For successful BPM implementation, the performance measurement for BPM is one of the most important issues. However, because of the wide variety of business process performance measures existing, choosing the performance measures is an extremely difficult and time-consuming task. This paper sshows how to determine which performance measures are effectively monitoring the expected outcomes of management and helps project managers to make a proper BPM investment strategy. Through a review of the literature, 24 performance measures were identified for the successful implementation of BPM performance measurement. To help advance this area of research and to help further integrate sustainability discussion into the performance measurement of BPM modeling area, this paper uses a mixed-number based neighborhood rough set approach to determine and manage these performance measures. Additionally, a case study is presented to illustrate the application of the proposed method. Insights into the application of the technique from both a research and managerial perspective are presented. Aggregate analysis for the methodology and future research directions are also introduced. ©2013 International Information Institute.
304	Educational building in United State account for around 14% of overall non-residential floor area. 76.61% of education building are twenty years old or older when the major building systems and equipment reach their service life span, and 38.30% of buildings are 50 years older or older which is nearly the expected serviceable lifespan of the buildings (CBECS, 2012). The aim of this paper is to propose a novel Building information model (BIM)-Building performance model (BPM) - Building environmental model (BEM) framework to identify the most energy efficient and cost effective strategies to renovate the existing education building to achieve the nearly zero energy goal while minimizing the environmental impact. A case building is used to demonstrate the validity of framework, and a set of building performance indicators includes energy performance, environmental impacts, occupant satisfaction are used to evaluate the renovation strategies. This novel framework further demonstrates the interoperability among different digital tools and platform as well. Lastly, the case study results highlight the particular energy profile and retrofit needs of education buildings with detailed analysis and measurement. © (2019) by International Building Performance Simulation Association (IBPSA) All rights reserved.
305	The aim of this paper is to propose a novel building information model (BIM)-building performance model (BPM)-building environmental model (BEM) framework to identify the most energy-efficient and cost-effective strategies for the renovation of existing education buildings to achieve the nearly zero-energy goal while minimizing the environmental impact. A case building, the University of Maryland's Architecture Building, was used to demonstrate the validity of the framework and a set of building performance indicators-including energy performance, environmental impacts, and occupant satisfaction-were used to evaluate renovation strategies. Additionally, this novel framework further demonstrated the interoperability among different digital tools and platforms. Lastly, following a detailed analysis and measurements, the case study results highlighted a particular energy profile as well as the retrofit needs of education buildings. Eight different renovation packages were analyzed with the top-ranking package indicating an energy saving of 62%, carbon emissions reduction of 84%, and long-term cost savings of 53%, albeit with a relatively high initial cost. The most preferable package ranked second in all categories, with a moderate initial cost. © 2018 by the authors.
306	The manufacture of high-quality cars at comparatively low-cost has gradually become the mainstream. Our study designs a set of integrated time-driven-activity-based costing (TDABC) of performance-oriented systems using the bottleneck-breaking concept of theory of constraints (TOC). We use it to provide timely and relevant information on operation resources and cost management, which is an urgent issue. Through applications of TOC to TDABC, we further integrate cost concepts into the information system of the enterprise to achieve the following objects: First, the company can concentrate its limited resources on the main problem of bottleneck operations to effectively solve the inconsistency between individual departments and overall objects of the company. Second, in business process management, the company leads all operation processes to follow three major performance indicators. Third, the production-planning units are assisted in applying the specifications and definition of product to the manufacturing cost analysis of new product development. Fourth, in the delivery time, the production and management units are assisted in giving priority to the bottleneck operations when facing rush orders. Finally, in process improvement, improving bottleneck operations fast is the key for overall profits of the corporation. © 2013 © 2013 Taylor & Francis.
307	Traditional approaches to Business Process Management (BPM) focus primarily on the process aspects, and treat the persistent data accessed and manipulated by the business processes as second class citizens. A recent approach to BPM, based on "business artifacts", is centered on a modeling framework that places data and process on an equal footing. The approach has been shown useful in various application domains, and one variant of business artifacts forms the basis of the emerging OMG Case Management Model and Notation (CMMN) standard. Research results have been developed around conceptual models, enterprise interoperation, business intelligence, and verification. This data-centric approach has the potential to provide the basis for a new generation of BPM technology in support of diverse application, and fueled by the insights into abstraction and data management that have been the hallmark of database research since the 70's.
308	nan
309	Organizations are influenced by external demands which can be represented by changes on the markets organizations are part of. Companies are operating on a new context, where the importance of sustainability has been highlighted by events such as environmental problems, social responsibility issues and quality assurance of products and services. Those aspects are represented by the areas of the Triple Bottom-Line (3BL), which treat organizations operational performance on economic, environmental and social aspects. However, organizations are still trying to develop new performance measurement systems, which relate to the 3BL and that can be used for sustainable performance assessment and benchmarking. In order to address this need, this research aims to develop a process that enables standards and guidelines to be used as tools for the establishment of a performance measurement system which can address the needs of integrated management on behalf of sustainability aspects. The method used on the development of this article is based on concepts of the Process Approach methodology from Cambridge University, as well as Business Process Management Notation to represent processes for performance assessment. Those processes were built with a high emphasis on Performance Assessment frameworks and Key Performance Indicators (KPIs) theories. The processes generated have been applied in a project of innovation in sustainable management, in which its application enabled to work with requirements from various standards and guidelines in a practical context, through the usage of indicators and performance measurement. Exemplifying the application of this process, the article will aim to clarify the usage of indicators based on standards and guidelines as a tool for sustainability assessment, through an integrated management of an organization set of standards and guidelines.
310	BPM system is an information system that is introduced to accelerate process cycle time through automation of repetitive organizational tasks. With growing importance of business process management, functionality of BPM systems is now extended to support the design, analysis and optimization of business processes. In particular, BPM brought in new applications related with managing business processes; Business Activity Monitoring (BAM) and Business Process Analysis (BPA). In this study, we raise four issues regarding the successful implementation of BAM and discuss what companies should do to address them. Specifically, we will focus on the identification of Key Performance Indicators (KPIs), mapping the KIPs to the BPM metrics. Designing the analysis methods and building digital dashboards. By linking BPM and BPA, BAM provides the visibility on what goes on with several major business processes and all the related information that will help managers make a well-informed, timely decision, so that it significantly accelerates the enterprise's reaction time. © Medwell Journals, 2009.
311	The concept of Internet of Things (IoT) is important in collecting the shop floor data and transmitting it into the Information System in real time. The rapid proliferation of IoT in recent days has given rise to demands for clear definition among metrics as important sources of the performance measurement. This requirement comes from the various usage of IoT data: One raw IoT data is able to produce many metrics. In order to understand it, we need to consider the usage points of IoT data at different management levels. And by composing company management levels: Strategic level, Tactical level and operational levels, we are able to analysis usage of IoT data among management levels. The purpose of this study is to present the work flow of the performance measurement process with regard to monitoring the IoT outcomes. Also, we try to explore the core issues with Business Process Modelling and simulation. As a result of study, we expect that how IoT data is processed and which level needs an IoT data as a performance metrics. We use BPM as a description of activities that constitute a performance measurement. Those are described in a graphical way using some components: Agent, Resources, Process, flow logic, and etc. Agent is management level which is consists of following three level: Strategic level, Tactical level and operational levels. Resources is defined as "IoT outcomes that is of utility and under the control of some agents?. Process has an acitivity that uses the resources to produce new or modify existing process. The identification and discussion of result of BPM reflects how IoT data is handled and make a clear distinction of metrics usage among management levels.
312	We study the problem of computing containment queries on sets which can have both atomic and set-valued objects as elements, i.e., nested sets. Containment is a fundamental query pattern with many basic applications. Our study of nested set containment is motivated by the ubiquity of nested data in practice, e.g., in XML and JSON data management, in business and scientific workflow management, and in web analytics. Furthermore, there are to our knowledge no known efficient solutions to computing containment queries on massive collections of nested sets. Our specific contributions in this paper are: (1) we introduce two novel algorithms for efficient evaluation of containment queries on massive collections of nested sets; (2) we study caching and filtering mechanisms to accelerate query processing in the algorithms; (3) we develop extensions to the algorithms to a) compute several related query types and b) accommodate natural variations of the semantics of containment; and, (4) we present analytic and empirical analyses which demonstrate that both algorithms are efficient and scalable.
313	Similarity metrics applied to business processes are used to compare and assess the similarities and differences between a set of process models. The results of this comparison can then serve as input to take management decisions, such as to prevent the proliferation of process variants. This is particularly useful in large (enterprise or governmental) organizations with multiple organizational units that share the same business processes. Examples include faculties of a university and their student enrollment process, hospitals or primary care centers of National Health Services and their medical appointment process, or even the pick and pack process across several warehouses of a large company. Due to many aspects (i.e. local policies, resources, socio-technical aspects, culture), a certain business process is individually evolved and refined across the multiple organizational units of the same organization. Organizations have then to deal with several process variants, which hampers the collection of performance indicators, optimization procedures and business process management overall. In this paper, we perform a similarity based approach to assess the similarities and differences that exist between home healthcare processes for two public primary healthcare centers in Portugal. We will achieve this by eliciting business process models according to best practices. Then, we lead a similarity based comparison between the elicited models. This is in order to show how much models are different in the same organization. © 2016 The Authors.
314	Business Process Management (BPM) is widely seen as the top priority in organizations wanting to survive competitive markets. However, the current academic research agenda does not seem to map with industry demands. In this paper, we address the need to identify the actual issues that organizations face in their efforts to manage business processes. To that end, we report a number of critical issues identified by industry in what we consider to be the first steps towards an industry-driven research agenda for the BPM area. The reported issues are derived from a series of focus groups conducted with Australian organizations. The findings point to, among others, a need for more consolidated efforts in the areas of business process governance, systematic change management, developing BPM methodologies, and introducing appropriate performance measures. © 2006 Indulska, Chong, Bandara, Sadiq, Rosemann.
315	The aim of this paper is to introduce a matrix model to be used for business process management. The process control matrix is applied in the case of the Romanian Farm Land Register (cadastre services) - which is a premiere and an original contribution. The Key Performance Indicators (KPI) and control matrix were developed using statistical methods while six sigma methodology and lean production systems were used to select the relevant factors. The results are positive and managerial implications are associated to the advantages of the model - mainly a higher stability of the process outputs - for the benefit of the whole organization, which is transiting from unstructured activities to a process-focused organization.
316	nan
317	nan
318	Abstract BPMN Sketch Miner is a modeling environment for generating visual business process models starting from constrained natural language textual input. Its purpose is to support business process modelers who need to rapidly sketch visual BPMN models during interviews and design workshops, where participants should not only provide input but also give feedback on whether the sketched visual model represents accurately what has been described during the discussion. In this article, we present a detailed description of the BPMN Sketch Miner design decisions and list the different control flow patterns supported by the current version of its textual DSL. We also summarize the user study and survey results originally published in MODELS 2020 concerning the tool usability and learnability and present a new performance evaluation regarding the visual model generation pipeline under actual usage conditions. The goal is to determine whether it can support a rapid model editing cycle, with live synchronization between the textual description and the visual model. This study is based on a benchmark including a large number of models (1350 models) exported by users of the tool during the year 2020. The main results indicate that the performance is sufficient for a smooth live modeling user experience and that the end-to-end execution time of the text-to-model-to-visual pipeline grows linearly with the model size, up to the largest models (with 195 lines of textual description) found in the benchmark workload.
319	Implementation of simulation technologies for surgery training is a challenging problem nowadays that involves modern information technologies to perform a breakthrough in medical higher education. Still using of various surgery simulators in practice requires much assistance from teachers that need to monitor the training process and manage the students. In order to reduce these efforts and improve the efficiency of simulation surgery training there is proposed a software solution based on subject-oriented representation of training process, which allows higher customization of education making it adaptive and individualized. This paper describes this solution based on the concept of management by conditions and implemented in training simulators for laparoscopy and endovascular surgery training delivered as a result of "Virtual Surgeon" and "Inbody Anatomy" projects. The proposed approach was implemented by a software development kit (SDK) that is destined to develop on its basis new training simulation solutions for surgery education. The results and their probation in practice are illustrated by the simulation centre established at Samara State Medical University.
320	In this paper, we analyse how decentralised digital infrastructures can provide a fundamental change in the structure and dynamics of organisations. The works of R.H. Coase and M. Olson, on the nature of the firm and the logic of collective action, respectively, are revisited under the light of these emerging new digital foundations. This study proposes a novel analysis of how these instruments can affect the fundamental assumption on the role of organisations, either private or public, as a mechanism for the coordination of labour. We propose that these technologies can fundamentally affect: (i) the distribution of rewards within an organisation and (ii) the structure of its transaction costs. These changes bring the potential for addressing some of the trade-offs between the private and public sectors.
321	Over the past decade, process mining has emerged as a research field analyzing processes using event data. Unlike traditional data mining techniques, which focus on specific steps, process mining looks at end-to-end business processes. This is made possible by the increasing availability of event data and advancements in process discovery and conformance checking techniques. Process models, which were previously created manually without using event data, are now used for analysis, simulation, verification, and enactment by Business Process Management and Workflow Management systems (BPM/WFM). Process mining techniques utilize event logs to discover, analyze, and enhance business processes by examining the activities performed by people, machines, and software. In this paper, four process mining miners (Alpha Miner, Alpha++ Miner, Genetic Miner and Heuristics Miner) were utilized to enhance the processes of revenue department in the municipality of Hamadan based on the event logs. The contextualization of this research lies in its importance in improving municipal revenue practices, enhancing transparency, and optimizing resource allocation, which is a critical aspect of efficient governance. Process mining offers a data-driven approach to identify bottlenecks, delays, and deviations in the revenue process, ultimately leading to more effective decision-making and improved public service delivery. The results demonstrated that the Genetic Miner achieved the best result with an impressive 98% overall score, which is an average across key performance metrics including fitness, simplicity, precision, and generalization. The implications of this finding highlight the potential for municipalities and similar organizations to leverage process mining as a means of enhancing their revenue processes, thereby fostering more efficient resource allocation and governance. ©2024 IEEE.
322	Abstract Data science and big data analytics (DS &BDA) methodologies and tools are used extensively in supply chains and logistics (SC &L). However, the existing insights are scattered over different literature sources and there is a lack of a structured and unbiased review methodology to systematise DS &BDA application areas in the SC &L comprehensively covering efficiency, resilience and sustainability paradigms. In this study, we first propose an unique systematic review methodology for the field of DS &BDA in SC &L. Second, we use the methodology proposed for a systematic literature review on DS &BDA techniques in the SC &L fields aiming at classifying the existing DS &BDA models/techniques employed, structuring their practical application areas, identifying the research gaps and potential future research directions. We analyse 364 publications which use a variety of DS &BDA-driven modelling methods for SC &L processes across different decision-making levels. Our analysis is triangulated across efficiency, resilience, and sustainability perspectives. The developed review methodology and proposed novel classifications and categorisations can be used by researchers and practitioners alike for a structured analysis and applications of DS &BDA in SC &L.
323	In today's global market the main focus of competition is not only between different companies but also between supply chains. Technological changes and organizational improvements are important for effective supply chain management (SCM), however, the main cause of SCM improvements is not the implementation of an information system (IS) itself, but rather a change and an integration of business processes. The paper summarizes the most important concepts of SCM and specifically concentrates on the importance of business process management (BPM) in supply chains, because full advantages can be realized when business processes in the supply chain are well defined, integrated and managed. The main purpose of this paper is to show that successful SCM calls for the maturity of supply chain processes in all involved companies and at the supply chain level, which can be realized by using effective BPM methods. A necessary condition for growing of SCM in terms of supply chain process maturity levels is an inter-organizational information system development and process renovation. Yet, BPM should not be considered as a one-time project of IS implementation and process change, but as a permanent process performance measurement, analysis and continuous improvement of the supply chain processes. The concepts are illustrated with a case study of fuel supply process.
324	The operational continuity of a business process is an important performance indicator that contributes to the perceived quality of service delivery, hence it is important to understand and monitor the underlying issues that can affect the performance of the process. These issues might have been foreseen at the beginning of the process design and deployment phase, or might have emerged during the execution of the process, and must be viewed as risk threats to the business process. In most cases risk is only considered from the project management angle or from financial, market, insurance and other general business perspective. Operational risk at service provision level receives little attention and thus there is a need to develop methodologies and tools to identify and analyse business operational risks. The authors concentrate on operational risk for business process management by introducing a novel way for applying risk assessment frameworks at the process activity level. The paper briefly reviews existing risk frameworks and selects the COSO framework as the most appropriate for business processes. This framework is modified in order to address and evaluate the main elements of business processes. It defines a statistical approach towards operational risk assessment by quantifying risk factors in each activity within a business process for service provision. A risk forecast is produced for each activity, and for the whole process, to model associated uncertainties and to contribute in identifying the risk factors that affect the business process objectives. To demonstrate the framework, it is applied to a hypothetical process involving setting up a network service. These results help to advise on which risk factors need higher attention in order to achieve successful process fulfilment. © Springer Science+Business Media, Inc. 2007.
325	With few exceptions, the opportunities cloud computing offers to business process management (BPM) technologies have been neglected so far. We investigate opportunities and challenges of implementing a BPM-aware cloud architecture for the benefit of process runtime optimization. Processes with predominantly automated tasks such as data transformation processes are key targets for this runtime optimization. In theory, off-the-shelf mechanisms offered by cloud providers, such as horizontal scaling, should already provide as much computational resources as necessary for a process to execute in a timely fashion. However, we show that making process data available to scaling decisions can significantly improve process turnaround time and better cater for the needs of BPM. We present a model and method of cloud-aware business process optimization which provides computational resources based on process knowledge. We describe a performance measurement experiment and evaluate it against the performance of a standard automatic horizontal scaling controller to demonstrate its potential. © 2014 IEEE.
326	Companies struggle to find ways to manage intra- and interorganizational service networks communicating in a distributed fashion across the globe. We review the state-of-the-art of managing choreographed service networks and put it in relation to process analytics and complex event processing (CEP) against the background of Cloud computing. We present an initial architecture for Event-driven Business Activity Management of service networks which also takes into consideration levels of virtualization. The architecture can serve as a blueprint for flexible business activity monitoring applications as well as closed loop service choreography control solutions. We illustrate the interaction of Cloud infrastructure, services networks, and CEP systems with a number of use cases. In addition, we discuss future research directions based on our experiences from early prototypes.
327	Timely insight into a company's business processes is of great importance for operational efficiency. However, still today companies struggle with inflexibility of monitoring solutions and reacting to process information on time. We review the current state of the art of business process management and business activity management. Based on that we develop an architecture for event-driven business activity monitoring which is capable of standalone process analytics or can make use of complex event processing engines to filter and aggregate process events in realtime. We discuss advantages and disadvantages of the two options in terms of ease of use, flexibility, and extensibility and close by introducing on future research directions based on our experiences from a prototypical implementation using standard software.
328	The impact of financial risks extends beyond the normal operation and survival of industrial and commercial enterprises and financial institutions. They also have the potential to impede the stable development of a country's and even the world's financial economy. This is clearly demonstrated by the severe consequences of the frequent financial crises that have occurred in recent years. It thus follows that the prevention of financial risks has become one of the core tasks of the operation and management of industrial and commercial enterprises and financial institutions. Portfolio optimization techniques are employed in the construction of a variety of asset allocation models, with reinforcement learning algorithms used to dynamically adjust investment strategies with the objective of maximizing returns and minimizing risks. The preliminary construction of an asset allocation model is achieved through the utilization of a genetic algorithm. Genetic algorithms emulate the processes of natural selection and genetic variation to identify the optimal portfolio of assets that will yield the greatest returns at a pre-established level of risk. Subsequently, the Deep Q-Learning algorithm is introduced to facilitate dynamic adjustments and optimization of the asset allocation, based on the initial construction. Deep Q-learning employs deep neural networks to forecast the prospective returns of disparate investment strategies, thereby optimizing the decision-making process through continuous learning and updating. The combination of genetic algorithms and deep Q-learning enables the system to identify the optimal investment strategy under a diverse range of initial conditions and to adapt it in real-time to respond to market fluctuations and uncertainties. The experimental analysis demonstrates that the proposed method exhibits an exemplary capacity for risk control and a robust ability to generate stable income growth across diverse market environments. In simulation experiments, portfolios constructed using this method demonstrate lower volatility and higher average returns than those generated through traditional methods.
329	Business performance management (BPM) systems involve many features different from traditional Enterprise resource planning (ERP) applications. Based on academic research and industrial experiences on developing BPM systems, this paper describes a framework and methodology for understanding the process of BPM design and implementation projects. The methodology was applied and proved in developing BPM systems for large companies in China. This paper reviews the researches of BPM system development and discusses the concept and the methodology for developing BPM systems. Based on the real case study, the research analyzes the characteristics and critical issues of the design and the implementing of BPM systems. It discusses the concept and the basic working principles of BPM systems. A conceptual framework of the methodology for developing BPM systems is built upon the study.
330	This paper is about business process management (BPM) and business activity monitoring (BAM) using event processing. We will show why the management of business processes is important for all further steps towards an event-driven and real time enterprise. That is process automation using workflow engines and standards like the Web Service Business Process Execution Language (BPEL). As an underlying middleware platform we use the service oriented platform SOPware of Deutsche Post AG.Events are emitted from all layers, the middleware platform layer and the business process layer, and figuratively build "event clouds". Event processing functionalities will correlate both "event clouds" and feed business activity monitoring. There, enterprise performance cockpits and dashboards depict the performance of the enterprise and of its processes.
331	Cloud computing services have evolved to a sourcing option that promises a wide range of benefits, such as increased scalability and flexibility at reduced costs. However, many enterprise applications are subject to strict requirements – e.g. regarding privacy, security and availability – and are embedded into complex enterprise IT architectures with a multitude of interdependencies. For these reasons, many decision makers have developed a sceptical stance towards cloud computing. A solution might be a hybrid (local/cloud infrastructure) approach where only suited components are migrated to a cloud infrastructure. This, however, has significant architectural consequences that need to be taken into account. This contribution suggests a cloud migration framework that will be implemented as an IT-based decision support system based on modelling the interdependencies between components. The approach is illustrated with the example of Business Intelligence (BI), i.e. integrated approaches to management support. The underlying decision model would particularly consider data transfer volumes, performance, sensitivity of cloud based data repositories, as well as exposure to public networks. The potential of such an approach is illustrated with a selected set of BI scenarios. Based on this, conclusions are derived and generalised for approaches taking into account deployments on both the local premises and cloud infrastructures.
332	Business Process Management Systems focuses on the development of the company's business processes in improving the relationship between the customer and the supplier (supply chain management) to fulfill customer demand. This process focuses on understanding the needs of the company's business processes to improve employee performance. The purpose of the study was to define business process management systems implementation model that can be used to measure employee performance improvement. The research methodology used the literature study, observations, questionnaires, and analysis of data using factor analysis. Results obtained from the research is a new factor analysis and indicators that can be used as a basis business process management systems implementation model for employee performance measurement model. Thus it can be concluded that in this study, the example of the company used in the study has an inadequate business process management system so that the results of this study produce a business process management implementation model that can be used as a benchmark in improving employee performance in a better direction. © 2018 IEEE.
333	In this paper, the main challenges of applying ICT in policy modeling are described and a solution is proposed, which emphasizes policy impact exploration, monitoring and risk management. State of the art of policy modeling is given, with the summary of those features of our solution, which goes beyond the available approaches. The paper will be structured as follows: First, the challenges of the ICT utilization for policy modeling are detailed. Next theoretical background of policy modeling is discussed, followed by research overview. The proposed solution – policy modeling cycle and the corresponding system is presented in the following section. Finally, conclusion and future work are shown.
334	Simulation optimization (SO) is the process of finding the optimum design of a system whose performance measure(s) are estimated via simulation. We propose some ideas to improve overall efficiency of the available SO methods and develop a new approach that primarily deals with continuous two dimensional problems with bounded feasible region. Our search based method, called Adaptive Partitioning Search (APS), uses a neural network as meta-model and combines various exploitation strategies to locate the optimum. Our numerical results show that in terms of the number of evaluations (simulation runs) needed, the APS algorithm converges much faster to the optimum design than two well established methods used as benchmark.
335	In this paper we present the problem of optimizing a business process model with the objective of finding the most beneficial assignment of tasks to agents, without modifying the structure of the process itself. The task assignment problem for four types of processes are distinguished and algorithms for finding optimal solutions to them are presented: 1) a business process with a predetermined workflow, for which the optimal solution is conveniently found using the well-known Hungarian algorithm. 2) a Markovian process, for which we present an analytical method that reduces it to the first type. 3) a nonMarkovian process, for which we employ a simulation method to obtain the optimal solution. 4) the most general case, i.e. a nonMarkovian process containing critical tasks. In such processes, depending on the agents that perform critical tasks the workflow of the process may change. We introduce two algorithms for this type of processes. One that finds the optimal solution, but is feasible only when the number of critical tasks is few. The second algorithm is even applicable to large number of critical tasks but provides a near-optimal solution. In the second algorithm a hill-climbing heuristic method is combined with Hungarian algorithm and simulation to find an overall near-optimal solution for assignments of tasks to agents. The results of a series of tests that demonstrate the feasibility of the algorithms are included.
336	Information technology (IT) has already gone beyond being a supportive tool for businesses. Strong competition and increased costs force businesses act more efficiently and rapidly, so almost in every business, the operations are carried out in IT platforms where the processes are automated. These platforms are referred to as Business Process Management (BPM) Suites. With this motivation, most companies analyze and reengineer their workflows. At this point, it is vital to be able to monitor current or reengineered business processes with key performance indicators and keep the process flows under control. This introduces a challenge for the management to evaluate how any particular modification to any of the process workflows affects the performance measures. Therefore simulation becomes an essence in the contemporary management of businesses. In practice, major business process management softwares include some kind of simulation environment either as an embedded engine within the modeling component or through third-party integration. In this study a general purpose simulation platform is analyzed and a mapping algorithm is developed to integrate modeling capabilities of a BPM tool with this simulation environment.
337	Cloud computing has strongly imposed itself on the area of research for both industry and academics requirements. Cloud providers are moving or planning to move their applications to the cloud environment attaining infrastructures and different cloud service organizations. This task includes a lot of details to be academic selected to tackle such a task raising up a lot of questions which needs to be addressed in a scientific and practical approach. Most researches concerning this issue stressing on the challenges of the migration process to the cloud. But few studies stresses on the life running of practical applications in the cloud environment monitoring some selected performance measures to be compared before and after migration .The objective of this process could assist in taking a critical decision regarding either to keep or modify the practical migrated application. The Objective of this research is to evaluate the performance measures of a real running transaction processing system (TPS) as a selected case study before and after migration to the cloud environment. Plotting and analysis of the conducted results over the Amazon EC2 cloud environment as public cloud and a selected specific private cloud indicates 52% compared to the performance measures before migration which strongly support the usage of cloud computing approach for practical case studies without concerning about any performance degradation. The lower overhead cost for migration to public cloud environments proves the robustness of the proposed approach for this research.
338	Recently, strong interests in the real-time performance management are increasing to gain competitive advantages in the rapidly changing business environment. For better business performance or continuous process improvement of an enterprise, real-time measurement and analysis of the performance of managerial activities is essential. Business activity monitoring (BAM) which provides real-time access to key performance indicators is one of core elements for the real-time performance management. A BAM system prototype is designed and implemented for a global automotive company in this paper. This paper presents the design procedure and implementation result of BAM system. This paper is expected to be a practical help to the practitioners who are planning and executing the BAM system implementation for the real-time performance management.
339	As business values pursued by today's organizations are abstract concepts, measurement of these values and their achievement is not straightforward. This paper proposes a value achievement measuring and managing framework, which recursively decomposes business values to construct a value hierarchy and then links it with the business process hierarchy. The framework makes it possible to measure value achievement, trace values to processes, and take necessary actions in response to the measured progress in value achievement. Copyright © 2012 The Institute of Electronics, Information and Communication Engineers.
340	Big data technology promises to transform the way in which medical care is delivered and to lead healthcare professionals to safer and more accurate diagnosis and focused treatments. Hence, healthcare professionals should increase their reliance on big data technology for diagnosis and decision making. In order to support this transformation in medical practice, healthcare professionals will need to be trained in big data usage and also to be guided and supported, during the whole learning process. Process-oriented e-learning systems seem to be ideal for healthcare professionals' training as they introduce flexible learning pathways so they can progress through the content in a variety of ways based on their needs and preferences. In such a workflow-based e-learning environment, Learning Analytics enhances the concept of "personalized learning", and thus, promises to provide improved learning outcomes by monitoring and predicting healthcare professionals' learning performance and enabling trainers to tailor training to each healthcare professional's level of need and ability. To this end, this paper presents a Learning Analytics approach for gaining insight into healthcare professionals' learning progress and evaluating the learning process in a workflow-based e-learning environment. Oracle's BPM Studio Analytics component was used to monitor the performance of the learning process by measuring key performance indicators (e.g. average time to complete an activity). © Proceedings of the 13th European, Mediterranean and Middle Eastern Conference on Information Systems, EMCIS 2016. All rights reserved.
341	The characteristic feature of e-business applications is the complexity due to the large number of factors that have to be taken into consideration and aligned with regard to the products and services offered, the business processes used, the organization and the information technology (IT) applied. Both researchers and practitioners state, that the alignment between IT and the competitive strategy of the business is paramount. In this paper, we will discuss the E-BPMS modeling framework that takes into account the requirements of a complex e-business application development and we will describe a case from the insurance sector as a proof of concept.
342	This work gives an overview of the future research challenges on enabling technologies for service-based applications that have been identified in the network of excellence S-Cube. Service-based applications comprise three layers: business processes, service compositions and services and service infrastructures. The goal of this work is to present a roadmap for future research in technologies for software and system services.
343	A number of e-Processes (i.e. software processes for developing e-Commerce information systems) exist in industry. We presuppose that for a subclass of these their targeted quality is considered as a driving force of system development. The complexity of selecting a well-suited e-Process for a case at hand is thus increased as e-Process knowledge needs to be blended with system quality knowledge. We suggest an approach for selecting a best suited one out of a set of admissible e-Processes using the Analytic Hierarchy Process for knowledge blending and discuss how the data generated can be used for assuring the sensibility of the selection. We explain the AHP-based selection procedure, tradeoff- and sensitivity analysis; briefly discuss a case study and the applicability of this approach.
344	nan
345	Refactoring a business process model (BPM) may improve its usability (understandability, modifiability) performance, and/or ease its maintainability. So-far proposed refactoring approaches have used either refactoring which focuses on structural aspects and/or semantic information. Nevertheless, these aspects provide a partial view of the model. As we show in this paper, combining the semantic and structural aspects with the temporal aspect decreases further the complexity of a business process modelled in BPMN and enhances its performance. Our method uses a set of transformation rules. We illustrate their efficiency through well-established performance measures (temporal and cost) and structural measures (complexity). Copyright © 2019 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved
346	In the automation industry an increasing need for integration exists, spanning from field level to enterprise resource planning. An important requirement is the adaptability of the involved production processes, because industry must be able to react quickly to new situations and challenges. Complex Event Processing (CEP) is a promising technology to detect and react to such situations. However, current approaches for CEP often mix the derivation of high-level business events with their interpretation and follow a bottom - up development that is not focused on Key Performance Indicators (KPIs). Consequently, maintainability and the required adaptability are hard to achieve.In this paper, we investigate the separation of two viewpoints in a CEP application: i) modeling critical business situations with the reactions to be taken and ii) aggregation of the necessary base data to distill key performance indicators. Additionally, we present a methodology for the engineering of these viewpoints. This gives guidance for the development of the underlying eventing infrastructure and provides a goal/KPI-oriented approach.
347	nan
348	The first purpose of this paper is to improve business processes in an industrial firm with business process modelling notation (BPMN) and business process execution language (BPEL). The second purpose is to provide a scientific approach for bringing business analysts and IT professionals together in a framework of an action research (AR). The research is conducted in one of the biggest distribution companies in Iran. BPMN is applied to model as-is and to-be situations of sale and distribution process. Both as-is and to-be models were simulated to compare their performance indexes. Moreover, models were implemented using BPEL, so that the model can be used for automating and improving the process. In this study, AR methodology was used to find a resolution of an organisational issue with those who experience this issue directly and to improve scientific knowledge and real-life contexts simultaneously. Copyright © 2011 Inderscience Enterprises Ltd.
349	Abstract Business process management (BPM) is a mature discipline that drives corporate success through effective and efficient business processes. BPM is commonly structured via capability frameworks, which describe and bundle capability areas relevant for implementing process orientation in organizations. Despite their comprehensive use, existing BPM capability frameworks are being challenged by socio-technical changes such as those brought about by digitalization. In line with the uptake of novel technologies, digitalization transforms existing and enables new processes due to its impact on individual behavior and needs, intra- and inter-company collaboration, and new forms of automation. This development led the authors to presume that digitalization calls for new capability areas and that existing frameworks need to be updated. Hence, this study explored which BPM capability areas will become relevant in view of digitalization through a Delphi study with international experts from industry and academia. The study resulted in an updated BPM capability framework, accompanied by insights into challenges and opportunities of BPM. The results show that, while there is a strong link between current and future capability areas, a number of entirely new and enhanced capabilities are required for BPM to drive corporate success in view of digitalization.
350	nan
351	Process Mining concerns discovering insights on business processes from their execution data that are logged by supporting information systems. The logged data (event log) is formed of event sequences (traces) that correspond to executions of a process. Many Deep Learning techniques have been successfully adapted for predictive Process Mining that aims to predict outcomes of processes, remaining time of the process execution, the next event, or even the entire suffix of running traces. Traces are multimodal sequences and very differently structured than the natural language sentences or images often used in Deep Learning. This may require a different approach to processing. Relevant challenges may be the skewness of trace-length distribution and of the activity distribution in real-life logs. So far, there has been little focus on these differences. For suffix prediction, the performance of Deep Learning models was evaluated only on average measures and for a small number of real-life logs with different pre-processing and evaluation strategies, which makes a comparison difficult. We provide an unified end-to-end framework and compare the performance of seven state-of-the-art sequential architectures in common settings. Results show that sequence modeling still has a lot of room for improvement for the majority of the more complex datasets. Further research is required to get consistent performance not just in average measures but over all the prefixes.
352	Key Performance Indicators (KPIs) are crucial tools that are remarkably used to evaluate business performance. Recently, the management of KPIs has fascinated the focus of both academic and business professionals, and that lead to the development of research on various methods dealing with issues such as modeling, maintenance, and expressiveness of KPIs. As a need for organizations and processes to adapt to continuously changing demands, the KPIs used to measure their effectiveness evolve too. In order to make KPI management easier, this research aims to define the best sequence of KPIs evaluation based on semantic relations. After an extensive analysis of the literature on KPIs ontologies, it proposes the idea of KPIs prioritization on the basis of relations among different categories of kpis established by a KPIs ontology. Our approach can be used independently from the particular KPI’s management strategy being employed. Copyright © 2023 by SCITEPRESS – Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)
353	Business imperatives are changing for every industry across the globe. The focus is on transforming supply chain by improving its performance and efficiency. In today's dynamic world Internet of Things (IoT) is significantly contributing by the use of connected devices. IoT facilitates with real time information using automated and intelligent seamless processes in the supply chain. The objective of this study is to understand the benefits and challenges of integrating IoT in supply chain. The research has done an extensive literature review to explore the role of IoT as an enabler for end to end supply chain. Technology cannot be functional without the intervention of channel partners. Therefore, the paper tries to explore and develop an integrated framework to link IoT with SCM and further attempts to see its implication on HR Management. Limited research has assessed the inter linkages between SCM performance and HR Management because of the intervention of technology, especially IoT. The researcher's anticipate that finding of this paper will be practical and will be beneficial for researchers, academicians as well as practitioners. The research would certainly help practicing managers to comprehend the significance and role of IoT in gaining SCM effectiveness by effective HR Management. The study would also broaden the understanding of interdisciplinary approach at the academic level. This transformation can be driven by the perception of motivated individuals and channel partners in end to end supply chain. Satisfied HR at individual and channel level is ultimate and vital goal of every supply chain.
354	Process mining has proven effective in explaining the&nbsp;underlying processes of systems, thereby improving systems’ understanding, analysis, and operational efficiency. Process mining, however, often falls short in addressing multiple dimensions of systems’ behaviors, limiting its ability to provide comprehensive insights for systems’ performance and optimization opportunities. In this paper, we introduce an enhancement to conventional process mining that we term Multi-flow Process Mining (MFPM), which effectively extracts process flows across different system dimensions, such as time, energy, waste, and carbon footprint. MFPM enables a more comprehensive view of a system's dynamics, enabling holistic decision-making for enhanced system efficiency. We detail the framework of MFPM, outline corresponding data requirements, and introduce an expanded version of Petri nets—used here as a modeling formalism to describe and analyze multi-flow system processes. Through a detailed case study, we demonstrate the practical application of MFPM in capturing and analyzing multifaceted aspects of systems.
355	The performance indicators are essential for showing with clear measures the company’s performance, according to the information needs exposed by the administration, however is a need to move forward in the process to promote the strategic alignment and prepare them for implementation of the strategy. This research aims to propose a method of support for the improvement of management of companies through the integration of processes with the strategic guidelines. The method was developed from the combination of a strategic management methodology based on performance indicators and process management. The results with the partial application of the method were satisfactory because they show that it extends the vision of the manager and approaches the operational and the strategy. This contributes not only in the case of the organisation analysed, but also for companies from other areas of activity, in order to perform a more effective and competitive management. Copyright © 2019 Inderscience Enterprises Ltd.
356	nan
357	The assessment and improvement of business processes is an important driver of success in organizations. However, as opposed to established KPIs and other metrics, the sustainability of business processes is much less straightforward to measure and quantify, partly due to the term's ambiguity and an inherent difficulty to be measured. In order to facilitate sustainability-oriented process redesign beyond greenhouse gasses, existing methods can be enriched by considering additional information from methods such as Life Cycle Assessment. This enables a holistic and flexible analysis, and can serve as a measurable driver for process redesign. Copyright © 2022 for this paper by its authors
358	Abstract Given the continuous global degradation of the Earth’s ecosystem due to unsustainable human activity, it is increasingly important for enterprises to evaluate the effects they have on the environment. Consequently, assessing the impact of business processes on sustainability is becoming an important consideration in the discipline of Business Process Management (BPM). However, existing practical approaches that aim at a sustainability-oriented analysis of business processes provide only a limited perspective on the environmental impact caused. Further, they provide no clear and practically applicable mechanism for sustainability-driven process analysis and re-design. Following a design science methodology, we here propose and study SOPA, a framework for sustainability-oriented process analysis and re-design. SOPA extends the BPM life cycle by use of Life Cycle Assessment (LCA) for sustainability analysis in combination with Activity-based Costing (ABC). We evaluate SOPA and its usefulness with a case study, by means of an implementation to support the approach, thereby also illustrating the practical applicability of this work.
359	Performance analysis from process event logs is a central element of business process management and improvement. Established performance analysis techniques aggregate time-stamped event data to identify bottlenecks or to visualize process performance indicators over time. These aggregation-based techniques are not able to detect and quantify the performance of time-dependent performance patterns such as batches. In this paper, we propose a first technique for mining performance features from the recently introduced performance spectrum. We present an algorithm to detect batches from event logs even in case of batches overlapping with non-batched cases, and we propose several measures to quantify batching performance. Our analysis of public real-life event logs shows that we can detect batches reliably, batching performance differs significantly across processes, across activities within a process, and our technique even allows to detect effective changes to batching policies regarding consistency of processing. © 2019, Springer Nature Switzerland AG.
360	In today's fast changing business world, the fulfillment of process goals needs to be constantly evaluated and adjusted. But processes are often carried out by systems which are not process aware. aPro is a modular architecture for business process optimization. In aPro process models can't be guaranteed to be executable but need to be monitored. In this paper, we propose a modeling language for process metrics, key performance indicators and goals and use the interchange format ProGoalML to automate creation and setup of monitoring infrastructure. © 2012 Springer-Verlag.
361	Today event-driven business process management has matured from a scientific vision to a realizable methodology for companies of all sizes and shapes. However, leveraging the power of complex event processing for supporting business process monitoring is cumbersome because of the complicated modeling of rules and alerts as well as key performance indicators in machine readable format using the event languages. However, using a model-driven approach for generating a monitoring infrastructure based on events like the aPro architecture is one possibility to enable companies with various infrastructures to leverage the advantages of business process monitoring. This paper describes how KPIs are modeled and transferred into event rules by a model-driven approach. © 2013 Springer-Verlag Berlin Heidelberg.
362	Several organizations choose to be process-oriented. They apply the concept of business process management and focus on business processes instead of emphasizing functional structures, i.e. they explicitly design and document their processes, implement the process owner role, employ process performance measurement, etc. This paper empirically explores the outcomes of business process management by conducting interviews with a total of 44 process-oriented firms. Key findings indicate that process orientation leads to higher transparency, clear responsibilities, higher efficiency, structure and tidiness, higher product quality, faster throughput times, and better customer orientation. ©2009 IEEE.
363	Purpose: Attention to processes has increased, as thousands of firms have adopted the process view of their organization. Process orientation (PO) means focusing on business processes rather than emphasizing functional structure or hierarchy. Despite the huge growth in the business process management literature, a methodological gap still remains about a certain ambiguity in the definition of the construct specifying its theoretical domain and dimensionalization. The aim of this paper is to contribute to the literature on PO through the creation and validation of a model to measure the key dimensions of the PO construct. Design/methodology/approach: The authors derive from literature several dimensions which shape the concept of PO. In a second step, the study includes factor analysis on a sample of 152 Austrian manufacturing companies to verify that the model is empirical valid. Findings: The paper provides insight in the concept of PO. It concludes that PO is a multidimensional construct, consisting of the following dimensions: design and documentation of business processes; management commitment towards PO; the process owner role; process performance measurement; a corporate culture in line with the process approach; application of continuous process improvement methodologies; and process-oriented organizational structure. Research limitations/implications: The sample used in this work only included Austrian firms operating in manufacturing industry. Generalizability of the findings to other industries or other countries is open to scrutiny. Originality/value: Several studies into process management use proxy variables as an indicator for PO (e.g. ISO 9000 certification). Other studies treat the construct as a unidimensional measure. However, unidimensional measures meet with increasing criticism, as they turn out to be insufficient to capture the richness of such a complex construct. This paper attempts to rectify the content deficiencies in the literature on the construct by specifying its theoretical domain and dimensionalization. © Emerald Group Publishing Limited.
364	This article explicitly outlines an approach designed to allow optimal utilisation of Analytics in the industry setting. The paper focuses on the key stages of the Analytics process that have not been identified in previous Analytics methodologies and draws on industry, consulting and research experience to show that correct design of the project trajectory can allow the industry to fully realise the benefits that Analytics has to offer. As the case studies provided demonstrate, it is often the skipping of key stages, especially the preliminary analysis stage, that are currently responsible for preventing success of an Analytics project. It has been shown how, using the outlined approach, project can achieve maximum effectiveness and business buy-in.
365	The Event-Driven Process Chain (EPC) is designed for modelling business processes, but does not yet include any means for measuring the performance of a business process. Thus, we extend the metamodel of the EPC with performance measures to make them conceptually visible. The extensions are tested with an example business process.
366	Thoroughly documenting digital business processes in a company is a crucial and necessary, yet cumbersome task. However, having detailed documentation of one's processes in a modelling language like Business Process Model and Notation (BPMN) can prove very useful regarding process optimization or automation, employee training and on- and offboarding. Process and task mining frameworks try to ease the creation of process documentation by automatically generating it based on transaction or user interaction data with the system. These approaches often have the disadvantage of not covering the whole process due to a variety of possible execution paths and their habit of not continuously recording process data. We propose an extension to the task mining tool Desktop Activity Mining (DAM) which allows to capture data continuously over several hours and therefore not miss any important cases that might not occur very often. This approach also limits the influence of human errors when recording process data with certain frameworks for documentation purposes and provide the possibility of an improved degree of automation. We evaluate the approach on real-world data to show its feasibility and application in practice. We used a combination of already existing algorithms and created our own. By classifying 332 unique user interactions, we end up with 76 different equivalence classes. Evaluating the algorithm, we achieved a classification correctness of 70% in two datasets.
367	The number of BPM products available has increased substantially in the last years, so that choosing among these products became a difficult task for potential BPM users. This paper defines a framework for evaluating BPM products, and discusses how this framework has been applied in the development of an open and objective evaluation method for these products. Our framework has been developed based on the BPM lifecycle we developed as a result of a thorough literature survey. Our method consists of a set of criteria, a test case and a rating schema. The paper also discusses how we evaluated our method (and indirectly our framework) by applying it to three BPM tool suites. We show that our method allows the rigorous comparison of these products according to different criteria, so that the choice of BPM product can be tuned to the specific goals of the users of these products. © 2010 Springer-Verlag.
368	The article analyzes the effectiveness of the quality management systems that operate at a number of enterprises. The main problem in most cases is determined as weak usage of the process approach in business-process management. To eliminate this problem, the authors offere to apply a process approach in the quality management systems of engineering enterprises for the purpose of receiving actual processes. Based on these processes and modern software tools, regulatory documentation is generated with the subsequent transition to the implementation of executable processes or BPM-systems (Business Process Management System). The regulation of business processes provides employees with regulatory documentation, and application of executable processes eliminates the "human" factor in process management. In addition, it is possible to monitor performance indicators and use the Deming cycle to continuously improve product quality. The practical realization of the project has been done in the framework of the Russian business-modeling software "Business Studio" and "Elma". © Published under licence by IOP Publishing Ltd.
369	Abstract Process resilience represents a core competence for organizations in light of an increasing number of process disruptions, such as sudden increases in case arrivals or absences in the workforce. It reflects an organization’s ability to restore a process to its acceptable performance level after a disruption. In this regard, the first key step for organizations towards achieving resilience is to understand how resilient their processes actually are. Although recognized as important, few works focus on such resilience assessment in a data-driven manner, thus barring organizations from gaining the necessary insights into how much their processes are affected by disruptions and how long it takes them to recover. To address this problem, we propose an approach for automated resilience assessment, based on recorded event data. Our approach interprets relevant process characteristics, such as the average lead time or arrival rate, as time series, which capture the development of the process execution over time. Based on these time series, it uses statistical modeling, specifically a vector autoregressive model, to determine the inter-relations between those characteristics and assess how the process performance responds to a disruption, i.e., a significant and temporal change in one of the process characteristics. We validate our approach by comparing its accuracy with a what-if analysis using a simulation model and demonstrate its effectiveness by assessing the resilience of the same process to diverse disruptions across different organizations.
370	Abstract Public administration institutions increasingly use business process management (BPM) to innovate internal operations, increase process performance and improve their services. Research on private sector companies has shown that organizational culture may impact an organization's BPM and this culture is often referred to as BPM culture. However, similar research on public administration is yet missing. Thus, this article assesses BPM culture in Germany’s municipal administration. 733 online survey responses were gathered and analyzed using MANOVA and follow-up discriminant analyses to identify possible determinants of public administration’s BPM culture. The results indicate that the employees’ professional experience and their responsibility influence the assessment of BPM culture, as does the size of a municipality. Based on these findings, the article proposes testable relationships and an agenda for further research on BPM culture in public administration.
371	Since Subject-oriented Business Process Management (S-BPM) models can be executed after validation without further transformation, toolshave been developed to support model execution. Asthese tools target not only non-disruptive execution of process models but also intuitive ease of use, stakeholders could expect effective and efficient implementation support of business processes. In the presented study we have challenged 3 stakeholder-centered tools refining, validating, and executing a complex process model. We wanted to knowhow much effort needs to be spent when a prototypical applicationis generated from a process specificationprovided by theinvolved stakeholders. The tools were a commercially available suite, a tool currently approaching the market, and a research tool. Our assessmentstudy reveals substantial effortthat needs to be spent for refining and validating process models, before being able to generate an interactive process experience. Hence, (S-)BPM tool developers are encouraged tosupport stakeholders according to the identified needs.
372	In this paper we introduce the intelligent Executable Product Model (iEPM) approach for the autonomous optimization of service industry's business processes. Instead of using a process model, we use an Executable Product Model (EPM). EPMs provide a compact representation of the set of possible execution paths of a business process by defining information dependencies instead of the order of activities. The flexibility that EPMs provide is utilized by intelligent agents managing the execution with the objective to optimize the Key Performance Indicators (KPIs) under consideration of the operating conditions. This paper demonstrates the practical application method of the iEPM approach as intelligent BPM engine where agents autonomously adapt their behavior in accordance to the current operating conditions for optimizing KPIs. The advantages of this method are discussed and statistically analyzed using a simulation based approach and the business process "new customer" found in banking. © 2010 Springer-Verlag.
373	nan
374	This study aims to present the flight simulator maintenance process model. To avoid failures of the system and mechanical, it is necessary to implement the maintenance processes. Moreover, flight simulator operator has to ensure that the performance of the devices qualified with the international regulations published by EASA, ICAO, and FAA. This paper demonstrates the maintenance process model and framework which is adapted to the supply chain operations reference (SCOR) model, to implement the flight simulator maintenance supply chain. The maintenance process model purposed with the most popular notation which called Business Process Model and Notation (BPMN) to support identification and visualisation of the processes as well as validate the effectiveness of models through the reviewing and analysing methodology with the experts in the field.
375	This paper proposes a concept for a prescriptive control of business processes by using event-based process predictions. In this regard, it explores new potentials through the application of predictive analytics to big data while focusing on production planning and control in the context of the process manufacturing industry. This type of industry is an adequate application domain for the conceived concept, since it features several characteristics that are opposed to conventional industries such as assembling ones. These specifics include divergent and cyclic material flows, high diversity in end products’ qualities, as well as non-linear production processes that are not fully controllable. Based on a case study of a German steel producing company – a typical example of the process industry – the work at hand outlines which data becomes available when using state-of-the-art sensor technology and thus providing the required basis to realize the proposed concept. However, a consideration of the data size reveals that dedicated methods of big data analytics are required to tap the full potential of this data. Consequently, the paper derives seven requirements that need to be addressed for a successful implementation of the concept. Additionally, the paper proposes a generic architecture of prescriptive enterprise systems. This architecture comprises five building blocks of a system that is capable to detect complex event patterns within a multi-sensor environment, to correlate them with historical data and to calculate predictions that are finally used to recommend the best course of action during process execution in order to minimize or maximize certain key performance indicators. © 2015, Springer Fachmedien Wiesbaden.
376	The development and implementation of innovative solutions in the fields of new production and employing new equipment, as well as such featuring new techniques and technologies, are associated with major expenditure. As the financial resources are limited, the selection of optimum options becomes an issue of crucial importance. It is even more so, as the implementation of high-performance manufacturing technologies, the collection of data on the performance of the units and the processes of the latter, the reorganization of the corporate structure aiming to eliminate the problem-generating system sections, are important to boost the competitiveness of an enterprise, which, in its turn, becomes the main factor of its sustainability and survival on a highly competitive market.
377	nan
378	Abstract In order to better facilitate the need for continuous business process improvement, the application of DevOps principles has been proposed. In particular, the AB-BPM methodology applies AB testing—a DevOps practice—and reinforcement learning to increase the speed and quality of business process improvement efforts. In this paper, we provide an industry perspective on this approach, assessing prerequisites, suitability, requirements, risks, and additional aspects of the AB-BPM methodology and supporting tools. Our qualitative study follows the grounded theory research methodology, including 16 semi-structured interviews with BPM practitioners. The main findings indicate: (1) a need for expert control during reinforcement learning-driven experiments in production, (2) the importance of involving the participants and aligning the method culturally with the respective setting, (3) the necessity of an integrated process execution environment, and (4) the long-term potential of the methodology for effective and efficient validation of algorithmically (co-)created business process variants, and their continuous management.
379	nan
380	This paper proposes a constructivist methodology of business process management to aid managers to generate understanding of the environment of their organization and to build recommendations on their resources and capabilities to create competitive advantages. This research is characterized as an applied research, and it is used a study case to illustrate how the use of presented framework may aid decisions to manage business processes as a dynamic capability. The presented framework is called Business Process Management-Constructivist. The presented framework is an extension of a performance measurement methodology and provides procedures to expand the understanding of the decision-maker about specific context and to recognize the uniqueness of the resources in order to manage processes as a dynamic capability. The presented framework intends to be a guide to managers and researchers to understand how to manage business processes from a resource-based view to create value to the decision-makers' perspectives. © 2014 John Wiley & Sons, Ltd.
381	Public organizations face difficulties in manipulating data essential for implementing efficient management, which compromises the quality of the services provided by these institutions. The use of Business Intelligence (BI) tools can contribute to the improvement of the organizational processes of these organizations. However, the high financial cost, in many cases, makes it impossible for public institutions to acquire proprietary BI solutions. An alternative is the use of solutions based on free and/or open source software. To identify, among the available OSS-based BI tools, which is the most appropriate for implementation in public bodies, it is necessary to apply some specific model for evaluation and selection. The literature describes several generic methods for assessing and comparing OSS. In this work, we select a suitable method and derive a model for the comparison and selection of OSS-based BI tools able to meet the demands of public organizations. In addition, through a case study, we demonstrate how this model can be used in the selection of a tool that can contribute to the improvement of information management in an organizational environment.
382	Over last few years Data Warehouse (DW) has emerged as the core of the Business Intelligence (BI) infrastructure for many forward-looking organizations. It is often complemented by Business Performance Management (BPM) and workflow management tools for operationalizing of strategic and tactical decisions and tracking progress of activities across the organization. However, till now there is not much support available to the decision-makers to leverage "organizational experience" i.e., the past events, corresponding responses made as well as their respective impacts, to guide him/her in the decision-making process. In this paper a conceptual BI framework, the Reference-Activity-Projection (RAP) is proposed. RAP is designed to support the decision-making process through a systematic access mechanism to organizational experience. RAP uses along with standard BI tools and techniques, the emerging technologies such as complex event processing (CEP), unstructured/semi-structured data mining, social network analysis etc.
383	Improving business processes and maintaining acceptable levels of performance are main factors in the success of any organization. Related to BPM (Business Process Management) [1] approaches, a variety of methodologies and techniques are available. These approaches include business process improvement methodologies (BPIM) [2] and process mining [3]. Actually, with BPM life cycle a continuous methodology of improvement business processes is defined, starting by the design phase and ending with the optimize phase. In this paper, we present a new vision BPM life cycle whose content differs from the classical one [4]. On each phase, we define a set of improvement indicators. These indicators recast business processes for best optimization results. © 2018 IEEE.
384	Nowadays, organisations use business process management (BPM) around the world to maintain a competitive advantage related to their business processes (BP). In this sense, business process improvement implies often a challenge in identifying specific improvement metrics according to the BP types, which from different scenarios. Thus, we present in this paper an integrated approach for defining improvement metrics according to the BP types. Our proposed approach is validated through a case study involving the enhancement of a BP. This BP is about requests for compensation within an airline company. Our approach consists of three main pillars: 1) management BP metrics; 2) operational BP metrics; 3) support BP metrics. In order to identify appropriate improvement interventions, modelling, analysis, simulation, monitoring and process mining techniques are used. © 2019 Inderscience Enterprises Ltd.
385	Business Intelligence (BI) platforms are applications to analyze critical business data so as to gain new insights about business and markets. The new insights can be used for improving products and services, achieving better operational efficiency, improve competitiveness, and fostering customer relationships. However, we notice that BI is not yet a reality in Small and Medium Enterprises (SMEs) and it's even unknown in many of these organizations. The implementation of BI in organizations depends on their specificities. It is essential that the information available on platforms and their functionality comes clearly to organizations. Only a correct choice, in response to business needs, will allow powerful data that results in gains and business success. For this purpose, we have developed a comparative analysis of the existing capabilities in the various BI tools, which is intended to assist the selection of the BI platform best suited to each organization and/or business area. In this paper, we study and compare seven of the most used open source BI platforms: Actuate, JasperSoft, OpenI, Palo, Pentaho, SpagoBI and Vanilla.
386	This research focuses on the effects of different business process management components in combination with information technology on recruiting process performance. The results of a study of Germany’s largest 1,000 business enterprises (response rate 13.1 %) reveal that business process analysis, business process improvement and the usage of applicant tracking systems reduce recruiting process costs. Specifically, the cycle time of the recruiting process can be shortened significantly through business process controlling and process analysis, and by using an applicant tracking system that supports the design and evaluation of key performance indicators. Business process standardization combined with applicant tracking systems and business process documentation as well these systems used together with business process controlling have a significant positive impact on stakeholder satisfaction with the recruiting process. The general quality of the process can be improved through business process controlling as well as through a combination of applicant tracking systems and business process controlling. Our results reveal that several components of the business process management in conjunction with a supporting applicant tracking system have differing impacts on recruiting process performance. This paper discusses these diverse effects of business process management on process performance and draws implications for information systems success research. © 2014, Springer-Verlag Berlin Heidelberg.
387	While performance management forms an integral part of the concept of supply chain management, designing a consistent and powerful performance measurement system (PMS) at the level of an enterprise network is still proving very problematic. In this paper, a business process oriented approach is proposed to tackle problems of heterogeneity between partners. Special attention is paid to the representation of both decisional and operational activities, taking into account the links between them. Based on this framework, a method is applied to select, implement and publish the key performance indicators (KPI). We propose a classification of KPI into three categories related to management abilities: ambition, reality and facility. These classes form a consistent set to support decision making and process control at a network level. A business case is used to show the potential of this approach. Copyright © 2011 Inderscience Enterprises Ltd.
388	nan
389	Dynamic manufacturing systems consisting of multiple stages use a combination of dispatching rules to obtain production schedules in general. A weighted sum method, which assigns different weights to each dispatching rule and prioritizes jobs with a high weighted sum, is widely used especially for LCD and semiconductor manufacturing. A suitable set of weights by considering dynamic system states has to be determined in order to improve the throughput and utilization of systems. Hence, we develop a sequential search framework, with simulation and decision trees, which can generate a good weight set of dispatching rules within a short period of time. We show that the proposed search method performs better than a random search by performing experiments with real fab data.
390	nan
391	In this paper, I shall propose an integrated model of worker skills and team motivation for a computer-based simulation game that can be used to provide experiential learning to students. They can act as project managers here without being burdened by the costs and risks associated with unsuccessful projects. I shall present an approach of classifying skills into five different types (relevant to IT projects) and apply a five-point competency scale to each skill type. The Pearson Correlation will be applied to the scores of each skill type to generate an efficiency index that will characterize the effectiveness of a team working on a task. I shall also describe a model to represent the relationship between the social needs of team members and their motivation levels. The results of the actual simulation games will be presented here followed by a discussion on the practical implications and recommendations.
392	The management and improvement of business processes is an evergreen topic of organizational design. With many techniques and tools for process modeling, execution, and improvement being available, research pays progressively more attention to the organizational impact of business process management (BPM) and the development of BPM capabilities. Despite knowledge about the capabilities required for successful BPM, there is a lack of guidance on how these BPM capabilities should be developed and balanced with the improvement of individual business processes. As a first step to address this research gap, we propose a decision model that enables valuating and selecting BPM roadmaps, i.e., portfolios of scheduled projects with different effects on business processes and BPM capabilities. The decision model is grounded in the literature related to project portfolio selection, process performance measurement, and value-based management. We also provide an extensive demonstration example to illustrate how the decision model can be applied. © 2014 Springer International Publishing Switzerland.
393	Deciding which business processes to improve is a challenge for all organizations. The literature on business process management (BPM) offers several approaches that support process prioritization. As many approaches share the individual process as unit of analysis, they determine the processes’ need for improvement mostly based on performance indicators, but neglect how processes are interconnected. So far, the interconnections of processes are only captured for descriptive purposes in process model repositories or business process architectures (BPAs). Prioritizing processes without catering for their interconnectedness, however, biases prioritization decisions and causes a misallocation of corporate funds. What is missing are process prioritization approaches that consider the processes’ individual need for improvement and their interconnectedness. To address this research problem, the authors propose the ProcessPageRank (PPR) as their main contribution. The PPR prioritizes processes of a given BPA by ranking them according to their network-adjusted need for improvement. The PPR builds on knowledge from process performance management, BPAs, and network analysis – particularly the Google PageRank. As for evaluation, the authors validated the PPR’s design specification against empirically validated and theory-backed design propositions. They also instantiated the PPR’s design specification as a software prototype and applied the prototype to a real-world BPA. © 2017, Springer Fachmedien Wiesbaden GmbH.
394	Abstract Business process management (BPM) is an important area of organizational design and an acknowledged source of corporate performance. Over the last decades, many approaches, methods, and tools have been proposed to discover, design, analyze, enact, and improve individual processes. At the same time, BPM research has been and still is paying ever more attention to BPM itself and the development of organizations’ BPM capability. Little, however, is known about how to develop an organization’s BPM capability and improve individual processes in an integrated manner. To address this research gap, we developed a planning model. This planning model intends to assist organizations in determining which BPM- and process-level projects they should implement in which sequence to maximize their firm value, catering for the projects’ effects on process performance and for interactions among projects. We adopt the design science research (DSR) paradigm and draw from project portfolio selection as well as value-based management as justificatory knowledge. For this reason, we refer to our approach as value-based process project portfolio management. To evaluate the planning model, we validated its design specification by discussing it against theory-backed design objectives and with BPM experts from different organizations. We also compared the planning model with competing artifacts. Having instantiated the planning model as a software prototype, we validated its applicability and usefulness by conducting a case based on real-world data and by challenging the planning model against accepted evaluation criteria from the DSR literature.
395	nan
396	Motivated by the entry into service of new aircraft such as the Airbus A380 as well as the pressure to operate existing fleets at lower cost, not only in civil but also in military aviation, a new industry paradigm has emerged where MRO (Maintenance, Repair and Overhaul) service providers or OEMs (Original Equipment Manufacturers) supply spare parts to airline operators on a maintenance-by-the-hour basis. As a consequence, the associated logistics networks have reached unprecedented complexity: Component exchange commitments are now made to multiple operators, not only at their main bases but also at outstations. In this setting, the limitations of conventional Initial Provisioning methods can be overcome with high-fidelity simulation-based optimisation techniques. In particular, this paper discusses how value can be unlocked from new logistics policies for spare parts management in aviation.
397	Modern business performance management (BPM) comprises modeling, analyzing and monitoring of business processes. A variety of different approaches for business performance management have emerged recently. One issue common to these approaches is the inability to link the business process schema to the information gathered during the relevant phases. In this paper, we present a Petri net-based approach for process-oriented business performance management. Our approach is based on a new type of high-level Petri nets, so called XML nets. In XML nets business process objects, performance indicators and the performance measurement system are represented with XML. Being a consistent and comprehensible methodology for the whole process life cycle, XML nets support integrated process-oriented business performance management. We also demonstrate the modules and basic functions of a Petri net-based software prototype designed to support process-oriented BPM.
398	nan
399	With the rapid development of semiconductor manufacturing, customers' demand for on-time delivery rate (ODR) makes scheduling strategies face new challenges. In order to meet customers' delivery requirements, scheduling strategies generally need to comprehensively consider remaining cycle time (CT), ODR, movement (MOV) speed and machine load balancing. In order to solve these problems, this paper proposed a scheduling strategy of semiconductor production lines with remaining cycle time prediction. Firstly, gather features related to performance index and then filtrate them through dimension reduction method. Secondly, use the above feature subset to build remaining cycle time prediction model by random forest algorithm. Next, design the scheduling strategy of semiconductor production lines with remaining cycle time prediction. Finally, make simulation experiments to verify the effectiveness of the proposed scheduling strategy. Simulation results show that the proposed scheduling strategy can improve the mean CT, throughput (TH), machine utilization time (MUT) and ODR in different extant.
400	During the life cycle of business process management, the quantitative analysis of the time performance measure is pivotal to guarantee the validity of process model and to improve its quality. Based on the characteristic of management processes and the assumption that the processing time of activities is either zero or a stochastic variable obeying the exponential distribution, the Generalized Stochastic Workflow Net model of the business process is constructed, which facilitates the analysis of time performance through the theories on Generalized Stochastic Petri Net and Markov Chain. Then the computational formula of the average flow time of workflow is deduced. Finally, a case study is given, and the computational value is compared with that of simulation. The test shows that these two results are almost identical. © 2008 IEEE.
401	In this paper, we present a model-driven approach to Business Performance Management (BPM). BPM is a new frontier in IT-enabled enterprise that supports the monitoring and control of business operations. BPM solutions must be able to efficiently process business events, compute business metrics, detect business situations, and provide the real-time visibility of key performance indicators. In addition, system support is required for the rapid development of BPM solutions and the adaptation of the solutions to the dynamic business environment. We have adopted a meta-model, dubbed the observation meta-model, for capturing the business requirements for BPM, which frees solution developers from low-level programming concerns. We have also used a hybrid compilation-interpretation approach to map an observation model to the runtime executable. First, we extract and refactor the data aspect of the observation model to facilitate runtime access. Second, we compile the operational aspect of the model, such as logic for metric computation and situation detection, into Java code. Third, we develop a runtime engine that interprets the refactored model and dynamically loads the generated code, according to the meta-model. Our framework further enables the evolution and hot deployment of the observation model and provides the platform for several on-going customer engagement efforts. © 2005 IEEE.
402	Companies around the world are finding themselves in a race against the relentless evolution of digital technologies that are accelerating innovation and creating a highly competitive environment. Many works in research and practice are trying to guide companies to a Digital Transformation (DT) that allows them to take full advantage of new technologies. However, generic solutions, that are mainly focused on technological aspects, make it clear that there is a lack of understanding of the whole scope of their implications. In this sense, this work takes a step back to analyze the origin of the shortcomings of current solution approaches. The results point out a lack of theoretical foundation on identifying the business dimensions implicated in a DT that define its scope. In this sense, this study contributes with a more comprehensive view of the DT process by using a formal approach to define the business dimensions involved in such a change based on the principles of the Socio-Technical Systems (STS) theory. As a result, this proposal goes beyond the purely technological views to (1) identify five business dimensions involved in the DT process: technology, processes, structure, competencies and culture and (2) recognize the key role of strategy and performance measurement, not as dimensions but as external elements that drive and control the DT process. A multiple case study of the DT process of three French manufacturers is presented to validate the proposition. General remarks and future research concerning the implementation of these dimensions conclude this study.
403	Business process design, reengineering and monitoring enable companies to achieve market-wide competitiveness and reduce their reaction time to environmental changes. IT systems become more sophisticated to meet the demands for real-time performance measurement and management. Besides, strategic management approaches such as the balanced scorecard gain more and more importance due to lacking alignment and strategic orientation in companies. Holistic management systems are therefore emerging. This paper focuses on a strategic management and monitoring framework that incorporates holistic aspects from the balanced scorecard with demands to data- and business driven process design and controlling. As a result, not a specific monitoring application is presented, but a methodology to combine strategic and tactical monitoring under best-practice assumptions.
404	nan
405	Artifact-centric business process has emerged as a representative paradigm of data-centric business process. As concerned in traditional business process, it is a critical issue to match business process models quickly, exactly and efficiently. Because of the pertinence between artifacts and tasks which deal with them, ordinary graph cannot describe the process successfully. Therefore, a bipartite graph for artifact-centric business process models is presented firstly, which can transform process model matching to graph matching. Secondly, a novel method using matrix conversion to measure graph edit distance is also brought forward. Finally, a similarity matching algorithm named ArtiMatch was designed and implemented. Theoretical analysis and experimental results show that the ArtiMatch algorithm outperforms existing algorithms in a number of performance metrics such as execution time, precision and recall.
406	Real-time performance monitoring is an essential practice to enable sense-and-respond capability of enterprises. However, building a performance monitoring application is often arduous. We present a model-driven, systematic approach to performance monitoring based on an extended business artifact-centric process model. In this approach, business artifacts provide a means of tracking resource utilization in processes. Monitoring contexts and inbound event definitions are derived from the artifact model and can be configured for target performance measures. During process execution, inbound events are collected in a timely manner and fed into the monitoring contexts to calculate performance measures and detect situations. Thus, we turn performance monitoring into an integrated part of business process modeling to achieve accelerated development.
407	nan
408	Nowadays, most business processes are running in a parallel, distributed and time-constrained manner. How to guarantee their on-time completion is a challenging issue. In the past few years, temporal checkpoint selection which selects a subset of workflow activities for verification of temporal consistency has been proved to be very successful in monitoring single, complex and large size scientific workflows. An intuitive approach is to apply those strategies to individual business processes. However, in such a case, the total number of checkpoints will be enormous, namely the cost for system monitoring and exception handling could be excessive. To address such an issue, we propose a brand new idea which selects time points along the workflow execution time line as checkpoints to monitor a batch of parallel business processes simultaneously instead of individually. Based on such an idea, a set of new definitions as well as a time-point based checkpoint selection strategy are presented in this paper. Our preliminary results demonstrate that it can achieve an order of magnitude reduction in the number of checkpoints while maintaining satisfactory on-time completion rates compared with the state-of-the-art activity-point based checkpoint selection strategy.
409	nan
410	Modern machine learning services and systems are complicated data systems — the process of designing such systems is an art of compromising between functionality, performance, and quality. Providing different levels of system supports for different functionalities, such as automatic feature engineering, model selection and ensemble, and hyperparameter tuning, could improve the quality, but also introduce additional cost and system complexity. In this paper, we try to facilitate the process of asking the following type of questions: How much will the users lose if we remove the support of functionality x from a machine learning service?Answering this type of questions using existing datasets, such as the UCI datasets, is challenging. The main contribution of this work is a novel dataset, MLBench, harvested from Kaggle competitions. Unlike existing datasets, MLBench contains not only the raw features for a machine learning task, but also those used by the winning teams of Kaggle competitions. The winning features serve as a baseline of best human effort that enables multiple ways to measure the quality of machine learning services that cannot be supported by existing datasets, such as relative ranking on Kaggle and relative accuracy compared with best-effort systems.We then conduct an empirical study using MLBench to understand example machine learning services from Amazon and Microsoft Azure, and showcase how MLBench enables a comparative study revealing the strength and weakness of these existing machine learning services quantitatively and systematically. The full version of this paper can be found at arxiv.org/abs/1707.09562
411	Companies need to become more agile to survive to the unstable and highly changing market-place. This can be achieved through the adaptation and control of their business processes. A process sufficiently structured but not over constrained by standards and based on experience feedback principles is necessary. This article describes a proposition of agile process driven by the reuse of experiences and knowledge. For this purpose, based on Case-Based Reasoning (CBR) principles, the complete lifecycle of an agile process is introduced, from requirements definition, retrieval, reuse, adaptation, and storage steps. Finally, an example applied to the domain of industrial problem solving is presented to illustrate the methodology.
412	nan
413	Numerous recent studies have presented concerning findings on the prevalence of errors in healthcare across OECD (Organization for Economic Co-operation and Development) countries, including Italy to a significant degree. A considerable portion of these errors appears to stem from non-compliance with organizational operating procedures, typically derived from ministerial directives and international standards. Against this backdrop, this paper describes the endeavors undertaken within an Italian research project, which proposed a more systematic approach to the healthcare sector, emphasizing clinical risk management. The modeling of clinical processes employed the widely adopted BPMN (Business Process Modeling and Notation) standard notation, subsequently integrated with the hospital information system to oversee and mitigate clinical risks. Digitalization of operating procedures additionally facilitated the establishment and computation of various Key Performance Indicators (KPIs) for long-term monitoring. The implementation of the project's experimental phase, leveraging the developed system, effectively identified the areas most afflicted by operational non-conformities, thereby enabling targeted measures to safeguard patient well-being and, indirectly, yield substantial cost savings. © 2023 Computers and Industrial Engineering. All rights reserved.
414	A multitude of studies have highlighted alarming data on healthcare adverse events and medical errors in many countries, including Italy. Many of these errors appear to be the result of non-compliance with good practices and organizational operating procedures, specified in ministerial directives and international standards. This paper describes the efforts of an Italian research project to propose a structured approach to healthcare process management, emphasizing clinical risk management. Using the Business Process Model and Standard Notation (BPMN), the project models clinical processes and integrates them into the clinical information system to identify process deficiencies, highlight compliance vulnerabilities, monitoring and managing clinical risks. The workflows’ digitalization, enabled the definition and calculation of several Key Performance Indicators (KPIs) for a long-term evaluation of the success of the modeled processes. In the experimental phase, the project allowed to identify areas significantly affected by operational deviations, enabling targeted actions to safeguard patient health and generate economic savings due to the reduction of legal actions against medical workers’ errors. The effects of an overall improvement on quality of care can be appreciated not only by patients but also by medical and administrative staff of the clinics. © 2024 The Author(s)
415	The innovative capability is a unique resource that enable companies to deliver a superior performance. It is also an essential resource to have for trucking companies, but not many studies have addressed this issue, especially in the service sector. This study investigates the factors influencing the trucking company's innovative capability, including market orientation and supply chain relationships through a case study. The factors and their indicators were obtained through extensive literature review. These factors were validated through the interview involving executives from five trucking companies. The study reveals that all the indicators obtained from the literature were considered valid and will therefore be used to develop survey instruments.
416	nan
417	nan
418	nan
419	The objective of this study is the development of a forecasting system for intraday stock price movement. Here, intraday refers to stock movement within a single trading day. To identify trends and forecasting market movements, artificial neural networks (ANN) are employed by the forecasting system. In a simulation study we compared the performance of our system with a buy &amp; hold and naive strategy. The model has been tested in some experiments on real data and the results are reported in this paper.
420	Construction business performance measurement (BPM) is myopic, most often being project-specific, profit-orientated, and neglecting broader “stakeholder” issues. If construction organizations are to remain competitive in the longer term, they need to develop and better understand their relations with their customers, suppliers, employees, lenders and the wider community. Hence, performance measurement must embrace these broader business characteristics. The need for a shift in “orthodox” (BPM) beliefs from “basic” performance measurement, to an alternative “stakeholder perspective measurement” (SPM), is underlined. SPM will adequately consider relations with customers, suppliers, employees, financiers, and the wider community; all being critical for a business's long-term viability. The paper goes on to advocate that construction organizations should reject this myopic strategic thinking, and better consider the interests of their stakeholders, both economically and morally. The latter calls for development of a serious stakeholder perspective to business performance measurement, so that construction organizations can be monitored and judged in a socially acceptable manner. © 2000, MCB UP Limited
421	In today's highly competitive business environment, the speed of a company's response to changes by adapting its own business processes is vital to its survival. In this paper, we propose a symbiotic simulation system that can monitor the real-world operations of high-tech manufacturing and service networks, carry out what-if analysis and optimization on service-oriented based business workflow, and dynamically deploy the optimized business workflow onto the real-world operations. A case study of an aerospace spare parts logistics system was carried out to investigate the viability of the system.
422	nan
423	High-level customer service, with improved quality at a lower cost, is imperative in today's global supply chain, where customers have myriad options across borders. This is in line with the primary objective of supply chain management, which is to enable and deliver high-level customer service with lower costs, reduce lead time, and improve the quality of products/services. The Supply Chain Operations Reference (SCOR) model based on KPI metrics enables an increase in the quality of products/services by monitoring and digitalising involved processes. The current paper suggests the structure of the SCOR database for Supply Chain process improvement by applying the best practices of the SCOR for Business Processes improvement. We recommend the Bayesian Belief Network (BBN) and Case-Based Reasoning (CBR) methods to estimate the influence of these improvements on Supply Chain efficiency through key performance indicators before implementation. Integrating the methods proposed in this article focuses on an approach that minimises supply chain failures, decreases failure elimination time, understands consumer needs, and offers more accurate price proposals and lead times to improve customer satisfaction. Accordingly, the integrated SCOR-based Business Process Modelling (BPM) was not previously combined with BBN to identify the most efficient ways to improve the reliability of a Supply Chain by applying best practices, which impacts the entire supply chain. Our research is limited to SME companies in electronics manufacturing, but our ambition is to develop a universal framework suitable for broader areas. The study aims to analyse how the customers see the company by combining the CDA (Customer Delivery Accuracy) and Customer Complaints measures and find the optimal way to improve business processes by applying best practices. Still, it is limited to SCOR reliability performance metrics. © 2023, Kauno Technologijos Universitetas. All rights reserved.
424	Purpose: The underlying purpose of this paper is to propose a comprehensive framework evaluating the performance of business units of an organization with a process perspective, identifying the most influential performance indicators, enabling managers to make more informed decisions based on data recording every day in their operational information systems. Design/methodology/approach: For proposing the conceptual framework of performance evaluation a synchronized analysis of selected process' data, obtained from an integrated information system of an Iranian chain store, was performed. Findings: The superiority of the proposed framework results is demonstrated in comparison to applying the process mining solely; principal component analysis was identified as an efficient link between process mining and data envelopment analysis. Also, based on the final data analytics, the units' throughput times and the variety of brands and suppliers had the most impact on their performances. Research limitations/implications: The data of abundant business units and performance indicators, which would have allowed adding data prediction and other data analytics techniques for more insight, was not able to be accessed. Practical implications: Organizations' managers can use the framework to evaluate their business units' current status and then prioritize their resources based on the most influential performance indicators for overall improvement. Originality/value: The study contributes to the research on performance management and process mining by presenting a comprehensive framework with two levels of data analytics. It stresses discovering what is happening in business units, and how to prioritize their improvement opportunities learning the significant correlations between performance indicators and units' performance. © 2021, Emerald Publishing Limited.
425	Logistics activities and production reporting are the important areas that are becoming the determinants or factors affecting the key performance Index (KPI) in evaluating the logistics business performance monitoring (BPM). Inventory management and manufacturing production processes are the activities that provide important information. These information or data are usually captured and updated in the normal computerized system in such module "SAP ERP" software. The integration and the linkage of the focus areas by the enterprise resource planning (SAP ERP) that champions the supply chain value are much relied on internet. The move of logistics operations in the internet economy actually shifted the traditional logistics to E-logistics. The internet of things (IOT) enhanced the logistics operation performance providing the real time update that influence the management making decision related to time and costs saving as well as improved operation's efficiency by connecting those unconnected activities as the enhancement for the issues addressed in manufacturing logistics. It benefited the related parties, especially the manufacturers and consumers.
426	Abstract Process mining—a suite of techniques for extracting insights from event logs of Information Systems (IS)—is increasingly being used by a wide range of organisations to improve operational efficiency. Despite extensive studies of Critical Success Factors (CSFs) in related domains, CSF studies tailored to process mining are limited. Moreover, these studies merely identify factors and do not provide essential details such as a clear conceptual understanding of success factors and their interrelationships. Through a multi-phased approach (applying published process mining case studies, conducting two in-depth case studies and expert interviews), this paper presents an empirically validated process mining CSF model and CSF interrelationships. This validated CSF model identifies ten process mining CSFs, explains how these factors relate to the process mining context and analyses their interrelationships with regard to process mining success. The findings provide a guide for organisations to invest in the right mix of CSFs for value realisation in process mining practice.
427	nan
428	The paper discusses dynamic workload management in transaction processing systems where the workload consists of multiple classes of units of work, including workflows comprised of interdependent tasks. Business requirements specify that differing levels of service must be provided to different classes of work, thus it is natural to specify performance goals per work class, that reflect the business requirements for the work class as well as the inherent resource demands of the units of work. Adaptive algorithms have been proposed for the satisfaction of performance goals of transaction classes. Scheduling the execution of complete workflows, which are multi-transaction units of work, is complicated by the need for task coordination, due to both control and data flow dependencies among tasks. Current transaction processing monitors provide infrastructure for the coordination of tasks by means of queueing facilities. We draw on previous work on goal-oriented resource management to design adaptive task scheduling algorithms. A detailed simulator of transaction processing systems with a queueing facility has been developed, with the specific aim to study the performance for workloads that include multi-transaction units of work.
429	Rapidly changing market conditions dictate new requirements for the organization of production enterprises. This is particularly true for high-tech industries such as oil refining.With a view of maintenance of competitiveness of work of the oil refining enterprises, it is expedient to aspire to increase of level of automation of technological and business processes that it is possible to realize by introduction in architecture of information systems of refinery IS of classes ERP, MES and ACSPP. To ensure effective integration of these IS data with the current information environment of the enterprise, the right solution will be to re-engineer some basic business processes. These measures will improve the quality and depth of processing of raw materials through the transition to automated systems that allow real-time adjustment of equipment operation modes depending on the established planned needs for commercial products and technological limitations.At carrying out of these actions it is necessary to consider the branch features inherent in difficult processes of oil refining manufacture which are also described in given article.
430	Adaptation of complex service-based systems is one of the most challenging research problems for the Future Internet. A considerable effort has been dedicated in recent years to address this problem. However, there are still several important issues that call for concrete solutions. In this paper, we present a set of research challenges for muti-layer and mixed-initiative adaptation and monitoring that may guide the research in this area for the next 5-10 years.
431	nan
432	This paper explores the impact of Supply Chain Management (SCM) practices on delivery dependability. Our research considers five dimensions of SCM practices, namely strategic supplier partnership, customer relationship, information sharing, information quality and internal lean practices. By reviewing strategic performance theory, we examine the impact of SCM practices on delivery dependability, the extent to which an organization is capable of providing on time, the ordered type and volume of product in conformance with customer specifications. We also examine the role of SCM information systems on the application of SCM practices across supply chain partners. The empirical findings from a survey of 47 manufacturing firms in Greece confirmed the crucial role of all SCM practices and especially information sharing on the establishment of a sustainable competitive advantage boosting supply chain performance outcomes. Managerial implications are discussed.
433	nan
434	It is well-known that context impacts running instances of a process. Thus, defining and using contextual information may help to improve the predictive monitoring of business processes, which is one of the main challenges in process mining. However, identifying this contextual information is not an easy task because it might change depending on the target of the prediction. In this paper, we propose a novel methodology named CAP3 (Context-aware Process Performance indicator Prediction) which involves two phases. The first phase guides process analysts on identifying the context for the predictive monitoring of process performance indicators (PPIs), which are quantifiable metrics focused on measuring the progress of strategic objectives aimed to improve the process. The second phase involves a context-aware predictive monitoring technique that incorporates the relevant context information as input for the prediction. Our methodology leverages context-oriented domain knowledge and experts' feedback to discover the contextual information useful to improve the quality of PPI prediction with a decrease of error rates in most cases, by adding this information as features to the datasets used as input of the predictive monitoring process. We experimentally evaluated our approach using two-real-life organizations. Process experts from both organizations applied CAP3 methodology and identified the contextual information to be used for prediction. The model learned using this information achieved lower error rates in most cases than the model learned without contextual information confirming the benefits of CAP3.  © 2013 IEEE.
435	Business performance measurement (BPM) is a fast evolving and diverse research field which features highly on the agenda of academics and practitioners from functions including general management, accounting, operations research, marketing, and human resources. Utilizing a citation analysis this paper identifies the following challenges for the field of BPM. The balanced scorecard seems to be the most influential and dominant concept in the field. Researchers are encouraged to further test and discuss its theoretical foundation and research methodology. The second challenge is to create a cohesive body of knowledge in the field of BPM. © 2003, MCB UP Limited
436	nan
437	Advanced case management gives enterprises the flexibility to organize their business operations in an efficient and transparent manner while providing knowledge workers the opportunity to proceed towards their goals and to react to exceptions as required in each individual situation. Powerful analytics based on pervasive observation of end-to-end case executions help to detect exceptional situations, determine possible derailment, and thus to prevent undesired outcomes. This paper demonstrates the application of proven technologies derived from real world examples to determine the health of a particular case.
438	The objective of this work is to enable the collaboration of multiple disciplines in the performance reviews of reservoirs while establishing a culture of variance reduction and sustainable consistency in results delivery. This effort focuses on the performance management reviews of very large carbonate reservoirs where the number of wells and producing zones overwhelm engineers and organizations with data volume and complexity due to areal and vertical heterogeneity. A novel Reservoir Performance Review (RPR) solution has been implemented across various offshore reservoirs units. RPR initiates all asset activities during reservoir performance reviews and allows the tracking of actions over the life of the reservoir. RPR leverages data analytics to automatically compute reservoir health key performance indicators that allow prioritization of the technical work, extract and transform data from multiple data sources, deliver performance dashboards with diagnostic plot standardized across all assets and users providing an archive of information and knowledge from past reservoir performance reviews. RPR leverages business process management and integrated visualization to assist in the identification and recording of opportunities, risks and actions, while providing control and management of the business processes. The solution offers an innovative way to collaboratively gather, validate, analyze reservoir performance across the asset on a sustainable and cost-efficient manner while addressing more formal approval processes in order to garner approval or authorization for action. Some of the realized benefits include ensuring effectiveness in the execution of reservoir management, monitor variance between actual performance and expectation during the execution of projects; and ensure production sustainability and mitigate shortfalls proactively. RPR enabled the achievement of a consistent approach across all assets for all reservoir performance review processes, while improving efficiency through automation of data gathering and presentation and the identification of all underperforming reservoir, sectors and fields. Reservoir management excellence is achieved by delivering immediate value on the opportunities identified during performance reviews which ensure short term profitability while preserving long term goals. Typically, operators are satisfied by meeting targets within certain tolerance. RPR ensures that performance excellence is achieved by considering all technical and business aspects. © Copyright 2018, Society of Petroleum Engineers.
439	nan
440	In order to provide certified security services we must provide indicators that can measure the level of assurance that a complex business process can offer. Unfortunately the formulation of security indicators is not amenable to efficient algorithms able to evaluate the level of assurance of complex process from its components.In this paper we show an algorithm based on FD-Graphs (a variant of directed hypergraphs) that can be used to compute in polynomial time (i) the overall assurance indicator of a complex business process from its components for arbitrary monotone composition functions, (ii) the subpart of the business process that is responsible for such assurance indicator (i.e. the best security alternative).
441	nan
442	We present a systematic method of measuring performance risk for specific implementations of an Enterprise SOA within a Cloud computing framework. The U.S. Department of Defense (DOD) is determining performance baselines for distributed architectures that are internally organized using service interfaces. Such architectures are essential for highly reliable and life critical Cloud applications. We provide baseline performance for an architecture comprised of service components from the service interfaces provided by several major commercial software vendors. Transition from legacy systems into Service-Oriented Architecture (SOA) systems necessitates an infrastructure of federated components. This paper documents a means to measure such an infrastructure. Baselines provide a foundation for assessment of future services including Quality of Service (QoS) contracts and assessment of fused web services within heterogeneous SOA or Cloud architectures.
443	To keep pace with the needs of the manufacturing industry of the future, companies need to flexibly react to changing demands and be able to manage production capacities in a rapid and efficient way. This requires agile collaboration among supply chain partners in context of Service-Oriented Architectures (SOA). To this end, we propose a novel pragmatic approach for automatically implementing service-based manufacturing processes at design and runtime, called ODERU. Relying on a set of semantic annotations of business process models encoded into an extension of the BPMN 2.0 standard, it combines pattern-based semantic composition of process service plans and optimization of non-functional aspects by means of QoS-based constraint optimization problem (COP) solving. The ODERU tool is part of a platform for cloud-based elastic manufacturing. In this paper we present the foundations of ODERU, show casing its application to two manufacturing processes with conflicting requirements showing how it solves the problem by leveraging the Everything-as-a-Service (XaaS) approach. Some initial evaluation sketches the expected benefits of such a solution, depicting its usefulness and potentialities.
444	The monitoring of business processes for performance measurement is challenged by the variety of inter and intra organisational units and information systems involved in the execution of these processes. In this paper we present a shareable, web service-based Intelligent Decision Support System (IDSS) for on-demand business process management, that we call the Solution Manager Service (SMS). The SMS allows organisations to outsource the collection, accumulation and transformation of information about their business processes from multiple distributed systems across multiple organisations in a centralised repository and share them among authorised parties, such as supply chain partners, clients or government agencies. Copyright © 2006 Inderscience Enterprises Ltd.
445	nan
446	nan
447	Selection of items to fill customer orders from systems of pallet rack or shelving arranged in rows with access by means of narrow aisles is becoming commonplace in many distribution centers.Such systems offer significant advantages in terms of space savings and utilization of the “cube” in distribution facilities. Narrow-aisle high-density order selection systems may tend, however, to have an adverse effect on selection productivity if not planned properly.This paper is a case study in the use of simulation as a tool for making informed decisions about the design of a narrow-aisle order selection system. Using hypothetical data, and a set of models developed in the SIMAN simulation language for one of the world's largest parts distribution centers, it examines the effect on selection productivity of three key factors in the design of a selection system:System ConfigurationStocking policySelection policy
448	Evaluating the performance of processes is of vital importance if organizations are to seek continuous improvements. It is by measuring processes that data on their performance is provided, thus showing the evolution of the organization in terms of its strategic objectives. These results will serve as the basis for making better decisions, thereby leading to continuous improvement. The approach set out in this paper is prompted by the relative lack of empirical investigations into performance measures contained in the literature and the difficulties that organizations face when trying to verify the results of their business processes. Based on analyzing studies selected in a Systematic Review of the Literature, there it was found the need to propose a new approach to evaluating business processes that brings together elements and recommendations selected from the analyzed approaches. In the evaluation of the proposed approach, a case study is discussed, to verify its applicability. © Springer International Publishing AG 2017.
449	BPM is a systematic approach that enables an organization to achieve results that are consistent and aligned with its strategic objectives. In this context, organizations need to measure the performance of their processes, thereby enabling them to support planning, inducing control and making it possible to diagnose the current situation. The research that led to this article was prompted by the paucity of empirical investigations into performance measures offered in the literature and recognition of the difficulties that organizations face when attempting to verify the results of their business processes. From a systematic review of the literature, it became evident that, among the approaches discussed, there are several variations in the methodology, in the specifications of the measures and even as to how business processes are evaluated. By undertaking a comparative evaluation of the approaches, a set of criteria was defined which addresses not only theory, based on the references, but also some usability aspects of a process performance model. Thus, we proposed the definition of a new approach that brings together elements and recommendations selected from the approaches analyzed, plus enhancements. To evaluate the proposed approach, a case study is discussed, and important results presented which demonstrate its applicability. Copyright © 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.
450	Regression testing is the cornerstone of quality assurance of software systems. However, executing regression test cases can impose significant computational and operational costs. In this context, Machine Learning-based Test Case Prioritization (ML-based TCP) techniques rank the execution of regression tests based on their probability of failures and execution time so that the faults can be detected as early as possible during the regression testing. Despite the recent progress of ML-based TCP, even the best reported ML-based TCP techniques can reach 90% or higher effectiveness in terms of Cost-cognizant Average Percentage of Faults Detected (APFDc) only in 20% of studied subjects. We argue that the imbalanced nature of used training datasets caused by the low failure rate of regression tests is one of the main reasons for this shortcoming. This work conducts an empirical study on applying 19 state-of the- art data balancing techniques for dealing with imbalanced data sets in the TCP context, based on the most comprehensive publicly available datasets. The results demonstrate that data balancing techniques can improve the effectiveness of the best-known ML-based TCP technique for most subjects, with an average of 0.06 in terms of APFDc.
451	Despite frequent allusions to the importance of change management and employee commitment in Business Process Management (BPM) initiatives, academics in this domain have so far failed to analyse how exactly employees perceive and experience these initiatives. Since we know BPM has an impact on employees, it is important for managers that are guiding process related change initiatives or leading people working in process oriented jobs to be aware of this impact and its consequences, as leaders play a crucial role in strategy based change initiatives. This paper aims to explore the employee's experiences with and perceptions of BPM, and whether these correspond to BPM experts' visions on BPM. Moreover, it constitutes a first test of a model that proposes an extra path through which BPM can increase the Organisational Performance: through Organisational Citizenship Behaviour. Results from eight case studies suggest a partial mismatch between the impact on employees that is generally claimed in literature and the real-life experiences of impacted employees, and reveal a potential for an increased beneficial impact of BPM.
452	Big data offers tremendous opportunities for transport process innovation. One key enabling big data technology is predictive data analytics. Predictive data analytics supports business process management by facilitating the proactive adaptation of process instances to mitigate or prevent problems. We present an industry case employing big data for process management innovation at duisport, the world's largest inland container port. In particular, we show how data-driven deep learning facilitates proactive port terminal process management. We demonstrate the feasibility of our deep learning approach by implementing it as part of a terminal productivity cockpit prototype. The terminal productivity cockpit provides decision support to terminal operators for proactive process adaptation. We confirm the desirability of our approach via interviews. We assess the viability of our approach by estimating the improvements in a key business KPI, as well as experimentally measuring the cost savings when compared to terminal operations without using proactive adaptation. We also present our main technical lessons learned regarding the use of big data for predictive analytics. © 2019 CEUR-WS. All rights reserved.
453	nan
454	A service supply chain (SSC) is a supply network that transfers resources into services with or without physical products, to satisfy customer needs. So it's evident that without offering the right service at the right time to the right person, the service is incomplete, inconsistent and ineffective. In the same context, the retirement field faces the challenge of offering the correct pension to the right pensioner the first month of his retirement. This paper approaches this challenge from a SSC perspective as a case study for dealing with continuity in service supply chain. It uses a methodology that combine Analysis-Specification-Design-Implementation (ASDI), Office Support Systems Analysis and Design (OSSAD), Business Process Management (BPM), and Supply Chain Operations Reference (SCOR). It analyzes and models the Moroccan retirement SSC, simulates the behavior of "the management of civil pension rights" process, and proposes a set of Key Performance Indicators (KPI) to evaluate the continuity in the service supply chain. Hence, this work provides guidance on the performance analysis of a SSC. © 2018 Authors.
455	The hospital is a complex system where many actors are involved; The challenges that this environment is facing justify the focus on this research subject. The contribution of the paper includes a proposition of a four-level model, that describes the hospital drug supply chain, based on the combination of the Supply Chain Operation Reference (SCOR) and Business Process Modelling Notation (BPMN), and the identification of a set of key performance indicators (KPI) that assess how well the drugs management process within the hospital are effective and efficient and how to improve them.
456	Teaching a formal method to business students can be quite challenging. Even more so, if this happens in a distance learning environment. For this purpose, the authors have developed the Repository for Ampersand Projects (RAP). RAP is a platform for researchers and students, that supports the learning of rule-based design in a formal method called Ampersand. While students perform design exercises in RAP, researchers are collecting measurements about the student's behaviour. RAP was designed to experiment with measurements of student behaviour, for the purpose of studying the didactics of this specific subject. In this paper, the authors demonstrate the practice of RAP by showing how various measurements have led to meaningful hypotheses about student behaviour. With RAP, the authors hope to increase their understanding of teaching formal methods and support students in learning Rule Based Design.
457	Just as BPM (business process management) technology is markedly different from conventional approaches to application support, the methodology of BPM development is markedly different from traditional software implementation techniques. With CPI (continuous process improvement) as the core discipline of BPM, the models that drive work through the company evolve constantly. Indeed, recent studies suggest that companies fine-tune their BPM-based applications at least once a quarter (and sometimes as often as eight times per year). The point is that there is no such thing as a "finished" process; it takes multiple iterations to produce highly effective solutions. Every working BPM-based process is just a starting point for the future. Moreover, with multiple processes that could benefit from BPM-style automated support, the issue becomes how to support dozens or even hundreds of engagements per year.
458	nan
459	Business process management is the discipline that encompasses the analysis, modelling, implementation, execution, monitoring/control and continuous improvement of business processes. Methods and models developed for this management activity offer wide-ranging assistance to, and potential for, most organisations, yet even a general awareness of them seems to be non-existent in many organisations. An empirical study, conducted in the German-speaking region of Europe, gathered useful data on issues relating to current and future investment in business process management, including initiatives in the field of business process outsourcing. Analysis of that data allows for the critical interpretation of the current viewpoint of this business discipline as well as providing some interesting new insights into applications in use, level of maturity, realised benefits and outsourcing opportunities. A bright future exists for business process management as long as the most significant hurdle, the failure to link the discipline with organisational strategy, is overcome. The pathway to achieve this lies in the development of a reliable and effective performance measurement system that, for the most part, will be unique to each organisation. © 2012 John Wiley & Sons, Ltd.
460	In the global economy, collaboration is no longer an option but a requirement for the organizations that want to achieve and maintain the competitive advantage on the market. The society based on knowledge and innovation, globalization and increased competition are the stimulating factors for switching from a traditional organization to an extended organization and further to the organization connected into a collaborative network. The organization networks have many advantages but also face challenges and problems mainly linked to the complexity of the collaborative environment. One of the main challenges of the organization networks is raised by the inter-organization processes. The complexity of these collaborative processes makes them difficult to model and represent them in a form that can be understood by electronic computing systems. Collaborative processes performance representation, automation and management require a good understanding of collaboration impact on business processes. This paper identifies the main characteristics of collaborative business processes, classifies them on several criteria, identifies possible approaches for management and implementation and proposes a mathematical model for measuring inter-organizational business process performance. © 2018, Bucharest University of Economic Studies. All rights reserved.
461	nan
462	The visualization of business data in a geographic context supports the decision making process by showing how e.g. sales data relates to other data. Tasks like market penetration analysis can be “visually” tackled by combining enterprise and market data on a map. In this paper it is shown how maps can be linked to the data queried from SAP's Business Information Warehouse (BW), in order to benefit from geographic analysis. BW provides a seamless integration of its unique GIS Tool called Business Explorer Map (BEx Map), in such a way that any report containing geographic data, can be displayed on a map. BEx Map provides an easy way of navigating (zoom in, geographic drill-down, slice &amp; dice) through BW reports, enabling all end-users to interactively analyze the BW report data.
463	nan
464	Easy-to-understand and up-to-date models of business processes are important for enterprises, as they aim to describe how work is executed in reality and provide a starting point for process analysis and optimization. With an increasing amount of event data logged by information systems today, the automatic discovery of process models from process logs has become possible. Whereas most existing techniques focus on the discovery of well-formalized models (e.g. Petri nets) which are popular among researchers, business analysts prefer business domain-specific models (such as Business Process Model Notation, BPMN) which are not well formally specified. We present and evaluate an approach for discovering the latter type of process models by formally specifying a hierarchical view on business process models and applying an evolution strategy on it. The evolution strategy efficiently finds process models which best represent a given event log by using fast methods for process model conformance checking, and is partly guided by the diversity of the process model population. The approach contributes to the field of evolutionary algorithms by showing that they can be successfully applied in the real-world use case of process discovery, and contributes to the process discovery domain by providing a promising alternative to existing methods.
465	Supporting business services through Web service compositions (WSC) as part of service-oriented architectures (SOA) involves business performance monitoring requirements. Their implementation results in additional development activities. To support these activities, we already contributed a model-driven approach to the development of monitored WSC as part of our preliminary work. In this paper, we present an extension to this approach, which focuses on supporting the specification and transformation of indicators to an executable implementation. To reduce development effort for this particular task, we provide a template-based mechanism for defining performance indicators. In combination with our preliminary work, now fully monitored WSC can be generated automatically from platformindependent design models. We demonstrate the applicability of the overall approach by instantiating an integrated development process for a target platform based on IBM SOA products and showing its application for a sample business process along with monitoring requirements. © 2009 IEEE.
466	A recent research manifesto has introduced the vision of AI-Augmented BPM (ABPM), where BPM systems are infused with AI to continuously adapt and improve a set of business processes with respect to one or more performance indicators. In the ABPM lifecycle, process modelling is lifted to the more general notion of process framing, which aims at capturing the boundaries within which the executions of one or more processes of interest should be confined. In this paper, I argue in favour of constraint-based declarative process specifications for process framing. I provide a list of key features that are needed towards this goal, and show how they are matched by research milestones recently obtained in this setting. In particular, I discuss how to deal with deviations, uncertainty, and object-centric processes. © 2023, Springer Nature Switzerland AG.
467	Business Process Automation has been gaining increasing importance in the management of companies and organizations since it reduces the time needed to carry out routine tasks, freeing employees for other, more creative and exciting things. It can be applied in the most varied business areas. Organizations from any sector of activity can also adopt it. Given these benefits, the granted success in transforming business processes would be expected. However, automation initiatives still fail. Adopting this technology can raise social, technological, ethical, methodical, and organizational issues. These facts have triggered the necessity for a summary that could extract more information about how to implement Business Process Automation (BPA), attending to the administrative processes, especially when applied in Small and Medium-sized Enterprises (SMEs). This study aims not only to review the available literature on how to implement BPA but also to typify the processes that can be automated, which technologies or tools exist for making that change, and influence factors in the procedure of BPA. We have covered more than 300 research papers published between 2016 and 2023 in reputable scientific data sources like Scopus, Web of Science/Clarivate, and ScienceDirect/Elsevier. The review revealed some paths for BPA, with some common steps. In addition, some common process characteristics fundamental to automation are exposed, as well as factors that are critical to an organization for successful automation. The results indicate that BPA is an established area in Business Process Management related to technologies/tools like Robotic Process Automation (RPA) or Cognitive-Robotic Process Automation (C-RPA), Workflow Management Systems (WfMS), Enterprise Resource Planning (ERP), and Blockchain. As far as we observed, this Systematic Literature Review (SLR) is a unique study that covers all the environmental variables for applying automation in business processes.
468	The development of products and IT services in bank sector, including the number and the complexity of processes required to operate efficiently, have had important improvements. The work that is presented in this paper is focused on the modelling of business processes that a banking organization follows, during the procedures of a loan request. These activities are modeled with the aim to trace time-consuming processes, which cause delays to the total procedure. The methodology that is used for the Bank loan processes is the Business Process Modelling Notation (BPMN). Objectives of this work are: reduction in the duration of implementation of enterprising process, reduction of implementation time, reduction of cost, improvement of quality. Through the application of BPM and the use of process-oriented IT systems (BPM systems using BPEL code) bank performance of loan processes could be increased substantially. The proposed system will help in the synchronized selection and effective correlation of all information, so as to result in the creation of a centralized knowledge base, through the dynamic depiction of important Key Performance Indicator networks. Furthermore, for modelling and assessment of loan process effectiveness purposes and in order to model in the best way the analyzed simulation results, some specific KPIs are proposed in order to measure and assess BPMN-based processes. © 2010 IEEE.
469	Soft System Methodology (SSM) is a systematic approach for tackling real-world of Business Process Management (BPM). There are some disadvantages of using Soft System Methodology (SSM): reliance on an expert, the result become fuzzy and has separated indicator with hard system. Now, we are discussing new idea that standardizes a Key Performance Indicator for decision making on the Soft System Methodology (SSM) assisted by Fuzzy Question in System Perspective. © 2014 IEEE.
470	nan
471	Software maintenance is a difficult task under the best of circumstances. Having work performed by an on-site contractor adds an additional layer of complexity to the customer's task. This type of relationship places greater emphasis on formal work procedures and detailed reports of the work in progress. It also promotes the use of performance norms for evaluating contractor performance. These factors are all on the positive side. However, such a relationship also calls for a special awareness of contractor ploys calculated to increase their performance evaluation.From the contractor's point of view, being on-site imposes a more disciplined environment and places special importance on the manner and means of dealing with the customer. Another special feature is that the contractor receives formal feedback from the users, through periodic performance evaluations, indicating how well the software maintenance group measures up to expectations.This paper describes the lessons learned by one customer and one on-site contractor.
472	In July 2000 I wrote the preface to the first edition of this book, which read: Performance measurement is on the agenda. New reports and articles on the topic have been appearing at a rate of one every five hours of every working day since 1994. A search of the World Wide Web reveals over 170,000 sites dedicated to it. In 1996, one new book on the subject appeared every two weeks in the US alone. Since 1994 Business Intelligence, a professional conference organising company based in the UK, has organised some 90 separate events on business performance measurement (BPM). Some 2,700 delegates from over 1,400 different firms attended these conferences. In terms of delegate fees alone, Business Intelligence has accrued over $5 million. Add to this, the revenues received by other conference organisers, publishers, market research firms, software vendors and consultants and it is clear that business performance measurement is a multi-million dollar industry. Like many multi-million dollar industries developments are rapid. Recent years have seen the introduction of new methods of measurement, such as activity-based costing, throughput accounting and shareholder value analysis. New measurement frameworks, most notably the balanced scorecard and the business excellence model, have taken the business community by storm. Data collected by the US research firm, Gartner, suggest that 70% of firms will be using balanced scorecards to measure business performance by the end of 2000. Other data, such as that collected by the US consulting firm Towers Perrin, indicate that the majority of firms have introduced their balanced scorecards during the last five years. © Cambridge University Press 2002, 2007.
473	Process improvement initiatives require access to frequently updated and good quality data. This is an extremely difficult task in the area of production processes, where the lack of a process digital footprint is a very big challenge. To solve this problem, the authors of this article designed, implemented, and verified the results of a new work measurement method. The Workplace Performance Measurement (WPM) method is focused not only on the measurement of task duration and frequency, but also on searching for potential anomalies and their reasons. The WPM method collects a wide range of workspace parameters, including workers' activities, workers' physiological parameters, and tool usage. An application of Process Mining and Machine Learning solutions has allowed us to not only significantly increase the quality of analysis (compared to analog work sampling methods), but also to implement an automated controlling solution. The genuine value of the WPM is attested to by the achieved results, like increased efficiency of production processes, better visibility of process flow, or delivery of input data to MES solutions. MES systems require good quality, frequently updated information, and this is the role played by the WPM, which can provide this type of data for Master Data as well as for Production Orders. The presented authorial WPM method reduces the gap in available scholarship and practical solutions, enabling the collection of reliable data on the actual flow of business processes without their disruption, relevant for i.a. advanced systems using AI. © The Author(s) 2024.
474	Abstract Process mining enables the reconstruction and evaluation of business processes based on digital traces in IT systems. An increasingly important technique in this context is process prediction. Given a sequence of events of an ongoing trace, process prediction allows forecasting upcoming events or performance measurements. In recent years, multiple process prediction approaches have been proposed, applying different data processing schemes and prediction algorithms. This study focuses on deep learning algorithms since they seem to outperform their machine learning alternatives consistently. Whilst having a common learning algorithm, they use different data preprocessing techniques, implement a variety of network topologies and focus on various goals such as outcome prediction, time prediction or control-flow prediction. Additionally, the set of log-data, evaluation metrics and baselines used by the authors diverge, making the results hard to compare. This paper attempts to synthesise the advantages and disadvantages of the procedural decisions in these approaches by conducting a systematic literature review.
475	Deploying web services on Shop Floor devices in a manufacturing enterprise extends the Service Oriented Architecture (SOA) to the device level, bringing Shop Floor and Enterprise computing resources closer to each other. In this paper, we further extend the SOA landscape towards cross enterprise scenarios, which benefit adaptive manufacturing to be extremely flexible till the last stages of production. A method using mash up of web service technologies like DPWS, BPEL and eSOA, is employed in this work. Possible methods to implement Web Services on wireless sensor nodes like SunSPOTs are also examined. These methods could be used together as an experimental platform to evaluate a new paradigm of factory automation and enterprise computing, in which shop floor real time data are easily accessible from the business level and can be shared among enterprises. This brings a new way of cross enterprise computing called Shop Floor Commerce.
476	The growing scrutiny from the public and stakeholders in terms of quality as well as requirements from the government and the needs to keep up with regional and international developments have been the driving forces in facilitating the need for accreditation of higher education institutions in Vietnam, both at the institutional and the program levels. Accreditation has provided a framework for universities in general and business programs in particular to pursue high standards in quality towards continuous and sustainable development. This paper presents a case study of a private university in Vietnam which has recently achieved the accreditation status for its Business Administration program, as granted by the Accreditation Council for Business Schools and Programs (ACBSP), to present a process of accreditation and discuss the implications for continuous improvement of the program, faculty, and institution in the future. This information is expected to provide comprehensive understanding for not only university seeking ACBSP accredited but also other similar program-level accreditation.
477	With the advent of Industry 4.0, industrial manufacturing systems constantly evolve into smart, interconnected production systems. Pervasive integration of information and communication technology into productional components results in massive amounts of various data. To meet the challenges that arise from an increasingly competitive market and more demanding customer requirements, technological drivers have to be leveraged in order to process data effectively. One important aspect in that regard is the efficient management of business processes and process risks. As an integrative concept in these areas is missing, we present a holistic framework for data-driven risk assessment based on real-time data. Besides a conceptual model, we provide a technical concept that combines methods for risk assessment with performance metrics and demonstrate a software implementation in the context of an exemplary use case scenario. Finally, we present the results of expert interviews and a discussion indicating future research directions. © 2016 IEEE.
478	The developer-centric approach to measuring and improving productivity.
479	Environmentally-aware resource usage has become an important aspect for today's industries, governments, and organizations. Customer demands, legal requirements, and financial aspects force organizations to rethink and reorganize their existing structures and business processes. Along with an increasing adoption of Business Process Management (BPM) in organizations, efforts are being made to also enable a green rethinking and change of BPM. However, in order to be capable of performing business in a green manner, the "delta" has to be known that distinguishes green business process management from the conventional one. In this paper, we investigate key perspectives of conventional BPM and compare them to requirements originating from an environmental perspective. The key perspectives we refer to are the business process lifecycle, key performance indicators, BPM architectures, and business and strategy. We highlight aspects that need to be extended, newly developed, or refined in order to achieve a holistic green BPM approach. © 2011 IEEE.
480	nan
481	The literature on Supply Chain Management (SCM) supports the integration of key business processes, including the performance management process, in order to increase the performance within and between the organisations. Nevertheless, the lack of proper shared performance metrics, frameworks and technology in order to design, implement and manage Performance Measurement Systems (PMSs), have been identified as problems for achieving integration. Semantics-based technologies, especially ontologies, have been suggested to address such problems. The purpose of this paper is to discuss how ontologies may be used to raise interoperability and shared understanding in inter-organisational PMSs from syntactic to semantic level by introducing the concept of Semantic PMS. We also suggest future research issues for approaching collaborative performance management problems. © 2010 Springer-Verlag Berlin Heidelberg.
482	Abstract Ever-growing data availability combined with rapid progress in analytics has laid the foundation for the emergence of business process analytics. Organizations strive to leverage predictive process analytics to obtain insights. However, current implementations are designed to deal with homogeneous data. Consequently, there is limited practical use in an organization with heterogeneous data sources. The paper proposes a method for predictive end-to-end enterprise process network monitoring leveraging multi-headed deep neural networks to overcome this limitation. A case study performed with a medium-sized German manufacturing company highlights the method’s utility for organizations.
483	Business processes and services of Service Oriented Virtual Organizations are subject to change to meet the internal and external requirements of the competitive and rapidly changing environment they operate in. Efficient and practical change management solutions are needed to enable partners to gain insight on the procedures and the processes which can be used to facilitate the process of change. This paper presents a procedural change management framework to facilitate the process of change allowing the participating partners in a Virtual Organization to initiate, assess, collaborate, authorize, implement, evaluate and control changes in the SOVO. The solution consists of a multi-layered procedural framework, including the six layers of change processes, change actors, change control requirements and related management interfaces. It is derived from Information Technology Infrastructure Library (ITIL V3), Engineering Change Management (ECM) and European Collaborative Networked Organizations Leadership initiative (ECOLEAD) best practices and recommendations and customized to fit SOVO requirements and challenges. We present the implementation of six layers of changes processes using the IBM Business Process Manager (BPM) and the implementation architecture of the change management console to facilitate the process of change in SOVO.
484	In the field of Business Process Management (BPM), planning and executing precise process tailoring and optimization can be done through different design strategies. Even though Situational Method Engineering (SME) can provide an additional layer of constitutional knowledge, it hasn’t been explored as deeply as other traditional methods. Strategies that rely on a so-called “situational context” make use of the atomic conceptual entities known as method chunks and/or fragments from the field of Situational Method Engineering (SME). BPM, on the other hand, describes processes through representational tools that have been thoroughly used in industry and established as reliable. All of these designs have advantages and disadvantages. We analyzed several designs and proposed a synthesized framework (metamodel) that combines their strong points, while also providing a way to objectively quantify and restructure the performance of a pre-existing process/product (or optimize the creation of an entirely new one). We provide an analysis with a manufacturing organization using BPM concepts for process management/improvement and our proposed method framework, which incorporates Situational Method Engineering metamodelling and the Critical Path Method as a base for process improvement. We show here how using our proposed framework brings a flexible approach to a structured process management, helping enterprises to define, apply, store and retrieve their processes through methods/fragments, while also providing a guideline for systematic tailoring.
485	Business process management and business intelligence initiatives are commonly seen as separated organisational projects, suffering from lack of coordination, leading to a poor alignment between strategic management and operational business processes execution. Information systems researchers andprofessionals have recognised that business processes are the key for identifying the user needs for developing the software that supports those requirements. This paper presents a process based approach for identifying an analytical data model using as input a set of interrelated business processes, modelled with business process model and notation (BPMN), and the corresponding persistent operational data model. This process-based approach extends the BPMN language allowing the integration of behavioural aspects and processes performance measures in the persistent operational data model. The proposed approach ensures the identification of an analytical data model for a data warehouse, integrating dimensions, facts, relationships and measures, providing useful data analytics perspectives of the data under analysis. Copyright © 2017 Inderscience Enterprises Ltd.
486	Cloud computing services are accessible from anywhere and used worldwide. There is plenty of information about concepts, architecture and models to deploy cloud systems. On the other hand, there is a lack of standardized information about utilization, contracts, and main performance metrics demanded by cloud services. Those data are usually private, non-structured and even customers commonly do not know exactly their contract clauses and demands. In this paper, we conducted a survey to investigate how the actual demands of customers are, in order to provide useful information for the specification of new models and to support decision making in cloud businesses. Based on the results obtained, we have identified the strong dependency of cloud services in the network level, and systematized an approach for cloud network governance to advance the state-of-the-practice in cloud governance and its relationship with business process management. © 2015 IEEE.
487	The article discusses the conceptual aspects of the relationship between strategic management and corporate business processes. Strategic changes within the corporation when changing the structure of business processes are identified and classified. The model of strategic management of business process reengineering was created and the economic and mathematical substantiation of its prospects of functioning was developed. Methodologically, the development of a strategic management system should be carried out using modern analytical approaches, which will allow at the systemic level to form decisions on the management of business processes taking into account the market features of corporations. Strategic level and business architecture interconnection techniques provide tools to evaluate, streamline business processes to meet corporate performance targets. Development of a comprehensive program of changes in the structure of business processes, which should take into account all areas of activity. The proposed model of strategic management of layered business processes can be used to develop strategic charts of a corporation, to record and control performance indicators of business processes, to assess the degree of achievement of strategic goals and to increase the adequacy of management decisions. The proposed model and analytical technologies allow to increasing the effectiveness of strategic business process management. Based on the proposed model, it seems possible to form and make a reasonable choice of the optimal management decision at the system level, taking into account the structure of the business process and the goals of the corporate strategy. © 2019 Allied Business Academies.
488	Some Business Process Management Systems (BPMSs) have been developed in the field of smart factories. These systems are typically based on technical or production areas and technical processes. However, many existing systems, with respect to technologies used in smart factories and also the dynamic nature of the processes in these environments, are not able meet requirements of smart factories in the business process execution. The present study presents a new prototype of BPMS architecture based on smart factories' characteristics. This prototype has several components. In the monitoring component, process management can take place through process mining techniques inside a defined data analysis system for collecting event logs from big data. This component could operate based on control and optimization modules. The control module is applied to discover process models and their conformity with models extracted from business process analysis using Non-dominated Sorting Genetic Algorithm-II (NSGA-II) and Adaptive Boosting (AdaBoost) algorithms. Also, the optimization module can improve the processes model based on Business Process Intelligence (BPI) technique and Key Performance Indicators (KPIs). The results of the new prototype execution on a case study indicate that the proposed architecture is highly accurate, complete, and optimal in process management for smart factories. © 2024 Sharif University of Technology. All rights reserved.
489	The challenges in the global economy have forced companies to rethink the way they operate and their relations with both customers and subcontractors. To remain competitive, companies need to align their business processes with the firm's strategy and make a strategic use of information technology. This paper addresses one of the important issues in business process management field as well as strategic alignment that is, how do we create and sustain alignment between business processes and strategy? The authors have performed a literature review in order to analyse the challenges and critical success factors in process management and business and IT alignment. The results of that investigation are the basis for developing the approach that is advocated in this paper. Four case studies have been conducted in the area of Jönköping in order to test the validity of the approach in Small and Medium Enterprises (SMEs). The results show that SMEs continuously put efforts to maintain alignment between their business processes and strategy by means of Information Technology. They usually consider people, management, IT/IS and organisational culture as most important in order to create alignment between strategy and business processes. Organisational structure and performance measurement tend to be less important.
490	In this paper we examine an initial step towards Green Business Process Management. We give insights from a research project with the goal of monitoring and redesigning business processes in an environmentally sustainable manner. Using literature analysis and three case studies we derive suitable languages and software for business process modeling. In addition, we show business processes that can act as key examples for green process monitoring and redesign. The results show that enterprises can build up on process modeling and energy monitoring to become more environmentally sustainable. © (2012) by the AIS/ICIS Administrative Office All rights reserved.
491	nan
492	Business Process Management Systems (BPMSs) provide automated support for the execution of business processes in modern organisations. With the emergence of cloud computing, BPMS deployment considerations are shifting from traditional on-premise models to the Software-as-a-Service (SaaS) paradigm, aiming at delivering Business Process Automation as a Service. However, scaling up a traditional BPMS to cope with simultaneous demand from multiple organisations in the cloud is challenging, since its underlying system architecture has been designed to serve a single organisation with a single process engine. Moreover, the complexity in addressing both the dynamic execution environment and the elasticity requirements of users impose further challenges to deploying a traditional BPMS in the cloud. A typical SaaS often deploys multiple instances of its core applications and distributes workload to these application instances via load balancing. But, for stateful and often long-running process instances, standard stateless load balancing strategies are inadequate. In this article, we propose a conceptual design of BPMS capable of addressing dynamically varying demands of end users in the cloud, and present a prototypical implementation using an open source traditional BPMS platform. Both the design and system realisation offer focused strategies on achieving scalability and demonstrates the system capabilities for supporting both upscaling, to address large volumes of user demand or workload, and downscaling, to release underutilised computing resources, in a cloud environment.
493	The benefits of using a systematic information technology-based performance measurement disciplines namely capability maturity models (CMM), control objectives for information and related technology (CobiT) and IT infrastructure library (ITIL), embedded into a general business process management (BPM) framework by companies to improve their organizational performance are discussed. CMM provides a roadmap for continous process improvement and can be used for self-assessment. CobiT enables IT to address risks and works well with ITIL. CMM, CobiT and ITIL are all compatible within themselves and also complement other general BPM frameworks such as ISO 9000, Six Sigma and the balanced scoreboard.
494	Purpose – The purpose of this paper is to create a conceptual proposal that considers the relevant aspects to guide the promotion and evolution of corporate sustainability performance measurement systems (SPMSs) from a perspective of business process management. Design/methodology/approach – This study is divided into two phases. The first phase is a literature review with the study question was, “Which aspects need to be considered for promoting and evolving SPMS with a focus on business processes?” The second phase involved comparing these approaches and presenting a conceptual proposal with the relevant aspects for promoting and evolving a corporate SPMS. Findings – In the literature review, the following aspects were considered relevant to promoting sustainability: strategy, integration, stakeholders, evolution over time and business processes. The conceptual proposal found each aspect relevant and complementary presented consideration for each, forming one SPMS pentagon. Research limitations/implications – The comparison between the approaches is conceptual. Practical implications – This study can help organizations address the evolution of their measurement systems systemically. Originality/value – The summaries of the main considerations and evaluation issues provide starting points for organizations, researchers and students involved in sustainability-related matters. The discussion presented here can help organizations identify the strengths and weaknesses of their measurement systems and provide a basis for the promotion and implementation of improvements. © 2015, Emerald Group Publishing Limited.
495	The Internet of Things (IoT) envisions a huge number of networked sensors connected to the internet. These sensors collect large streams of data which serve as input to wide range of IoT applications and services such as e-health, e-commerce, and automotive services. Complex Event Processing (CEP) is a powerful tool that transforms streams of raw sensor data into meaningful information required by these IoT services. Often these streams of data collected by sensors carry privacy-sensitive information about the user. Thus, protecting privacy is of paramount importance in IoT services based on CEP.In this paper we present a novel pattern-level access control mechanism for CEP based services that conceals private information while minimizing the impact on useful non-sensitive information required by the services to provide a certain quality of service (QoS). The idea is to reorder events from the event stream to conceal privacy-sensitive event patterns while preserving non-privacy sensitive event patterns to maximize QoS. We propose two approaches, namely an ILP-based approach and a graph-based approach, calculating an optimal reordering of events. Our evaluation results show that these approaches are effective in concealing private patterns without significant loss of QoS.
496	nan
497	nan
498	The execution of business process is a management process for the integration of goals, systems, processes, information and persons. While most Chinese enterprises are faced with the main problem which is business process management that cannot be implemented effectively, thus it can not achieve the desired target value. So key performance indicator (KPI) evaluation system is added in the enterprise informatization framework that can change the dynamic structure of business process quickly, thus make it meet rapid changes in market demand.
499	The turn of century saw ICT technologies making inroads into our lives. The governments world over are trying to use this medium for reaching out to their citizenry. This migration has been partly driven by transparency, efficiency and wider-access related benefits accrued by automation of government functions. E-Government Procurement (E-GP) is one such area which has drawn attention of politicians and researchers equally. However, studies bring out that E-GP project like any other e-Governance project has 70% chances of failure. Studies also underline that success of any E-GP system among other things, is affected by national culture, project environment (E-Readiness, IT literacy level and technological evolution) and regulatory framework which govern public procurement in a country. Indian government having realized the transparency and efficiency related benefits of E-GP system initiated an aggressive campaign to ensure its speedier implementation through National E-Governance Programme (NeGP) which was launched in 2006. However, recent review by Government of India (GoI) brought out that E-GP usage in the country has been less than satisfactory. In above perspective, this paper aims to undertake Template Analysis of stage-wise importance of 11 Critical Success Factors (CSF) (reported in literature) in E-GP project outcome in Indian context. For covering large landscape of E-GP implementation in India, two representative systems i.e. those implemented by Government of Andhra Pradesh and National Informatics Corporation were selected. The study concludes that out of 11 CSFs, five CSFs are not important at stage 2 of E-GP project evolution, while all 11 CSFs contribute to E-GP project success at Stage 3 and 4.
500	This research is focused on architectural and modeling issues of design and development of digital reporting system aimed at the railway communication network infrastructure. Our approach to these problems is based on digital ecosystem paradigm and open-source Big Data technologies. It also aims at methodology for KPIs data preparation and collection in railway communication networks. A practical result of the research is a proposed software framework for digital reporting system that consists of multiple agents, which are important for efficient KPIs data integration and processing in communication network reporting system. We have created and tested a prototype digital reporting system using KPIs data from the production railway communication network. KPIs data used in test implementation and obtained from the largest Russian Railway company included all incidents, occurred in the railway communication network in a week period. Prototype system implementation successfully processed all KPIs data using proposed data methodology and integrated framework.
501	nan
502	Data-driven techniques are used in cyber-physical systems (CPS) for controlling autonomous vehicles, handling demand responses for energy management, and modeling human physiology for medical devices. These data-driven techniques extract models from training data, where their performance is often analyzed with respect to random errors in the training data. However, if the training data is maliciously altered by attackers, the effect of these attacks on the learning algorithms underpinning data-driven CPS have yet to be considered. In this paper, we analyze the resilience of classification algorithms to training data attacks. Specifically, a generic metric is proposed that is tailored to measure resilience of classification algorithms with respect to worst-case tampering of the training data. Using the metric, we show that traditional linear classification algorithms are resilient under restricted conditions. To overcome these limitations, we propose a linear classification algorithm with a majority constraint and prove that it is strictly more resilient than the traditional algorithms. Evaluations on both synthetic data and a real-world retrospective arrhythmia medical case-study show that the traditional algorithms are vulnerable to tampered training data, whereas the proposed algorithm is more resilient (as measured by worst-case tampering).
503	Clinical practice guidelines (CPGs) are a formalization of specific clinical knowledge that states the best evidence-based clinical practices for treating pathologies. However, CPGs are limited because they are usually expressed as text. This gives rise to a certain level of ambiguity, subjective interpretation of the actions to be performed, and variability in clinical practice by different health professionals facing the same circumstances. The inherent complexity of CPGs is also a challenge for software engineers designing, developing, and maintaining software systems and clinical decision support system to manage and digitize them. This challenge stems from the need to evolve CPGs and design software systems capable of allowing their evolution. This paper proposes a model-driven, human-centric and tool-supported framework (called IDE4ICDS) for improving digitisation of CPG in practical environments. This framework is designed from a human-centric perspective to be used by mixed teams of clinicians and software engineers. It was also validated with the type 2 diabetes mellitus CPG in the Andalusian Public Health System (Spain) involving 89 patients and obtaining a kappa-based analysis. The recommendations were acceptable (0.61–0.80) with a total kappa index of 0.701, leading to the conclusion that the proposal provided appropriate recommendations for each patient.
504	PURPOSE: The concept of business analytics (BA) and business intelligence (BI) is just emerging in the Philippines. Since these are new concepts, it is important to investigate their impact on organizational performance and the performance metrics in business industry. The aim of this study is to examine the impact of business analytics generating business intelligence and how it affects organizational performance by developing a structural model. Consequently, the impact of organizational performance on other performance metrics was also established. METHODOLOGY: The partial least squares – structural equation modeling was utilized, which proposed a model that shows how business intelligence, generated by business BA, affects organizational performance, which consequently leads to improved marketing, financial, and business process performance. A survey was conducted on business analysts and executive managers of retail companies that have already been implementing BA for at least three years. FINDINGS: BA capabilities have a significant positive effect on the level of BI. BI has a significant positive effect on organizational performance. However, the result of the moderation analysis indicated that the level of readiness for BA implementation could not be considered a moderating factor on the relationship between BI and organizational performance. IMPLICATIONS: Out of the different BA capabilities, the decision support system and business process management were found to be the most beneficial functions in generating BI. BI amplifies organizational performance and consequently improves the marketing and business process performance of retail firms. However, the readiness for BA implementation does not significantly affect how BI improves organizational performance. Overall, it is recommended that in order to enhance marketing and business process performance, retail firms should focus on the BA capabilities of decision support system and business process management. ORIGINALITY AND VALUE: This would be the first empirical study in the Philippines which has assessed how business analytics and business intelligence impact organizational performance. This study is original in determining what BA capabilities generate BI, which translates to improved organizational performance. This study is also unique in defining what key performance metrics are much improved as a result of its implementation. This may serve as a viable reference for other researchers interested in business analytics and other technology about data management applied in business operations. © 2022, Cognitione Foundation for the Dissemination of Knowledge and Science. All rights reserved.
505	Business Process Management (BPM) aims to support the whole life-cycle necessary to deploy and maintain business processes in organisations. Crucial within the BPM life-cycle is the analysis of deployed processes. Analysing business processes requires computing metrics that can help determining the health of business activities and thus the whole enterprise. However, the degree of automation currently achieved cannot support the level of reactivity and adaptation demanded by businesses. In this paper we argue and show how the use of Semantic Web technologies can increase to an important extent the level of automation for analysing business processes. We present a domain-independent ontological framework for Business Process Analysis (BPA) with support for automatically computing metrics. In particular, we define a set of ontologies for specifying metrics. We describe a domain-independent metrics computation engine that can interpret and compute them. Finally we illustrate and evaluate our approach with a set of general purpose metrics.
506	The aim of the present work is to propose a prototype simulation of a hospital ward which permits the study of the workload and task distribution among nursing and auxiliary personnel. In our study, we took both X a generic ward in a complex healthcare structure (University Hospital "Federico II" – Naples, Italy) and a case study of a hospital immunology department as reference models. Both analyses were carried out together with a team of expert head nurses and following a specific simulation model developed in the Simul8 environment, which allowed the calculation of patient assistance timing as well as the efficiency of personnel use depending on the patient autonomy.
507	In outpatient management, the lead-time is a critical issue due to its important negative effect on healthcare quality perception. In particular, it generates the phenomenon of "no-show": when patients do not attend their scheduled appointments. In this study, we analyze the process of outpatient booking and its critical issues; in particular, we propose a simulation model to evaluate some different approaches. From our results, the lists cleaning can be considered a good tool to manage and reduce the no-show.
508	This paper describes a method for constructing econometric planning models that can translate macroeconomic information into projected income statements for each of a corporation's various business units. Each business unit is modeled by equations expressing historical relationships between micro variables of interest (sales, various costs, net income) and their macro and/or internal determinants. The text provides guidelines for designing a model structure, specifying and estimating major equations, and using the model.
509	nan
510	Companies are increasingly incorporating commercial Business Process Management Systems (BPMSs) as mechanisms to automate their daily procedures. These BPMSs manage the information related to the instances that flow through the model (business data), and recover the information concerning the process performance (Process Performance Indicators). Process Performance Indicators (PPIs) tend to be used for the detection of possible deviations of expected behaviour, and help in the post-mortem analysis and redesign by improving the goals of the processes. However, not only are PPIs important in terms of their ability to measure and detect a derivation, but they should also be included at decision points to make the business processes more adaptable to the process reality at runtime. In this paper, we propose a complete solution that allows the incorporation of the PPIs into decision tasks, following the Decision Model and Notation (DMN) standard, with the aim of enriching the decisions that can be taken during the process execution. Our proposal firstly includes an extension of the decision rule grammar of the DMN standard, by incorporating the definition and the use of a Process Instance Query Language (PIQL) that offers information about the instances related to the PPIs involved. In order to achieve this objective, a framework has also been developed to support the enrichment of process instance query expressions (PIQEs). This framework combines a set of mature technologies to evaluate the decisions about PPIs at runtime. As an illustration a real sample has been used whose decisions are improved thanks to the incorporation of the PPIs at runtime. © 2016 IEEE.
511	During the last 10 years, important contributions about knowledge management (KM) issues in supply chain management (SCM) have been published. The current paper aims to build upon previous literature reviews focused on KM in supply chains (SCs) from an integrative perspective, particularly recognising the studies conducted by Bhosale and Kant (2016. “Metadata Analysis of Knowledge Management in Supply Chain: Investigating the Past and Predicting the Future.” Business Process Management Journal 22 (1): 140–172) and Cerchione and Esposito (2016. “A Systematic Review of Supply Chain Knowledge Management Research: State of the Art and Research Opportunities.” International Journal of Production Economics 182: 276–292) as an effort to discuss the evolution of KM in the SC field. To this end, a systematic literature review including 210 papers is conducted over the period 2008–2017 from three positions previously not addressed jointly within the supply chain (SC) context: research methods employed by the authors; KM processes applied in the business processes across the SC; and intra and inter- organisational performance metrics linked with KM initiatives. Results exhibited that: (i) ‘Survey’ and ‘Case study’ are the two research methodologies mostly employed by authors (ii) the knowledge transfer is discussed in the majority of the studies reviewed, (iii) 114 intra and inter-organisational performance metrics are reported within the SC context from an empirical data approach. Findings concerning previous identified gap analysis and future lines of research are described. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.
512	nan
513	With the advent of mobile computing and location-based services, an increasing amount of spatial data is being collected and stored in databases. Spatial data are becoming a corner stone for decision-makers to analyze business data in a spatial context. However, this task is a non-trivial task when using Geographic Information Systems (GIS) with Data Warehouse (DW) because these two technologies are in general used separately. GIS typically handles spatial data without considering time constrains and DW manages non-spatial data for different time periods. Moreover, the DW process, though supporting bottom-up extraction of information from data, fails in top-down enforcing the company strategy. A new approach called Business Performance Management (BPM) is emerging from this framework: it includes DW but it also requires a reactive component capable of monitoring spatio-temporal Key Performance Indicators (KPI) to allow tactical and operational decision-makers to tune their actions according to the organization strategy. In this paper, we propose a business performance management approach to describe decision-makers metrics-driven information requirements, in a context of evolving specifications. The paper outlines how the spatial dimension may affect the decision process. Using a practical example in the field of airport traffic control, we evaluate the implementation of the model.
514	Reducing the processing time of instances at critical activities is essential for many application domains. We refer to an activity as being critical if due to restricted resources assigned to the activity, the arrival of a certain number of process instances might lead to a waiting queue. So far, queuing has been adopted for process optimization in a merely static manner, i.e., the strategy in which order the instances are processed from the queue is fixed. We argue that determining the processing strategy for instance queues at runtime (dynamic queuing) offers the potential to reduce the processing time at critical activities. The core idea is that instances arriving at critical activities are first clustered based on similar features and are then distributed to dynamic queues accordingly. The decision on the processing order for the resulting queues requires a state management for allocating the appropriate number of resources during runtime. For this, a configurable performance index is used. The proposed dynamic queuing approach is prototypically implemented and evaluated based on a realistic data set.
515	We introduce look-ahead strategies to sort the work-items in work lists of process agents in order to improve key performance indicators for the execution of business processes. In contrast to well known strategies relying solely on local information like first-in first-out (FIFO) or earliest-deadline-first (EDF), our look-ahead approach utilizes structural, organizational, empirical, and current workload information of the process to provide a heuristics for computing recommendations for actors, which work-item should be selected next for execution. We describe the look ahead strategies and report and discuss the results of simulation experiments for checking the feasibility of the approach.
516	Measuring performance of business processes is necessary to access information on their efficacy. This enables successful optimization, reengineering and alignment on strategies. In general, measurement is done via numeric KPIs. Though, especially processes of a quantitative, nondeterministic or supportive nature are hard to describe via figures which leads to a reduced perception of performance problems. In this paper, the concept of visibility is presented. It fosters the development of a suitable Performance Assessment System (PAS) that broadens the range of indicators to e.g. goals, complexity, maturity, relations or dependencies in addition to KPIs to finally improve visibility of process performance. © 2011 IEEE.
517	When results of business processes cannot be measured, the application of numeric Key Performance Indicators fails. Process performance cannot easily be analyzed unless other indirect indicators are applied. So, other existing models for process analysis containing convenient solutions and indicators have to be assessed and validated in order to use them to sufficiently assess business processes. In this article, various existing models were reviewed in an empirical investigation, categorized in systems and put into context to relevant theories. The result of the research is a Reference Model Catalog of Models for Business Process Analysis that also incorporates indirect process performance aspects like soft goals, complexity, maturity or dependencies. It is enabling enterprises and researchers to select a convenient process analysis model for their specific performance problem. Moreover, it is offering a comprehensive overview of models and visualizes correlative voids in their scope.
518	Measuring performance is a key to optimize business processes. However, many of them cannot be easily measured due to their non-deterministic or qualitative nature. So, to fit in common performance measurement systems (PMS) that normally use numeric parameters (KPIs), artificial and simplifying measures have to be used that are complicated and costly to create and evaluate. Using a literature review, this paper documents the dominance of PMS that rely on KPIs and a lack of those that also incorporate non-numeric, generic indicators that better address qualitative problems. Combined with the discussion of different viewpoints to PMS properties as well as the demand for better transparency and comparability of business processes, the necessity of deployment for a refined PMS using additional indirect indicators is derived. It would be able to assess hidden performance problems and hence to reveal additional business process improvement possibilities.
519	Many business processes cannot be easily measured due to their non-deterministic or qualitative nature. So, to fit in common performance measurement systems (PMS), artificial and simplifying measures are used that are complicated and costly to create and evaluate. Using a literature review, this paper documents the dominance of PMS that rely on KPIs and a lack of those that also incorporate non-numeric, generic indicators that better address qualitative problems. Considering the need for better transparency and comparability of business processes as well as visibility of process performance, the final necessity of deployment for a refined PMS using additional indirect indicators is derived. It would be able to assess hidden performance problems and to reveal additional improvement possibilities. © 2011 IEEE.
520	Performance measurement systems (PMS) are necessary to ensure adequate information supply to management, but an information gap exists between process analysis and execution. PMS predominantly rely on countable, objective measures, but are also designed to deliver additional viewpoints to foster necessary explanations to measurements. Still, there is no definition of how well these approaches work in delivering sufficient explanatory information. The introduced concept of visibility of performance explains how the explication of process performance information leads to additional interpretation possibilities in performance measurement to deliver embedded and rich knowledge. It is tested on a business case, in which additional subjective information could be explicated through the application of a suitable Performance Assessment Model. The result of the explication of this knowledge is an enhanced comprehension of performance that bridges the information gap between operative and strategic level. Copyright © 2012, IGI Global.
521	Almost all of today's performance measurement systems (PMS) rely on the usage of numeric indicators to quantify success or failure, normally referred to as key performance indicators (KPIs). This restriction makes it difficult to describe hard-measurable or business processes that are rather qualitative in nature. So, other existing models for process analysis containing convenient solutions and indicators have to be assessed and validated in order to offer them to stakeholders to thoroughly assess business processes. In this article, various existing models and frameworks for performance measurement were reviewed in an empirical investigation, categorized in systems and put into context to relevant theories. The result of the research is an overview of models for business process analysis that also incorporates indirect process performance aspects like soft goals, complexity, maturity or dependencies.
522	Performance measurement of business processes is necessary to ensure adequate information supply to the management. Though, the assessment of rather qualitative or non-deterministic processes is hard, because common analyzing and controlling approaches are restricted to the use of numeric indicators. Important qualitative performance aspects remain invisible. To bridge this gap, we introduce the concept of visibility which defines appropriate information supply in the domain of process performance. Derived from these requirements, we also present a multi-dimensional performance assessment system that combines numeric and verbal indicators. In two cases, we prove its applicability and positive contribution to performance visibility.
523	Performance measurement is a knowledge intensive business process and performance measurement systems (PMS) are appropriate tools to collect relevant performance information. Though, the application of many PMS fails. Therefore, there is a vivid debate in the literature about the right design, implementation, and use of PMS. Other contributions describe specific obstacles in different contexts, but there is no thorough investigation of the underlying patterns, especially in the context of information supply. This paper delivers a literature review aiming at explicating the reasons for failure in order to identify patterns and implications for PMS improvement. The findings suggest that involved people have difficulties with the PMS and there the problem is not in PMS itself. They emphasize the need to improve the knowledge related side of performance. In particular, a lack of understanding of PMS results and purpose demands better information supply and quality to foster their personal and organizational adaption.
524	The importance of actively managing and analysing business processes is acknowledged more than ever in organisations nowadays. Business processes form an essential part of an organisation and their application areas are manifold. Most organisations keep records of various activities that have been carried out for auditing purposes, but they are rarely used for analysis purposes. This paper describes the design and implementation of a process analysis tool that replays, analyses and visualises a variety of performance metrics using a process definition and its corresponding execution logs. The replayer uses a YAWL process model example to demonstrate its capacity to support advanced language constructs. © 2010 Piessens, Wynn, Adams, van Dongen.
525	In most business processes, several activities need to be executed by human resources and cannot be fully automated. To evaluate resource performance and identify best practices as well as opportunities for improvement, managers need objective information about resource behaviors. Companies often use information systems to support their processes, and these systems record information about process execution in event logs. We present a framework for analyzing and evaluating resource behavior through mining such event logs. The framework provides (1) a method for extracting descriptive information about resource skills, utilization, preferences, productivity, and collaboration patterns; (2) a method for analyzing relationships between different resource behaviors and outcomes; and (3) a method for evaluating the overall resource productivity, tracking its changes over time, and comparing it to the productivity of other resources. To demonstrate the applicability of our framework, we apply it to analyze employee behavior in an Australian company and evaluate its usefulness by a survey among industry managers.
526	Technology and Information are vital to the success of companies. To leverage the successes in IT projects, companies have at their disposal, references globally accepted as good practices (COBIT, ITIL, PMBOK, ISO, TOGAF, etc.). In spite of this, it is still great the magnitude of spending on IT projects poorly designed or improperly implemented. This paper presents a brief description of standards and good practices related to governance and management of enterprise IT, defines the Lean Thinking, Lean IT, the Processes Management, the Portfolio, Program and Project Management, and the Work System Theory, and highlights the purpose of them, showing their characteristics and suggests a Framework of Lean Governance and Management of Enterprise IT, by demonstrating how the standards and good practices presented can work together, because it advocates that the Lean Thinking, the Process, Portfolio, Program, and Project Management, and the Work System Theory complement the standards and good practices of Governance and Management of Enterprise IT with an approach not referenced in these standards and good practices.
527	This survey documents representation approaches for classification across different modalities, from purely content-based methods to techniques utilizing external sources of structured knowledge. We present studies related to three paradigms used for representation, namely (a) low-level template-matching methods, (b) aggregation-based approaches, and (c) deep representation learning systems. We then describe existing resources of structure knowledge and elaborate on the need for enriching representations with such information. Approaches that utilize knowledge resources are presented next, organized with respect to how external information is exploited, i.e., (a) input enrichment and modification, (b) knowledge-based refinement and (c) end-to-end knowledge-aware systems. We subsequently provide a high-level discussion to summarize and compare strengths/weaknesses of the representation/enrichment paradigms proposed, and conclude the survey with an overview of relevant research findings and possible directions for future work.
528	Business Intelligence (BI) techniques and workflow has changed significantly in the last few years. Due to the introduction of SAP HANA and other similar tools, real-time BI in support of business decision making is now possible. To develop student skill in real-time BI, and to allow them opportunity to see how BI techniques have evolved over the years, a semester-long BI-focused lab sequence has been employed alongside an ERP-based simulation game. The lab sequence allows computing students to see how their future work can support an organization's strategic planning and execution.
529	Our research paper aims to present the subject concerning theoretical contributions regarding performance and the way to achieve excellence in a business organization. As research economists we strongly believe that the future of any type of society stands in its on-going power to generate performance and better anticipate the need of correct and reliable knowledge, in order to achieve excellence. Moreover, the "art" of generating excellence in a business organization means to generate useful value done through the process called generically the business process management. Business process management is a reliable source that can truly ensure competitiveness at an organization's level and generate performance and excellence. Our study starts with an introduction in which we emphasized the place of both performance and excellence in a business organization and which are the main triggers that generate performance and excellence; we continued with a literature review in which we have presented the opinions that academics, researchers and specialists regarding performance and excellence in a business organization; we presented the perspectives for a society in continuous development: from "performance" to "excellence", performance indicators, as drivers of nowadays society, the way to getting from the "quality control" to the "total quality management" and the one to getting from the "total quality management" to the "managerial excellence", as well as the evolution of quality standards: ISO 9000 family.
530	Paper deals with the practical application of modern costing methods in terms of organizations providing health services to optimize their costs. Within the research the specifics of cost management in health organizations will be explored. The implementation of modern costing methods in selected health organizations will be carried out and based on this a methodology will be elaborated for their application and practical use, which will be of great importance for given organizations in optimizing costs. After introduction Activity based costing we can approach to identification of the fundamental elements of process management in a health organization with links to process performance measurement.
531	Identifying, modelling and documenting business processes usually require the collaboration of many stakeholders that may be spread across companies in inter-organizational settings. While modern process modelling technologies are starting to provide a number of features to support remote collaboration, they lack support for visual cues that are present in co-located collaboration. In this paper, we examine the importance of visual cues for collaboration tasks in collaborative process modelling from distributed remote locations. Based on this analysis, we present a prototype 3D virtual world process modelling tool that supports a number of visual cues to facilitate remote collaborative process model creation and validation. We report on a preliminary analysis of the technology and also describe the future direction of our research with regards to the theoretical contributions expected from the evaluation of the tool.
532	A growing number of business process management systems is under development both in academia and in practice. These systems typically are based on modern system engineering principles, such as service-oriented architecture. At the same time, the advent of big data analytics has changed the scope of these systems, including functionality such as data mining. However, existing reference architectures for business process management systems date back 20 years and, consequently, are not up-to-date with these modern developments. To fill the gap, this article proposes an up-to-date reference architecture, called BPMS-RA, for modern business process management systems. BPMS-RA is based on analysis of recent literature and of existing commercial implementations. This reference architecture aims to provide a guideline template for the development of modern-day business process management systems by specifying functions and interfaces that need to be provided by these systems as well as a set of quality criteria that they need to meet.
533	A number of recent initiatives in both academia and industry have sought to achieve improvements in e-businesses through the utilization of Business Process Management (BPM) methodologies and tools. However there are still some inadequacies that need to be addressed when it comes to achieving alignment between business goals and business processes. The User Requirements Notation (URN), recently standardized by ITU-T, has some unique features and capabilities beyond what is available in other notations that can help address alignment issues. In this paper, a URN-based framework and its supporting toolset are introduced which provide business process monitoring and performance management capabilities integrated across the BPM lifecycle. The framework extends the URN notation with Key Performance Indicators (KPIs) and other concepts to measure and align processes and goals. An example process for controlling access to a healthcare data warehouse is used to illustrate and evaluate the framework. Early results indicate the feasibility of the approach. © 2009 Springer Science+Business Media, LLC.
534	Decision making is a crucial yet challenging task in enterprise management. In many organizations, decisions are still made based on experience and intuition rather than on facts and rigorous approaches, often because of lack of data, unknown relationships between data and goals, conflicting goals, and poorly understood risks. This paper presents a goal-oriented, iterative conceptual framework for decision making that allows enterprises to begin development of their decision model with limited data, discover required data to build their model, capture stakeholders goals, and model risks and their impact. Such models enable the aggregation of Key Performance Indicators and their integration to goal models that display good cognitive fit. Managers can monitor the impact of decisions on organization goals and improve decision models. The approach is illustrated through a retail business real-life example. © 2011 Springer-Verlag Berlin Heidelberg.
535	A number of recent initiatives in both academia and industry have sought to achieve improvements in e- businesses through the utilization of Business Process Management (BPM) methodologies and tools. However there are still some inadequacies that need to be addressed when it comes to achieving alignment between business goals and business processes. The User Requirements Notation (URN) has some unique features and capabilities beyond what is available in other notations that can help address alignment issues. In this paper, a URN-based framework and its supporting toolset are introduced which provide business process monitoring and performance management capabilities integrated across the BPM lifecycle. The framework extends the URN notation with Key Performance Indicators (KPI) and other concepts to measure, and align processes and goals. A healthcare case study is used to illustrate and evaluate the framework. Early results indicate the feasibility of the approach.
536	Business Process Management (BPM) is perceived as the spanning discipline that largely integrates and completes what previous disciplines have achieved (Brocke and Rosemann, 2014). As such, its integrating activities focused on to discover, model, analyse, measure, improve, optimize, and automate business processes (Weske, 2012). All of these enables implementing performance measurements within the organization, which in effect can lead to decision making based on data rather than people's opinion. © 2022 The Authors. Published by Elsevier B.V.
537	nan
538	The food industry represented 2019 3.2% of the Gross Domestic Product (GDP) in Peru, in addition to presenting high employability being that the sector contained 7.4% of the Economically Active Population (EAP) [1]. However, due to the world crisis caused by COVID 19, this sector has been harmed in the year 2020 because the GDP of the accommodation and restaurants sector decreased by 50.2% compared to the previous year [2]. For that reason, strengthening this industry is considered crucial. One of the most critical links in the management of the supply chain of material, this problem results in the late delivery of orders to their customers, which would generate significant monetary losses and a bad reputation. In this sense, the present research proposes an integral improvement model based on the combination of tools such as the 5S ordering of raw material under a multi-criteria ABC approach, FEFO, MRP, Forecasting, and BPM, whose objective is to reduce the lead time. The model was validated through a simulation in Arena 16.1, where a reduction in delivery time and the frequency of extra purchases in 7.2% y 50%.
539	The heavy freight transportation sector has been positioning itself stronger in the sector as a result of the increase in imports and exports in Peru, which has generated a 5.6% increase in its GDP. According to the above, it is essential to identify the stages of the processes, maintenance plan, availability of trucks, as well as the quality of freight transportation. A fundamental part of these considerations is the maintenance management and the restructuring of the stages of the service process, the model proposed by this research is the use of tools such as VSM, BPM, and TPM, whose main objective is to reduce the current rate of orders delivered out of time of 4.78 %, generated by a poor organization of the administrative and logistics area. After the implementation through a pilot plan within the company, a reduction of 0.72% was obtained.
540	Seamless workflows among and within functional groups, and the resulting quality of inputs used for decision making, are common areas of concern-in the oil and gas industry today. Sales of information management applications and methodologies are based on this definition of quality, which refers to the usefulness and direct availability when needed of known or high-quality information. The reality, however, is that increasing pressure to reduce costs, the volume and dynamic nature of E&P workflows, and the difficulty in measuring return on investment in addressing data quality have led to the existence of "siloed" workflows, databases of substandard quality, and resulting decision-making inefficiencies. These inefficiencies are frequently accepted as the nature of the job, both because of the difficulty in measuring their impact, and the challenge of effectively measuring the return on investment that would result from improvements. One solution to this situation is to apply technologies and methodologies that have been proven in other industries. This can help determine key performance indicators - from operational to executive levels - to enhance workflow and data quality, and can also facilitate fast cleanup and the trending of improvements and their impact on the bottom line and user perception. Modular technology also facilitates phased rollouts to minimize investment before value can be determined. Business Process Management and Six Sigma methodologies, proven in other industries, can help control cross-functional processes and the systematic reduction of defects to acceptable levels, opening the door to the establishment of industry-relevant quality benchmarks that can ultimately impact investor confidence in the oil and gas sector and within individual organizations. Copyright 2008, Society of Petroleum Engineers.
541	Service delivery processes and service consumption processes are partially and sometimes completely overlapped. This means that there is no room for quality control and prevention of other forms of poor quality output. This is why modern service quality management should be based on controlling the process of providing such services. The purpose of this paper is to propose a framework for managing service quality by tracking performance indicators of processes responsible for rendering observed services. The paper describes a case study of the managing service quality by managing processes in National Employment Agency in Serbia (NEA) and significant improvements of service quality were achieved through the application of proposed framework. This paper helps clarify how the quality of services can be managed in the process of their provision.
542	Abstract Small and medium-sized businesses (SMEs) typically steer clear of implementing business intelligence (BI) systems because they feel that this sort of modeling is complicated and costly. But the market for business intelligence (BI) has evolved quickly. New opportunities like cloud computing have greatly lowered prices and eventually made it possible to design integrated solutions that are only intended for SMEs. In addition to highlighting the research trends in the sector under investigation, this paper explores the function of business intelligence in enhancing the decision-making process and competitive advantage of SMEs. The research subject has been approached using bibliometric analysis using the R package. The display of the results was done with the aid of Biblioshiny and VOSviewer's bibliometric tools. The study highlighted that SMEs have started integrating Business Intelligence systems. However, a new business model that will combine business analytics and will ensure to SMEs that emerging technologies will not affect them negatively is crucial. Thus, this research proposes the development of a new business model that will be based on Business Intelligence and Technology–organization–environment framework (TOE) framework, which helps SMEs to feel safe with emerging technologies.
543	An organization achieves competitive advantage by right strategic positioning and operational effectiveness. For the organization, the cost of its products and services is influenced by the effectiveness of the business processes that drive the organization. Effectively managing those processes, in the context of key performance measures, can reduce the cost and thereby ensuring organizational effectiveness. In this paper, we introduce a framework to identify the most effective actions that help translate strategy to organizational effectiveness.
544	Learning outcomes: Students should be able to: identify the elements of business processes; analyze efficiency measures; identify and define causes of poor efficiency in business process; analyze the results of a simulation model; propose process redesign alternatives based on the analysis; and acknowledge the challenges for improving public service processes. Case overview/synopsis: The process to get a passport seems to be very simple, but Jose Hernandez, a Manufacturing Plant Director, has had bad experiences the past three times he has visited the passport office. He and his family have spent more than 3 h to get the passport for his little daughter, Maria. In this case, the authors illustrate the process analysis performed by Jose to find effective and efficient solutions to the problems that he found. The case study guides students through the analysis of a business process in public service from the perspective of the users. The students participating in the case analysis will not only learn to diagnose and describe the process but also to redesign it to achieve significant improvements. Furthermore, the students will realize that adding more resources to the process may not solve the fundamental issues, but analytical and creative skills are needed. In addition, the teaching notes provide a discussion about the existing challenges to improve public service processes. Complexity academic level: Management and engineering undergraduate programs, operations management and business process design in Master of Business Administration programs. Supplementary materials: Teaching Notes are available for educators only. Subject code: CSS 9: Operations and Logistics. © 2020, Emerald Publishing Limited.
545	nan
546	Typical player management processes focus on managing an athlete's physical, physiological, psychological, technical and tactical preparation and performance. Current literature illustrates limited attempts to optimize such processes in sports. Therefore, this study aimed to analyze the application of Business Process Management (BPM) in healthcare (a service industry resembling sports) and formulate a model to optimize data driven player management processes in professional sports. A systematic review, adhering to PRISMA framework was conducted on articles extracted from seven databases, focused on using BPM to digitally optimize patient related healthcare processes. Literature reviews by authors was the main mode of healthcare process identification for BPM interventions. Interviews with process owners followed by process modelling were common modes of process discovery. Stakeholder and value-based analysis highlighted potential optimization areas. In most articles, details on process redesign strategies were not explicitly provided. New digital system developments and implementation of Business Process Management Systems were common. Optimized processes were evaluated using usability assessments and pre-post statistical analysis of key process performance indicators. However, the scientific rigor of most experiments designed for such latter evaluations were suboptimal. From the findings, a stepwise approach to optimize data driven player management processes in professional sports has been proposed.  © 2021 J. Ranaweera et al., published by Sciendo.
547	Organizations become dependent on Information Technology (IT) to fulfill their corporate aims, meet their business needs and deliver value to customers. For effective and efficient utilization of IT, we intend to contribute to the alignment between IT and organizational strategies. The challenge is to make the enterprise and its Information System (IS) as responsive as possible within the regard to changes in enterprise while taking into account the enterprise operational performance. When a change happens or a new opportunity comes, organizations do not know which assets are linked to which business processes and which services, especially IT services, to bring up first and which can wait until later. Our principal aim is to propose an indicator framework to track and control business-IT alignment. However, this paper is a preliminary study on this framework. We are inspired by COBIT 5 processes as indicators and believe that the Service-Oriented Architecture (SOA) applied to these processes interlinks and can interact well the different processes. The validity and applicability of our theoretical study will be evaluated for future work.
548	The abundance of free technology tools that can be used to communicate of today's businesses are in way creating more confusion and redundant tasks which is not good for a striving small business. The study aims to serve as a single platform of communication tool for a small accounting firm, a website and mobile application were developed which are the capable of providing an online ticketing which can respond to customer concerns, a service tracking, and a tool that can aggregate reports of the firm's performance in providing services in the form of charts. Web Development Life Cycle (WDLC) was used as the process model in the development of the website and mobile application. Interview validated the business processes and supported the design of web and mobile applications. Development tools used for website and mobile application are Cascading Style Sheets (CSS), Hypertext Preprocessor (PHP), Android and MySQL for database. In order to evaluate the performance of the developed system, a usability evaluation was conducted with the customers and employees of the accounting firm using the criteria: communication, transaction, aesthetics, ease of use, information and maintainability. Evaluation result shows that majority of customers strongly agree on the efficiency of communication and transaction functionalities of the developed system with the need in the improvement of image and text. Meanwhile, the evaluation of website's back-end shows promising result as well with mostly strongly agreement except for the transaction criterion wherein the employees who used the developed system had difficulty in using the system. Overall, the visual components, management of tickets, management of service tracking and viewing of the aggregate reports in the form of charts are all beneficial to a small business so that they could focus on their core business and use the developed website and application in customer engagement.
549	nan
550	nan
551	Supply chain managers today face an unremitting challenge to their capabilities in both the volume and complexity of factors to be reconciled. In order to achieve more effective decision making, it is very necessary to link strategic objectives to operational actions. However, little is available to guide managers in translating a set of objectives into operations so far. This paper presents a comprehensive methodology to address this gap. In this methodology, strategic objectives are translated into performance metrics by qualitative strategy map and metric network firstly, and then quantitative techniques such as system dynamics simulation and optimization are adopted to take managers through the stages of strategy mapping, action evaluation and decision making. A case study, supported by a software tool, is carried out throughout the paper to illustrate how the method works.
552	During the last several decades Key Performance Indicators (KPIs) became the standard approach to the monitoring and management of the enterprise performance. At the same time, Business Process Management (BPM) brought the revolutionary alternative to the traditional way of the management of an enterprise. As BPM dramatically changes the managerial perspective and consequently the view of the enterprise performance this perspective should also significantly change the approach to KPIs. Instead of establishing the KPIs for the particular places of the organization they should be derived from its business processes. In this paper we introduce the idea of deriving KPIs from the business process definitions based on our methodology MMABP in order to contribute to the theory of Key Performance Indicators as well as their practical application. © 2019, Springer Nature Switzerland AG.
553	The definition of process-related key performance indicators (KPIs) is a key part of performance measurement and one of the most challenging because of the lack of one best way to define business-applicable KPIs that are both aligned with the strategic goals that the organisation wants to achieve and, at the same time, measurable and as objective as possible. In this demo, we present KPIshare, which is a web platform whose main goal is to provide the BPM community with a knowledge base of well-defined, mature KPIs and a place where they can discuss, collaborate and create process-related KPIs that are applicable in real business situations. To this end, KPIshare introduces a detailed structure for KPI definition and the concept of operational KPI challenge as a mechanism to foster the collaboration in the platform. Copyright © 2014 for this paper by its authors. Copying permitted for private and academic purposes.
554	Abstract Process models are important for supporting organizations in documenting, understanding and monitoring their business. When these process models become outdated, they need to be revised to accurately describe the new status quo of the processes in the organization. Process model repair techniques help at automatically revising the existing model from behavior traced in event logs. So far, such techniques have focused on identifying which parts of the model to change and how to change them, but they do not use knowledge from practitioners to inform the revision. As a consequence, fragments of the model may change in a way that defies existing regulations or represents outdated information that was wrongly considered from the event log. This paper uses concepts from theory revision to provide formal foundations for process model repair that exploits domain knowledge. Specifically, it conceptualizes (1) what are unchangeable fragments in the model and (2) the role that various traces in the event log should play when it comes to model repair. A scenario of use is presented that demonstrates the benefits of this conceptualization. The current state of existing process model repair techniques is compared against the proposed concepts. The results show that only two existing techniques partially consider the concepts presented in this paper for model repair.
555	The purpose of this article is to investigate the impact of blockchain on global supply chain operational and managerial processes. This article reviews and classifies the existing empirical evidence of blockchain applications in the global suppbly chain. We utilize the Mooney et al. framework to organize this evidence into operational and managerial business value processes and the effects—automational, informational, and transformational. Our findings indicate that blockchain is not following the Mooney et al. stage model proposed in 1996 since the empirical evidence is evenly spread between the three effect categories. In addition, we have identified possible reasons why blockchain is not following the Mooney et al. stage model. Our study concludes with nine propositions as a guide on how to facilitate blockchain deployment and future research. Limitations of this article concerning blockchain are the lack of consistency and understanding of standards and the lack of information on blockchain implementation, which is referred to as the “grey space.” Blockchain today is where radio-frequency identification (RFID) was in 2002 and the bar code was in 1980. Therefore, future research work could be expanded to investigate case studies of blockchain implementations as they become available across the global supply chain. For practitioners, the empirical evidence presented in this article can help identify applications and implementation steps for building the business case where blockchain can have a greater impact on the organization. This article fills a void in the literature by providing practitioners and academics with a better understanding of blockchain and its applications for implementation.
556	Abstract Collaborative networks require inter-organizational business process governance (IO-BPG) mechanisms to define ownership over shared resources and activities, accountability over operations, inter-organizational roles and responsibilities, and strategic partner alignment. We developed an IO-BPG modeling approach aiming to incorporate (1) IT governance activities (e.g., IT performance measurement), (2) data governance activities (e.g., data strategy management), and (3) “shadow” parallel governance-related operations. Resulting from a design science research project, our contributions include the building blocks (domain attributes, ontology, and requirements) of a novel BPMN extension, its demonstration in logistics operations, its evaluation, and design principles to guide IO-BPG modeling. Suggestions for the development and evaluation of future BPMN extensions are also highlighted based on the lessons learned in this project. For practitioners, our contribution can improve accountability reports over data assets and operations, identify dataset ownership, assist in the coordination of governance activities in networked businesses, and comply with regulations and strategic partnership agreements.
557	This paper presents the case study of BT Italy, which has implemented a performance dashboard to monitor business processes to deliver customer services. Top Management had a punctual view of the business processes, performance, such as Order Acquisition, Order delivery. Nevertheless, it wanted to enhance the end-to-end view to take actions improving the customer experience and reducing the lead time. The project objective has been to build a model to monitor the performance of customer services business processes, such as from customer's service request to service delivery and bill. Higo has been the main framework to define and select key performance indicators. The first part of the paper presents the BT scenario, the second part describes the performance monitoring model and the performance dashboard. The last paragraph presents the expected benefits and the conclusion of the case study. © 2008 Springer Science+Business Media, LLC.
558	Multidimensional modeling requires specialized design techniques. Though a lot has been written about how a data warehouse should be designed, there is no consensus on a design method yet. This paper follows from a wide discussion that took place in Dagstuhl, during the Perspectives Workshop "Data Warehousing at the Crossroads", and is aimed at outlining some open issues in modeling and design of data warehouses. More precisely, issues regarding conceptual models, logical models, methods for design, interoperability, and design for new architectures and applications are considered.
559	nan
560	This paper develops a functional analysis of the aircraft flow through the airport operational framework, focusing on the airspace-airside integrated system. In this analysis, we use a dynamic spatial boundary associated with the Extended Terminal Maneuvering Area (E-TMA) concept, so inbound and outbound timestamps can be considered. Aircraft operations are characterized by several temporal milestones, which arise from the combination of a Business Process Model (BPM) for the aircraft flow and the Airport Collaborative Decision Making (A-CDM) methodology. This timestamp approach allows us to study the successive hierarchical tasks. The objective is to establish a taxonomy that classifies the system's capacity to “receive and transmit” aircraft streams with adherence to the expected schedule. By considering the accumulated delay across the different processes and its evolution, several indicators are proposed to evaluate the system's level of saturation and its ability to ensure an appropriate aircraft flow in terms of time-efficiency. Finally, the relationships between the factors that influence the aircraft flow are evaluated to create a probabilistic graphical model, using a Bayesian Network (BN) approach. This model predicts outbound delays given the probability of having different values at the causal control variables. The methodology is developed and validated through a case study at Adolfo Suárez Madrid-Barajas Airport (LEMD): a collection of nearly 34,000 turnaround operations (registered at the peak traffic months of 2016) is used to statistically determine the aircraft path characteristics. The contribution of the paper is twofold: it presents a novel methodological approach to evaluate and predict the system's state at the rotation stage and it also provides insights on the interdependencies between factors influencing performance. © 2018 Elsevier Ltd
561	nan
562	nan
563	nan
564	nan
565	Multi-tenancy is a cloud computing phenomenon. Multiple instances of an application occupy and share resources from a large pool, allowing different users to have their own version of the same application running and coexisting on the same hardware but in isolated virtual spaces. In this position paper we survey the current landscape of multi-tenancy, laying out the challenges and complexity of software engineering where multi-tenancy issues are involved. Multi-tenancy allows cloud service providers to better utilise computing resources, supporting the development of more flexible services to customers based on economy of scale, reducing overheads and infrastructural costs. Nevertheless, there are major challenges in migration from single tenant applications to multi-tenancy. These have not been fully explored in research or practice to date. In particular, the reengineering effort of multi-tenancy in Software-as-a-Service cloud applications requires many complex and important aspects that should be taken into consideration, such as security, scalability, scheduling, data isolation, etc. Our study emphasizes scheduling policies and cloud provisioning and deployment with regards to multi-tenancy issues. We employ CloudSim and MapReduce in our experiments to simulate and analyse multi-tenancy models, scenarios, performance, scalability, scheduling and reliability on cloud platforms.
566	Process owners are vital to the establishment and functioning of process oriented organisations. However there is a paucity of understanding regarding the tasks process owners should undertake and what competencies they require. Sets of process owner competencies and process owner tasks emerged from interviews with executives from three financial services organisations in South Africa. The first set highlighted business process management, interpersonal, and holistic thinking competencies while from a tasks perspective process measuring, customer experience, staffing, and process improvement were highly ranked. Nonetheless process orientation was found to be more aspirational than applied which was ascribed in part to a lack of business process education.
567	This study examines the development and use of multiple scorecard metrics within each stage of the perioperative process as key performance indicators to enable business process management practices across the entire process to target and measure continuous improvement. This paper identifies how dynamic technological activities of analysis, evaluation, and synthesis applied to internal and external organizational data can highlight complex relationships within integrated hospital processes to target opportunities for improvement and ultimately yield improved process capabilities. The identification of existing limitations, potential capabilities, and the subsequent contextual understanding are contributing factors that yield measured improvement. This case study investigates the impact of integrated information systems to identify, qualify, and quantify perioperative improvement based on a 154-month longitudinal study of a large, 1.046 registered-bed teaching hospital. The theoretical and practical implications and/or limitations of this study's results are also discussed with respect to practitioners and researchers alike. © 2017 Proceedings of the Annual Hawaii International Conference on System Sciences. All rights reserved.
568	This study examines the development and use of balanced scorecard metrics as key performance indicators within each stage of the perioperative process to enable business process management across the entire process to gauge performance and target improvement opportunities. The identification of existing limitations, potential capabilities, and the subsequent contextual understanding are contributing factors toward perioperative improvement. This paper identifies how dynamic technological activities of analysis, evaluation, and synthesis applied to internal and external organizational data can highlight complex relationships within integrated hospital processes to address root causes rather than symptoms and ultimately yield improved capabilities. This case study investigates how integrated information systems can identify, qualify, and quantify perioperative performance indicators to measure improvement based on a 157-month longitudinal study of a large, 1,157 registered-bed teaching hospital. The theoretical and practical implications and/or limitations of this study's results are also discussed with respect to practitioners and researchers alike. Copyright © 2017, IGI Global.
569	Business process management (BPM) literature suggests that more than 60% of quality improvement projects fail due to factors associated with the lack of predictive quality performance control and the failure of continuously searching for quality anomalies in quality performance over time. Quality anomalies are indications of extreme performance deviation from quality expectations and requirements. The findings suggest that quality performance control in BPM is the scientific method for producing quality anomaly knowledge and signalling opportunities for informed, systematic, and continuous performance improvement. A predictive framework is proposed based on the findings. © 2018 The Authors. Published by Elsevier Ltd..
570	Abstract Background Policy Deployment and Daily Management are two critical vehicles of Total Quality Management implementation in a company. Integration of these two vehicles has been discussed and adequately addressed in a few companies that have been practicing Total Quality Management for a long time. However, most companies often face challenges and difficulties in ensuring smooth and seamless transfer of Policy Deployment plans into Daily Management activities. Case description The challenge is even bigger in service sector which embarked on the Total Quality Management journey barely 5–6 years ago. The service sector has traditionally used Balanced Scorecard which has relatively weaker emphasis on the means to achieve the targets. The authors of this report have found a customized and unique model whose success has been demonstrated through deployment in two customer-facing processes in a large life insurance company in India. The traditional approach used in manufacturing industry has been simplified and customized for the effective application in the service sector. Discussions & Evaluation The traditional approach used in manufacturing industry has been simplified and customised for the effective application in the service sector. A survey was done to identify the issues and the approach was modified and implemented in couple of key customer-facing processes. Conclusion The phenomenal results have led to a big ‘pull’ from other process owners to replicate this approach across all operational and support processes. Initial ‘reluctant participants’ of the process have now become the ‘champions’ and truly the ‘change catalysts’ for this approach. The process is now being replicated in several other processes across several Industrial sectors.
571	The recent move towards migrating business processes in the cloud often requires organisations to have some parts of their business processes execute on cloud-native systems and others on the organizations’ own infrastructure. In many scenarios, there could be multi-cloud configurations with parts of the process run by different cloud providers. Hence, current-day business process executions rely on complex software ecosystems with high levels of cross-dependencies, heterogeneity, and redundancies. This growing complexity amplifies the need to monitor and maintain business process executions near real time to ensure the key performance indicators are met. Instances of system failure require early detection and diagnosis of the problem demanding minimal time to understand its impact on the process execution. We propose the notion of business process observability where the intention is to leverage parameters amenable to external monitoring, to adequately represent the state of a business process. The objective of the proposed approach is to offer an end-to-end observability of business processes provisioned in distributed environments that allows for (1) detection, (2) diagnosis, and (3) actions to address business process execution failures. The paper proposes a solution approach that uses observability data to build a cross-layer topology linking a business process and its underlying software ecosystem and provide detailed diagnostics correlating the business process and software execution failures.
572	The performance of business processes such as order fulfillment, is measured and monitored in terms of Key Performance Indicators (KPIs) measured at periodic time intervals often hourly, daily, or weekly, depending on the business process. A business process is enabled by a set of IT software systems, infrastructure components, and external resources. Often, the impact of an anomalous event, such as a failure of an underlying IT system or poor weather conditions, on the business KPIs is unknown. Lack of knowledge as regards the impact of anomalous events leads to delays in handling these events. Providing a prior assessment of the impact can help prioritize the corrective actions and minimize further effect. In this work, we present a system that first uses periodic measurements of the business KPIs as a time series to correlate and identify the events impacting the KPIs, and forecasts the impact of anomalous events on the process performance. Our approach considers various types of process tasks that characterise a business process execution. We present experiments on synthetic and real-world datasets to validate the effectiveness of our approach in identifying and forecasting the impact of anomalous events on Business KPIs. We have deployed this functional component as a part of an IT Operations platform.
573	nan
574	In the educational field, Key Performance Indicators (KPIs) aim to provide an opportunity to evaluate the performance of employees, teachers’ skills and pedagogy, students’ results, learning objects, educational institutions, and teaching-learning methods. In this research work, we focus on studying the performance of reading teaching-learning methods, specifically whole-word and syllabic language learning methods. More precisely, we propose a Business Process Management (BPM) based approach for performance measurement of the corresponding business processes of both methods. We elaborated the reading teaching-learning business processes using the Business Process Model and Notation (BPMN), which is a widely adopted standard for formalizing business process modeling. We prepared a set of KPIs for the different activities and the whole process. We used these KPIs to gauge the performance of each business process and make comparisons between them. To validate our approach, we launched a dedicated questionnaire to primary school teachers in the third grade. By using this questionnaire, we were able to evaluate the overall performance of each reading process. Our findings indicate that the whole-word method is the most effective teaching method compared to the other.  © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
575	In the educational filed, Key Performance Indicators (KPIs) aim to provide an opportunity to evaluate the performance of em- ployees, teachers' skills and pedagogy, students' results, learning objects, educational institutions and teaching-learning methods. In this research work, we focus on studying the performance of reading teaching-learning methods, specifically whole-word and syllabic languages learning methods. More precisely, we propose a Business Process Management (BPM) based approach for per- formance measurement of the corresponding business processes of the both methods. We elaborated the reading teaching-learning business processes using Business Process Model and Notation (BPMN), which is a widely adopted standard for formalizing busi- ness process modeling. We prepared a set of KPI for the different activities and for the whole process. We used these KPIs to gauge the performance of each business process and make comparisons between them. To validate our approach, we launched a dedicated questionnaire to primary school teachers in the third grade. By using this questionnaire, we were able to evaluate the overall perfor- mance of each reading process. Our findings indicate that the whole-word method is the most effective teaching method compared to the other. © 2024 The Author(s).
576	Business process modelling languages do not usually represent non-functional requirements, focusing only on the functional ones. In order to fill this gap, the StrAli-BPM (strategic alignment with BPM) approach was presented. StrAli-BPM is divided in BLA@BPMN and BLA2SLA: the former extends BPMN to embody non-functional requirements through business level agreements (BLAs); the latter supports the creation of a set of service level agreements (SLAs) based on a particular BLA. This paper describes the results obtained with the evaluation of StrAli-BPM. The approach was evaluated by a proof of concept, based on prototype tools, which enabled us to verify its technical applicability. Moreover, a survey was conducted, in qualitative terms, with a panel of experts. As a result, StrAli-BPM was well accepted by the experts who judged it as important and necessary to completely cover the BPM lifecycle. Some lessons learned from both evaluations are presented. Copyright © 2018 Inderscience Enterprises Ltd.
577	Key analysts are emphasizing the importance of the digitalization especially of the supply chain. This work aims to improve maritime shipping companies by introducing digitalization in their operations. This objective is achieved analyzing the impact of maritime container shipping companies’ digitalization. This analysis requires as input the Business Process Model (BPMo) and an inventory of digital applications to verify how the BPMo changes when deploying the applications, define the prerequisites necessary for this deployment, and identify the key performance indicators (KPIs) to track it. The impact of the deployment of the applications has been quantified by using four performance dimensions: Costs, Time, Quality, and Flexibility. The results show that the impacts are different per application, with changes in the processes, the addition of new ones, and the decommissioning of others. The impact of digitalization is high when trying to deploy all the applications at the same time. Companies can leverage this work, which requires reviewing the documented impacts in their processes and the applications’ prerequisites as well as updating their existing balanced scorecard, incorporating the application’s KPIs. A list of 10 applications has been identified as “quick wins”; then, applications can be the starting point for digitalizing a company. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.
578	ADNOC has development and implemented a robust automated sector performance review (SPR) process using state-of-the-art analytics and business process management tool (Khan et al., 2019). In this paper, we will present the achieved results and the defined opportunities by implementing SPR across some targeted reservoirs during the previous last 2 years. With the necessity of having analysis at sector level, the main objective of this work is to conduct an integrated reservoir dynamic synthesis, identify all challenges and opportunities to come up with robust and practical action plan aiming for best reservoir management and ultimately obtain best oil recovery by sector. Applying Integrated Reservoir Management (IRM) Workflow on Giant Onshore Field, It was decided to start the project on one major Reservoir A (divided by 3 sectors) as a project pilot. First data were collected from operations database, data management in spreadsheets, simulation output format, maps and images. All data were organized into the automated SPR workflow through a web based Business Process Management (BPM) that provided mechanism for the user to load, validate and approve technical data. Setting the workflow to focusing on analyzing the reservoir performance at sector level, the data is illustrated in an integrated visualization environment including panels for the reservoir KPI, production plan compliance status and reservoir pressure maintenance, diagnostic plots, production and injection summary, etc., opening the possibility for the user to identify new opportunities and areas that needs further investigations. Few key enhancements are listed and were suggested to the solution as a next phase. Following a methodical SPR automated workflow these conclusion are drawn: • Technical data can be approved with appropriate notification for task execution. • Data processing cycles, visualization and performance analysis dashboard time frame was reduced. • It was identify the underperforming areas into the sectors. • The Opportunity Management proactive system was used to identify reservoir profitable opportunities through a centralized platform. • Action plans include well and surface intervention. 20% of the activities were successfully implemented and provided significant added values. Implementation of the automated SPR workflows as part of Digital technologies is renovating the traditional work process into very effective and advanced analytics and has achieved excellence in reservoir management and reserves recovery. Copyright © 2022, International Petroleum Technology Conference.
579	nan
580	Digital transformation is essential for improving the operational processes of organisations and, consequently, their performance. This work presents the prototype of a computer application to support the management of outgoing students’ applications in a higher education institution. The key outcomes of this work include the systematisation of the process, the establishment of key performance indicators, and the real-time monitoring and traceability of students’ applications. From a managerial perspective, this work provides insights for higher education institutions aiming to digitalise and control their processes. Moreover, it offers a practical framework that can be adapted by any industry seeking to implement controlled processes, enabling the collection of data from activities to feed the key performance indicators. Copyright © 2025 Inderscience Enterprises Ltd.
581	The need to store and analyze movement data is continuously growing as a consequence of the huge availability of data being collected through GPS receivers, mobile devices, sensors, and others technologies. This paper presents an approach for the storage and analysis of maritime transportation data in a spatial data warehouse. The aim is to identify near-miss situations, which are the contexts where collisions between ships may occur. Moreover, a key performance indicator is proposed to compute the target percentage of safe situations between ships. The proposed spatial data warehouse was modeled, implemented and loaded with the data collected by The Netherland Coastguard, and includes data of shipping movements collected by AIS (Automatic Identification System) base stations. Through the SOLAP analysis of this data set, and taking a sample safety distance of 50 meters between ships, it was possible to verify that the percentage of safe situations is of 92%, going beyond the defined target limit of 90%. The results are promising at the conceptual level and demonstrate the need for further development of key performance indicators for analyzing large movement data sets.
582	A Service-Based Application (SBA) is composed of a number of loosely coupled services available on the network which provide the desired functionalities. Service Based Applications execute in dynamic business environments and have to address evolving requirements. Hence they should be flexible to identify violations and adapt to changes in business requirements or context. Monitoring is the key element for adaptation. A Service Based Application can be viewed in terms of three layers i.e., Business Process Management Layer, Service Composition Layer and Service Infrastructure Layer. Application performance depends on the combined performance of components and their interactions within the SBA layers. Therefore it necessitates to constantly monitor the health of the application by monitoring activities occurring in SBA layers. In this paper we present a view of the monitoring approaches across the three layers.
583	Nowadays, business process management and process modeling is an important part of business management and business process improvement. Resulting from the increasingly fast growing customer requirements for the final product, organizations need to introduce process management. The work presented in this paper was situated in the area of the automotive industry, which is the most important sector of the world economy. Technical development is progressing with rapid fashion, and even in the automotive industry, there is a need to monitor, manage and improve production processes. This is related to the deployment and use of information systems that support and automate these processes. The main goal of the work described in the paper is to provide a brief overview of the field of business process management, process modeling, related technologies, and the situation of the automotive industry in general. This work also analyzes the current situation in one of the measurement centers, selected processes, and user requirements for the application supporting those processes. Based on the analysis, we proposed an improvement of the selected processes and also designed a web application that supports these processes. The application was built using current technologies such as ASP.NET Core Framework, MVC architecture and the available libraries. Results of testing proved that the solution meets all requirements and in terms of key performance indicators surpassed the expected results. It is suitable for real use in practice and in the future, it is recommended its deployment to all measurement centers. © 2018, Springer International Publishing AG.
584	Various life-cycle approaches to Business Process Manage- ment (BPM) have a common assumption that a process is incrementally improved in the redesign phase. While this assumption is hardly ques- tioned in BPM research, there is evidence from the field of AB testing that improvement concepts often do not lead to actual improvements. In this thesis, we propose a methodology named AB-BPM and a set of sup- porting techniques that facilitate rapid validation of business processes by conducting sequential experiments.We evaluate our methodology and techniques with real-world and synthetic case studies.  Copyright © 2020 for this paper by its authors.
585	A fundamental assumption of Business Process Management (BPM) is that redesign delivers new and improved versions of business processes. This assumption, however, does not necessarily hold, and required compensatory action may be delayed until a new round in the BPM life-cycle completes. Current approaches to process redesign face this problem in one way or another, which makes rapid process improvement a central research problem of BPM today. In this paper, we address this problem by integrating concepts from process execution with ideas from DevOps. More specifically, we develop a technique called AB-BPM that offers AB testing for process versions with immediate feedback at runtime. We implemented this technique in such a way that two versions (A and B) are operational in parallel and any new process instance is routed to one of them. The routing decision is made at runtime on the basis of the achieved results for the registered performance metrics of each version. AB-BPM provides for ultimate convergence towards the best performing version, no matter if it is the old or the new version. We demonstrate the efficacy of our technique by conducting an extensive evaluation based on both synthetic and real-life data. © Springer International Publishing AG 2017.
586	Business process improvement ideas can be validated through sequential experiment techniques like AB Testing. Such approaches have the inherent risk of exposing customers to an inferior process version, which is why the inferior version should be discarded as quickly as possible. In this paper, we propose a contextual multi-armed bandit algorithm that can observe the performance of process versions and dynamically adjust the routing policy so that the customers are directed to the version that can best serve them. Our algorithm learns the best routing policy in the presence of complications such as multiple process performance indicators, delays in indicator observation, incomplete or partial observations, and contextual factors. We also propose a pluggable architecture that supports such routing algorithms. We evaluate our approach with a case study. Furthermore, we demonstrate that our approach identifies the best routing policy given the process performance and that it scales horizontally. © Springer International Publishing AG, part of Springer Nature 2018.
587	A fundamental assumption of Business Process Management (BPM) is that redesign delivers refined and improved versions of business processes. This assumption, however, does not necessarily hold, and any required compensatory action may be delayed until a new round in the BPM life-cycle completes. Current approaches to process redesign face this problem in one way or another, which makes rapid process improvement a central research problem of BPM today. In this paper, we address this problem by integrating concepts from process execution with ideas from DevOps. More specifically, we develop a methodology called AB-BPM that offers process improvement validation in two phases: simulation and AB tests. Our simulation technique extracts decision probabilities and metrics from the event log of an existing process version and generates traces for the new process version based on this knowledge. The results of simulation guide us towards AB testing where two versions (A and B) are operational in parallel and any new process instance is routed to one of them. The routing decision is made at runtime on the basis of the achieved results for the registered performance metrics of each version. Our routing algorithm provides for ultimate convergence towards the best performing version, no matter if it is the old or the new version. We demonstrate the efficacy of our methodology and techniques by conducting an extensive evaluation based on both synthetic and real-life data. © 2018 Elsevier Ltd
588	Many geo-distributed services at web-scale companies still rely on databases (DBs) primarily optimized for single-site performance. At AT&amp;T this is exemplified by services in the network control plane that rely on third-party software that uses DBs like MariaDB and PostgreSQL, which do not provide strict serializability across sites without a significant performance impact. Moreover, it is often impractical for these services to re-purpose their code to use newer DBs optimized for geo-distribution. In this paper, a novel drop-in solution for DB clustering across sites called Metric is presented that can be used by services without changing a single line of code. Metric leverages the single-site performance of an existing service's DB and combines it with a cross-site clustering solution based on an entry-consistent redo log that is specifically tailored for geo-distribution. Detailed correctness arguments are presented and extensive evaluations with various benchmarks show that Metric outperforms other solutions for the access patterns in our production use-cases where service replicas access different tables on different sites. In particular, Metric achieves up to 56% less latency and 5.2x higher throughput than MariaDB and PostgreSQL clustering, and up to 90% less latency and 26x higher throughput than CockroachDB and TiDB, systems that are designed to support geo-distribution.
589	The business process management discipline is a vastly studied field with significant contributions to creating value for organizations, being structured around various activities. Among these activities, creating and modifying business processes are particularly difficult and resource-intensive tasks within organizations. Recently, a new artificial intelligence architecture model was introduced, generative pre-trained transformers, changing the way machines can process and understand digital content. The integration of generative artificial intelligence into virtually any field of study is occurring at a very fast pace, but applying it to the optimization of business processes is still ongoing research. We have identified a particular area of improvements. A lot of work has been done on the automation of activities of a process but not on the process itself. In this paper, we conducted a business use case, consisting of dynamically meta-optimizing a credit application process, based on performance indicators (e.g. profit), using a software prototype system. Several implications derive from the execution of this business use case. (1) A significant decrease in the time a process manager needs to spend on designing and redesigning the business process; (2) An increase in the speed of adoption of business processes, even for small and medium-size enterprises; (3) Integrating such a system into the organization provides an element of agility, making it ready to environmental changes and able to adapt. (4) Ultimately, organizations that successfully adopt this technology, could achieve autonomous adaptation to the environment, leading the way for the ultimate digital enterprise. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
590	Healthcare organizations are facing huge daily challenges which led them trying to give the best solutions in order to manage their resources and deliver a best quality of services. The recent adoption of Business Process Management (BPM) in healthcare organizations is dealing with the development of performance indicators in this domain to help healthcare providers structuring the interaction of information between systems and people. Moreover, there are a lot of available methods and tools for BPM that afford different manners to simulate models. Nevertheless in these process models, the resource handling is frequently missing or it is defined in a simplistic way. In this paper, we present the application of BPM in healthcare sector, using the Business Process Model and Notation (BPMN), coupled with a multi-dimensional Agent Based Model (ABM) of multidimensional organizational network of resources and geographical positioned population on a territory. ©2017 Society for Modeling & Simulation International (SCS).
591	Market players that can respond to critical market events faster than their competitors, will end up as winners in the emerging new economy. In order to win the next phase in the never-ending market race, they will also need to integrate their business processes with those of their suppliers and business partners. Additionally, the ability to quickly adjust processes to better respond to one's customers will also become a decisive factor in the new economy. In this paper, we discuss the deficiencies of formal existing process management approaches and propose an agile process management approach based on Sense and Respond loop.
592	Due to the distributed nature of Service-Oriented Architectures (SOA), maintaining control in a SOA environment becomes more difficult as services spread over different lines-of-business. The concept of SOA governance has emerged as a way to implement control mechanisms in a SOA. In this paper we identify a lifecycle based approach for executing SOA governance. This approach consists of defining a SOA strategy, aligning the organization, managing the service portfolio, controlling the service lifecycle, enforcing policies and managing service levels. By incorporating a maturity model in this approach, it is possible to minimize the required effort while still having sufficient governance. From a series of interviews that have been carried out we could conclude that most current SOA projects - although relatively limited in their scope - raise governance issues that need to be addressed to prevent future problems.
593	With access to critical performance indicators of business processes, executives, business managers and staff members can play a crucial role in improving the speed and effectiveness of an organization's business operations. The monitoring and analysis of business processes are complicated by the variety of organizational units and information systems involved in the execution of these processes. In this paper, we present a Process Information Factory as a solution for managing performance data of business processes. The purpose of the Process Information Factory is to provide a data foundation for a process-driven decision support system to monitor and improve business processes continuously.
594	The dynamic business environment of many organizations require to monitor their business, IT and organizational processes in real-time in order to proactively respond to exceptions and to take advantage of time-sensitive business opportunities. The ability to sense and interpret events about a changing business environment or customer needs require an event-driven IT infrastructure for making fast and well-informed decisions and putting them into action. In this paper we introduce sense & respond loops that support a complete business intelligence process to sense, interpret, predict, automate and respond to business processes and aim to decrease the time it takes to make the business decisions. Our approach enables real-time analytics across corporate business processes, notifies the business of actionable recommendations or automatically triggers business operations, effectively closing the gap between business intelligence systems and business processes. We propose a system for executing and managing sense & respond loops and illustrate our approach with a supply chain business scenario
595	Business Process Monitoring plays an important role in organizational development. It delivers management information and thus allows for better decision making in terms of process design, implementation and execution. This contribution first sheds some light on the importance and forms of business process monitoring. Then we look at current monitoring features of S-BPM software supporting the S-BPM approach and discuss development perspectives particularly in the field of Business Activity Monitoring (BAM). In this context we adapt an existing concept for modeling BAM specifications with reference to BPMN models for the use with S-BPM. © 2013 Springer-Verlag.
596	The competitive edge of using expert system technology is beginning to have an impact on the marketplace. Described here are applications of expert system technology to customer service and many of the ideas presented here are applicable to other areas of business as well. This project was accomplished in cooperation with the Customer Service Department of a major U.S. chemical company, and this paper describes the design, implementation, and results of a diagnostic expert system prototype and the design of an Expert Inquiry Handler for customer service. The prototype design was based on a previously successful design by the authors, and the Expert Inquiry Handler design addresses what it means to do intelligent inquiry handling in customer service and how an Expert Inquiry Handler interfaces with its resources (data base and people) to accomplish its job.
597	Process mining is the area of research that embraces the automated discovery, conformance checking and enhancement of process models. Declarative process mining approaches offer capabilities to automatically discover models of flexible processes from event logs. However, they often suffer from performance issues with real-life event logs, especially when constraints to be discovered go beyond a standard repertoire of templates. By leveraging relational database performance technology, a new approach based on SQL querying has been recently introduced, to improve performance though still keeping the nature of discovered constraints customisable. In this paper, we provide an in-depth analysis of configuration parameters that allow for a speed-up of the answering time and a decrease of storage space needed for query processing. Thereupon, we provide configuration recommendations for process mining with SQL on relational databases.
598	Considering that each IT-organization is based on an established IT-governance the introduction of SOA as a new overall architectural approach will change the requirements for the specific governance model. The paper presents a SOA-specific governance model which differentiates an operating model, service lifecycle management, service ownership, cost allocation, and meta-data management support. Based on the company´s maturity along the SOA-relevant dimensions IT-governance, SOA experience, and process maturity, its size, as well as its organizational structure the paper discusses an SOA operating model with organizational structure, roles, responsibilities, and KPI´s. The main assumption of the approach is the alignment of the organizational structure of IT with a functional domain model. This operating model is the outcome of ten industrial workshops and one complex case study based on standards as CobiT and ITIL.
599	Conceptual models organize the data as well as the processes from a business domain using a human-readable, yet formal representation language. For static data models, various modeling approaches have been proposed to represent complex multilevel abstraction hierarchies. For process models, though, current modeling approaches do not provide a flexible and powerful formalism for representing complex multilevel abstraction hierarchies. In this paper, we motivate the need for multilevel business process models, present our initial approach, and sketch future research in this area.
600	Accounting information systems fulfil the purpose of recording the business transactions over time according to the legal accounting requirements. Management information systems provide the information and mechanisms that are needed to manage the enterprise in different management domains. The primary research objective of this article is the specification of the relevant concepts underlying both information systems and their integration in a comprehensive framework. The resulting framework shows the economic and managerial requirements for integrated accounting-based management information systems and it can be used for a semantic design of such systems.For this purpose the probabilistic REA management ontology is developed by integrating the management concepts of the cybernetic management framework into the REA business ontology. Consequently the derived REA management ontology rests upon the well-established REA business ontology and it allows the semantic design and implementation of accounting-based management information systems.
601	After the initial phase of E-Government and the exaggerated expectations for the new internet-based technologies, a pragmatic state of mind has evolved during the last few years. Thereby, it is especially the evaluation of the related financial benefits that has become a crucial aspect. The paper presented outlines a process-driven approach for the analysis of technology-driven performance impacts based on performance indicators. From a German perspective, existing evaluation concepts were concretized for the case scenario of German Plan Approval Procedures.
602	nan
603	Creative processes, for instance, the development of visual effects or computer games, increasingly become part of the agenda of information systems researchers and practitioners. Such processes get their managerial challenges from the fact that they comprise both well-structured, transactional parts and creative parts. The latter can often not be precisely specified in terms of control flow, required resources, and outcome. The processes' high uncertainty sets boundaries for the application of traditional business process management concepts, such as process automation, process modeling, process performance measurement, and risk management. Organizations must thus exercise caution when it comes to managing creative processes and supporting these with information technology. This, in turn, requires a profound understanding of the concept of creativity in business processes. In response to this, the present article introduces a framework for conceptualizing creativity within business processes. The conceptual framework describes three types of uncertainty and constraints as well as the interrelationships among these. The study is grounded in the findings from three case studies that were conducted in the film and visual effects industry. Moreover, we provide initial evidence for the framework's validity beyond this narrow focus. The framework is intended to serve as a sensitizing device that can guide further information systems research on creativity-related phenomena. © 2010 by the authors.
604	nan
605	nan
606	nan
607	South African public hospitals are faced with many challenges comprising inefficient processes, lack of digitalisation, severe austerity measures, and the rising burden of disease. Irrespective of the many existing initiatives in place, a critical challenge is the shortage of necessary resources required to fund, implement, and sustain new interventions. This deprives public hospitals from the efficiencies and quality of service experienced in private hospitals or other business entities. Through a case study strategy, this paper has abstracted two practice contributions. First, it describes and prescribes a low-cost approach in which business process redesign was applied in a public hospital through a partnership between the hospital and a higher learning institution. The initiative involved third year students majoring in Information Systems performing, as part of their class project, process analysis at the hospital at no cost to the hospital other than their employees' time. The second contribution is a priority list of redesign and lean management principles that were abstracted from these initiatives. These include improving staff training, distributing and adhering to up-to-date standard operating procedures, performing tasks in parallel rather than in series, reducing handovers by avoiding certain tasks, incentivizing use of existing mobile software by doctors, developing low-cost task automation solutions such as Microsoft Office applications, redesigning and standardizing forms, capturing data at source electronically rather than later, redesigning physical spaces, and improved key performance indicators and reporting. The study confirms the usefulness of this collaborative business process redesign approach for public hospitals as stakeholders got relevant information and practical, low-cost, creative solutions with the potential to improve efficiencies and subsequently service delivery. © 2019 John Wiley & Sons Ltd
608	Execution of a process model produces data that can be used for analysis and optimization of business processes. For several years, data warehouse (DW) technology has been used for analysis and decision making. A data warehouse developed for business processes is called a process warehouse. The capabilities of a process warehouse are seldom evaluated, since a generic framework that can be used for the evaluation is missing. Therefore, in this paper, we develop a generic framework called Process Analysis Framework (PAF) that can be used for evaluating analysis capabilities of a process warehouse. Furthermore, the framework has been used to evaluate various process warehousing approaches, collected through a comprehensive survey.
609	In order to design a system for managing performance in collaborative project-based enterprises, it is necessary to undertake real-time monitoring of its business processes and activities. This paper presents a systematic approach to project business process monitoring (BPM) and identifies the key aspects of virtual enterprise (VE) process evaluation. A framework for VE BPM is presented with special emphasis in linking interest groups to the development of their targets, information and knowledge sharing. The proposed model defines the exclusive performance metrics, which are needed during BPM. This interdisciplinary study examines BPM through peer-to-peer information exchange in the VE domain, which is currently a research gap. The fundamental metrics to define business process performance monitoring are elaborated in the research reported in this paper. The identified performance metrics can be used to measure the overall performances for both a project business and VE. A reference architecture is also highlighted with a case example with the objective to measure the performance in a project business VE. An overall definition of collaborative BPM and performance management systems is also presented accordingly. Future research directions are identified regarding the nature of collaboration in a project business VE and the characteristics of performance indicators to support it. © 2017 Informa UK Limited, trading as Taylor & Francis Group.
610	This paper describes a Service-Oriented Computing Kit (SOCK), which is an overarching framework covering the key artifacts in planning, modeling, designing, developing, deploying, and managing service-oriented solutions in the enterprise computing space. Based on a divide-and-conquer strategy, this comprehensive kit is a systematic taxonomy to abstract complexities and organize the major aspects of service-oriented development, so that the roles, responsibilities, accountabilities, skillsets, procedures and deliverables can be clearly defined for the IT teams to effectively construct service-oriented systems. SOCK comprises eight modules - Architecture, Process, Integration, Environment, Technology, Development, Management, and Roadmap. Each module addresses specific technical concerns in particular areas. SOA provides the service definitions, service catalog, service composition, scope of applications and portfolios, and service architecture modeling methodology. SOP deals with the business process management, process modeling & notations, process orchestration, coordination/collaborations, human interactions, and 1-phase commit compensation for long-lived processes. SOI concentrates on the service interoperability, integration patterns, enterprise service bus, traditional synchronous/asynchronous enterprise application integration, and integration with portals and content management systems. SOE consists of the runtime infrastructure, service registry for discovery and directory, service transformation/routing gateway, service virtualization via grid computing, and quality-of-services compliance with service-level agreements. SOT covers the implementation technologies - web services, standards and specifications, technical patterns, convergence, and aspect-oriented techniques. SOD is composed of the development lifecycle, programming model, design/development tools, frameworks, reusable utilities/toolkits/components, and model-driven approaches. SOM includes services & policies repository in service identification and categorization, security mechanisms, business activity monitoring, reporting, BI, and provisioning. SOR handles the planning/blueprint, strategy, KPI dashboards, governance, and organization. The elements in each module are further decomposed to form loose semantic associations. This holistic kit has been implemented on an open source mind-mapping platform, which is used in guiding the migration from the conventional multi-tier web application style to a service-oriented paradigm in the financial services sector, and SOCK has proven to be an effective approach to pragmatically transitioning to the new computing mode. © 2006 IEEE.
611	nan
612	nan
613	Boeing has nearly completed a major program for business process redesign. Given the scale of this project and the large number of existing, heterogeneous systems, it has been essential that a standards-based architecture be implemented. The Common Object Request Broker Architecture (CORBA) standard has worked well as the application integration baseline for this new system
614	Business intelligence (BI) as a paradigm with methods and tools substantially improves decisions with regard to business evolutions. Through the emerging business process management approaches, it becomes possible to link BI-tools with the underlying process models. This paper explains how process models can be enriched with risk models in the context of business intelligence.
615	The article discusses the impact of the digital transformation of loyalty systems on the success rates of the telecommunications business. The specifics of the telecommunications industry are particularly high rates of customer churn, averaging from 10 to 67% per year. As a result, the cost of attracting a new client is 4-10 times more expensive than retaining an existing one. So digital transformation of customer loyalty systems becomes a tool for predicting customer behavior and delivering timely and relevant offers, improving the user experience. The purpose of the study is to propose the approach to managing of the digital transformation of customer loyalty systems of telecommunications companies by the measures of the business process management improving based on e-TOM model. The paper defines criteria for evaluating the effectiveness of customer loyalty systems digital transformation for telecommunications companies. The essence of the assessment method is to compare two blocks of indicators: economic efficiency coefficients (before and after digital transformation) and a group of indicators of effects accompanying digital transformation (indicators of strategic, client, operational, cultural, technological effects). The information base of this study was modern literature and statistical about digital transformation of telecommunications companies, as well as data of business processes of telecommunications sector organizations (from America, Europe, Asia, Russia) and the results of interviews with industry experts. Also, we used data from the report of the customer loyalty system's digital transformation results of the telecommunications company, conducted with the participation of the authors. The results of assess the effectiveness of the digital transformation of the telecom provider's customer loyalty system show an increase in the efficiency coefficient from 0.62 to 1.08, as well as an increase in all groups of effects except of personnel culture in the company. In particular, the customer satisfaction index (CSI) increases from 21% to 79% and the outflow of customers decrease from 37.5% to 25%. Finally, there was a discussion of the results of our study, and the conclusions were summarized.
616	The growth of cloud computing has resulted in uneconomic energy consumption, which has negatively impacted the environment through the generation of carbon emissions. One of the most important issues for green cloud environments concerns where to place new virtual machine (VM) requests across physical servers in a way that ensures reduced energy consumption. This paper proposes a deadline based dynamic virtual machine (DBDV) migration algorithm to reduce energy consumption in Cloud datacenters. Virtual machines are classified in three categories: compute intensive task, data intensive task and mix load task. Tasks have been allocated based on similar category of virtual machine. Compute intensive task is assigned to compute intensive virtual machine, data intensive task is assigned to data intensive virtual machine and mix load task is assigned to mix load virtual machine. All tasks are assigned to similar type of virtual machine without classifying virtual machine. The proposed algorithm for virtual machine mapping is based on deadline of task and migration of virtual machine. The proposed algorithm is compared with threshold-based method, PSO and Ant Colony Optimization algorithm and analyzed the result for the energy utilization and number of virtual machine migration as well as completion time. The experimental results show that a DBDV migration algorithm outperforms the existing algorithms in terms of these parameters.
617	BP's FIELD OF THE FUTURE for North American Gas Strategic Performance Unit is a ground-breaking initiative which utilizes advanced automation, collaboration and analytic tools to enable major reductions in well intervention timing, as well as, prevent and recover lost volumes more quickly. This effort requires a phased, multi-discipline approach and encompasses changes in technology, business process and people. FIELD OF THE FUTURE begins with upgrading foundational equipment and systems, such as, current automation and field telecoms. From a systems standpoint, FIELD OF THE FUTURE requires enhancement of NAG's data management approach towards collection, storage and retrieval of significantly increased data (100x or more), from field operations. Another key component of change is the design and installation of Advanced Collaborative Environments (ACEs). ACEs are integral in this phase, as they enable multi-disciplinary teams working in collaborative spaces, to successfully interact during the decision-making process. Even with the enhanced foundational systems, the influx of new and vast amounts of data will reach beyond personnel capability to utilize effectively, without the new technologies. To manage the additional data, FIELD OF THE FUTURE leverages integrated advanced visualization, modeling and intelligent applications functionality. These are then merged into the business process to discover areas for optimization in day-to-day operations. This leads to greater productivity, as well as, reduced decision cycle time. Taking this one step further, FIELD OF THE FUTURE identifies viable solutions (both current and futuristic), which can further enhance benefits through analytic and business process management tools. These can empower the organization to do more with less - a problem we will confront within the North American Gas SPU, in the next five years. The success of the program lies in the ability to integrate accurate, real-time data with people and their daily work activities. To achieve program goals, FIELD OF THE FUTURE is currently testing and refining enhancements in automation, collaboration, data/applications and processes by partnering with three Pilot Assets across North America. The ultimate measure of the program's success will be based on key performance indicators, described herein, which demonstrate real value to the Assets. These include: Increased production Decreased Health Safety Security Environment (HSSE) incidents, Reduced downtime, Greater organizational capability, People productivity Increased operational efficiency. FIELD OF THE FUTURE has the potential to impact every aspect of field operations and must be strategically aligned with other BP corporate initiatives. Thus, FIELD OF THE FUTURE must have executive alignment and active executive leadership to enable change. Finally, FIELD OF THE FUTURE is not about individual technologies, but about the integration of tools and capabilities spanning people, process and technology. The presentation paper will give an update on the current status of work at the three Pilots and share key Lessons Learned by NAG FIELD OF THE FUTURE, in this journey. Copyright 2007, Society of Petroleum Engineers.
618	Performance Management Systems (PMS) - Also termed as Business Performance Management (BPM), Corporate Performance Management (CPM) or Enterprise Performance Management (EPM) - represents an often topic of debate in academic journals. The literature consists of two highly overlapping categories of research. The first category is research on Performance Measurement, which primarily addresses the question of appropriate measurement how company proceeds towards its performance goals. The second stream of research deals with Management Control Systems (MCS) and focuses more on the purpose of performance measurement and its specific context. The aim of this article is to address the following three basic research questions that each scholar starting research in PMS has to answer. Namely these are: RQ1. How to define contemporary PMS? RQ2. What are the key factors that influence the design and outcomes of PMS? RQ3. Which methods best reflect the interdependences among factors, PMS and performance? The article reveals that despite 50 years of research, the terminological inconsistencies persist involving the definition of the term PMS itself, its subcategories and last but not least the list of factors with impact on PMS. These contingency factors are briefly introduced and the final framework mapping their relationships is presented as well. Because traditional statistical methods coping with the standalone relationship are not sufficient, the quantitative studies in the intertwined nature of contingency factors, PMS and its outcomes usually employ the technique of Structural Equation Modelling (SEM), which represents the answer to the third research question.
619	Workflow Management Systems (WfMSs) provide platforms for delivering complex service-oriented applications that need to satisfy enterprise-grade quality of service requirements such as dependability and scalability. In this paper we focus on the case of benchmarking the performance of the core of WfMSs, Workflow Engines, that are compliant with the Business Process Model and Notation 2.0 (BPMN 2.0) standard. We first explore the main challenges that need to be met when designing such a benchmark and describe the approaches we designed for tackling them in the BenchFlow project. We discuss our approach to distill the essence of real-world processes to create from it processes for the benchmark, and to ensure that the benchmark finds wide applicability.
620	Purpose - Extensive literature on business process management suggests that organizations could enhance their overall performance by adopting a process view of business. However, there is a lack of empirical research in this field. The purpose of this paper is to investigate the understanding of the process view and process maturity levels in a transition economy and to test the impact of process orientation maturity level on organizational performance. Design/methodology/approach - Empirical investigation combined an exploratory-confirmatory approach using factor analysis and structural equation modeling. Findings - The investigation confirms the impact of business process orientation on organizational performance in a transition economy. The link is even stronger than in the original investigation. The results show that business process orientation leads to better non-financial performance and indirectly to better financial performance. Practical implications - The research confirms that business process orientation is advantageous for companies since it has a positive influence on organizational performance. The finding that the impact on financial performance is indirect through non-financial performance suggests that the companies have to take that view of performance into consideration as well. Originality/value - The paper is valuable for academics and practitioners because the impact of business process orientation on organizational performance has been confirmed for a transitional economy. Its originality is in the measurement of organizational performance, for which a more detailed specification of organizational performance based on the balanced scorecard concept that includes non-financial performance measures has been used. © Emerald Group Publishing Limited.
621	Multiparty Computation is based on complex math, and over the past decade, MPC has been harnessed as one of the most powerful tools available for the protection of sensitive data. MPC now serves as the basis for protocols that let a set of parties interact and compute on a pool of private inputs without revealing any of the data contained within those inputs. In the end, only the results are revealed. The implications of this can often prove profound.
622	Rapid delivery strategies strive to balance critical performance qualities vs. reducing the time between an idea and deployment of a software implementation of that idea. For industrial software solutions that encapsulate expertise in deliverable components, technical SMEs (Subject Matter Experts) with ideas and knowledge have traditionally partnered as requirements providers with software development teams. These human processes are not optimally fast, are vulnerable to errors in translating or interpreting requirements, and do not scale when software teams need to integrate the knowledge of many SMEs into multiple software solutions and deployments. To address these limitations, ABB has pursued an industrial research initiative for innovative SME toolsets with focus on two goals: to accelerate the creation, evolution, reuse, and delivery of expert algorithms, and to streamline the deployment of these algorithms into releases and fielded solutions. The vision underpinning the initiative is to empower technical SMEs as "end-user developers" to convert their knowledge into reusable software solution components without having to learn, perform, or partner on traditional software development, integration, or deployment. In this paper, we summarize our experiences and lessons learned to date from this initiative, key continuing challenges, and some positional thoughts on how end-user development by technical SMEs aligns with emerging approaches for rapid delivery and evolution.
623	In today's difficult economy, companies are reorganizing and streamlining wherever possible in order to save money and attract customers. This new corporate emphasis on better organizational performance, i.e., both productivity and quality goods and services, challenges all parts of an organization, including IS, to make improvements in what they do and how they operate. This is easier said than done and many organizations are having difficulties knowing where to start, what to do, and what their goals should be. Organizational learning change are the hallmarks of business in the nineties and the starting point for this effort is the collection of accurate and adequate information and its appropriate analysis.It is not surprising therefore that comparison, measurement, and evaluation have become something of a preoccupation in many businesses in recent years. The U.S. National Quality Institute, (which establishes the detailed criteria for the Malcolm Baldridge Awards), suggests there are three components of effective information and analysis which act as the "brain center" driving the corporate improvement effort, regardless of a company's organization or structure (Baldridge Criteria, 1993):1. Scope and management of quality and performance information.2. Collection, analysis, and use of company level data, including customer data and operations data, and linking performance data to overall financial performance.3. Competitive comparisons and benchmarking.These criteria can also be used by individual corporate subunits to determine how well they contribute to overall quality and performance.One organizational subunit receiving a considerable amount of executive attention in this regard is the information systems (IS) function. Many companies are looking to information technology to help them support corporate restructuring, but to do it with increasingly fewer resources. Unfortunately, IS has also been an area of the company that has been extremely difficult to measure and evaluate. IS also continues to have a credibility problem in some organizations where executives believe that IS has contributed little or nothing to the corporate bottom line (Roach, 1989). As well, there are still many users who tend to feel that IS service is lacking or could be bought cheaper elsewhere. With IS budgets coming under closer and closer scrutiny, IS itself is placing new emphasis on measurement to demonstrate its contribution to overall corporate performance, both through quality services and systems and through its ability to do so cost-effectively.This paper looks at the three components of information and its analysis, as outlined above, from the perspective of the IS subunit. It summarizes what IS departments are doing to assess and analyze their organizations and makes suggestions about how the measurement and evaluation of IS both internally and externally could be improved.
624	The article describes the concept of corporate performance management (CPM), its strategic role and actuality in current terms of doing business. The author analyses and classifies CPM maturity levels, reviews fundamental performance management instruments, presents key factors of successful CPM implementation and key activities for business performance improvement in a strategic perspective. Economic management efficiency activities directed at optimizing implementations strategies and consisting of a set of integrated cyclic analytical process, supported corresponding technologies and related how to apply for financial assistance, so to the operating room information. BPM allows the company to determine, measuring and manage efficiency its activity, directed at achieving strategic purposes. Key financial and operating systems processes BPM enable planning and budgeting, consolidation and reporting, key data analysis indicators efficiencies and their distribution within the organization. Also, the article deals with the relationship between budgeting and the business system management efficiency. Management efficiency of business activities (English the terms CPM, BPM, EPM) — this is a set managerial processe (plannings, organizations accomplishments, monitoring and analysis), which are allowed to define a business strategic goals and then to evaluate and to manage activity on achievement delivered goals at the optimal level usage existing resource. International Research Publication House
625	Software systems must be updated regularly to address changing requirements and urgent issues like security-related bugs. Traditionally, updates are performed by shutting down the system to replace certain components. In modern software organizations, updates are increasingly frequent—up to multiple times per day—hence, shutting down the entire system is unacceptable. Safe dynamic software updating (DSU) enables component updates while the system is running by determining when the update can occur without causing errors. Safe DSU is crucial, especially for long-running or frequently executed asynchronous transactions (workflows), e.g., user-interactive sessions or order fulfillment processes. Unfortunately, previous research is limited to synchronous transaction models and does not address this case.In this work, we propose a unified model for safe DSU in workflows. We discuss how state-of-the-art DSU solutions fit into this model and show that they incur significant overhead. To improve the performance, we introduce Essential Safety, a novel safe DSU approach that leverages the notion of non-essential changes, i.e., semantics preserving updates. In 106 realistic BPMN workflows, Essential Safety reduces the delay of workflow completions, on average, by 47.8% compared to the state of the art. We show that the distinction of essential and non-essential changes plays a crucial role in this reduction and that, as suggested in the literature, non-essential changes are frequent: at least 60% and often more than 90% of systems' updates in eight monorepos we analyze.
626	Business processes need to achieve key performance indicators with minimum resources in changing operating conditions. Changes include hardware and software failures, load variation and variations in user interaction with the system. By incorporating simulation in the prediction model it is possible to predict with more confidence system performance degradations. We present our dynamic predictive model which uses forecasting techniques on historical process performance estimates for business process optimization. The parameters of the simulation model are estimates tuned at run-time by tracking the system with a particle filter. © 2011 ACM.
627	Business processes need to adapt to changes in the operating conditions and to meet the service-level agreements (SLAs) with a minimum of resources. Changes in operating conditions include hardware and software failures, load variation and variations in user interaction with the system. An integral component to adaptation is the awareness over the behavior of self and environment (or having an estimation of the current situation). Aiming at estimation, this paper investigates the automatic building of a dynamic predictive model of the business process that is used for business process optimization. The model is a simulation model whose parameters are tuned at run time by tracking the system with a particle filter.
628	FOR MANY YEARS, the word mechanization remained the key word in the computer solution of business problems. The objectives were confined to the realization of early benefits through reduction in the clerical working force. The resulting inefficient computer usage has led to a shift in emphasis from the autonomous computer program to an overall systems approach.Within our division a project is under way directed towards the development of an integrated management control system for research and development projects. Known as the ICON information system it will provide both operational and executive levels of management with a comprehensive picture of a complex operation to facilitate decision making.
629	How managers’ social network would affect a firm's performance, and what kind of relationship between them are two main points we discuss during our research. We evaluate a manager in four centralities: degree centrality, closeness centrality, betweenness centrality, and eigenvector centrality, and compare to their company performance. Overall, our results suggest that executives’ social networks relate tightly to firm performance and have a positive relation to it.
630	In the world of business, even small advantages make a difference. As such, establishing strategic goals becomes a very important practice. However, the big challenge is in the designing of processes aligned with the goals. Modeling goals and processes in an integrated way improves the traceability among strategic and operational layers, easing up the alignment problem. © Springer International Publishing Switzerland 2014.
631	Abstract When a company decides to automate its business processes by means of RPA (Robotic Process Automation), there are two fundamental questions that need to be answered. Firstly, what activities should the company automate and what characteristics make them suitable for RPA. The aim of the presented research is to design and demonstrate a data-driven performance framework assessing the impact of RPA implementation using process mining (PPAFR). Firstly, we comment on and summarise existing trends in process mining and RPA. Secondly, we describe research objectives and methods following the Design Science Research Methodology. Then, we identify critical factors for RPA implementation and design process stages of PPAFR. We demonstrate the design on real data from a loan application process. The demonstration consists of a process discovery using process mining methods, process analysis, and process simulation with assessment of RPA candidates. Based on the research results, a redesign of the process is proposed with emphasis on RPA implementation. Finally, we discuss the usefulness of PPAFR by helping companies to identify potentially suitable activities for RPA implementation and not overestimating potential gains. Obtained results show that within the loan application process, waiting times are the main causes of extended cases. If the waiting times are generated internally, it will be much easier for the company to address them. If the automation is focused mainly on processing times, the impact of automation on the overall performance of the process is insignificant or very low. Moreover, the research identified several characteristics which have to be considered when implementing RPA due to the impact on the overall performance of the process.
632	An important part of Business Performance Management (BPM) is identifying strategic targets for the organisation, cascading them down into tactical and operational targets and finally optimising operational levers or actions as to achieve the given targets. In order to do this, performance metrics have to be defined at all levels and relationships between levers and metrics have to be mathematically modelled. Thereby, traditional BPM cannot deal with imprecise information although imprecision is a commonplace in real world applications. We discuss the most important functions of BPM and show how fuzzy and probabilistic techniques can be applied to process imprecise information. A few of the techniques have already been implemented in a research prototype. ©2008 IEEE.
633	A frequent hurdle in applying Business Process Management(BPM) to large enterprises is that, since business processes are not only numerous but also documented in an engagement in multiple representations,it is difficult to work with the documented 'as-is' or 'to-be' state of the business, leave aside make accurate transformation decisions. In this paper, we consider the problem of how to reconcile and organize documented information about processes into groups that convey inter-process similarity. The discovered knowledge can be used for many applications like search, e.g., find all requirements across all available processes that are similar to those of the "Account Receivable" process. The method has been tested on a dataset consisting of hundreds of processes documented in Word and Visio, wherefrom it could find process clusters that significantly boosted search performance.
634	This paper proposes a novel method for the structuring of the knowledge of a service process in order to be processed by lightweight declarative computing infrastructures. Through the identification of self-similarities in the process, the flow of the structured information and the sequence of activities performed in the process are easily implemented by means of cyber-physical systems technologies, in order to timely meet the customer/stakeholder’s requirements. The study was performed in a telecommunication service providing organization. Service teams create a collaborative network. With the use of the CPS proposed in this work they can communicate problems and disseminate solutions. This methodology uses the information of a set of performance indicators of the service organization to achieve a better control of the effectiveness and the bottlenecks in the supply network. The methodology is borrowed from the mechatronics field and it is prone to a natural extension and reuse for the similar information structures in manufacturing processes. © IFIP International Federation for Information Processing 2017.
635	nan
636	nan
637	Companies require highly automated business process management (BPM) functionality, with the flexibility to incorporate business intelligence (BI) at appropriate stages throughout the workflow. Business Activity Monitoring (BAM) unifies these two technologies and provides real-time access to critical performance indicators to improve the speed and effectiveness of business operations. This paper discusses BPM technologies in the context of the supply chain and presents the comprehensive BAM solution that utilizes latest BPM, BI and portal technologies in order to enable decision makers to access and assimilate the right information to make well-informed, timely decisions. © 2008 International Federation for Information Processing.
638	Agile supply chain analytics is about ability to adapt business intelligence (BI) systems to meet the changing needs of the supply network and its environment. Agile BI incorporates both technical and process-oriented approach to development, management, and delivery of BI solutions. To achieve agile BI, supply chains must provide and establish the necessary infrastructure, architecture, tools and processes in a way that enables them to deliver BI systems capable of quickly and effectively adapting to the rapidly changing business needs and environment factors. However, most supply chains still lack methods, processes and tools to successfully design and implement these systems. The paper first provides an analysis of current situation and a concise background research, followed by the introduction of the integrated and adaptive supply chain business intelligence model. This model enables design of pervasive analytical systems for collaborative decision-making, monitoring and management of the supply network. The main components of the model are described, as well as the architecture and features of the specialized supply chain intelligence web portal which demonstrates usefulness and applicability of the proposed model. This system allows creation of a new breed of flexible and agile BI systems which ultimately results in more efficient, responsive and adaptive supply chains.
639	Process models generated through process mining depict the as-is state of a process. Through annotations with metrics such as the frequency or duration of activities, these models provide generic information to the process analyst. To improve business processes with respect to performance measures, process analysts require further guidance from the process model. In this study, we design Graph Relevance Miner (GRM), a technique based on graph neural networks, to determine the relevance scores for process activities with respect to performance measures. Annotating process models with such relevance scores facilitates a problem-focused analysis of the business process, placing these problems at the centre of the analysis. We quantitatively evaluate the predictive quality of our technique using four datasets from different domains, to demonstrate the faithfulness of the relevance scores. Furthermore, we present the results of a case study, which highlight the utility of the technique for organisations. Our work has important implications both for research and business applications, because process model-based analyses feature shortcomings that need to be urgently addressed to realise successful process mining at an enterprise level. © 2021 The Author(s)
640	nan
641	This paper analysis BPM adoption in context of companies operating in Serbia. The goals were to determine level of BPM adoption in companies in Serbia and identify what factors contributing the most to the success in BPM adoption. Questionnaire was used for data collection. BPM adoption was measured through Process Performance Index (PPI). Parametric statistical tests were used on survey data to identify factors that contribute the most to successful BPM adoption. Results in this research shows several factors that significantly contribute to success of BPM adoption measured through PPI. First, companies who have formally trained their employees in process analysis/redesign experienced more significant success in BPM adoption. Second factor is strategic orientation, expressed through criteria such as enterprise-wide business process architecture design and change efforts, increased market share and revenue, reduction of business risk, etc. This shows that strategic focus can even make up for the lack of operational knowledge, and increase chances for success of BPM adoption. © 2019, Springer Nature Switzerland AG.
642	Subject-oriented Business Process Management (S-BPM) is an emerging approach focusing on adjusted interaction and individual behavior of stakeholders in business operation. Unfortunately, current implementations &amp; tools lead to issues in most industry-related S-BPM-projects. This contribution reveals how the concept of Business-Actors reduces S-BPM to it's underlying core and enhances it at the same time in some fields. Thus, Business-Actors are a method and technology being able to overcome problems of classical S-BPM-approaches.
643	nan
644	Risk analysis is one of the most challenging task in a business process management perspective. In healthcare, risk management focuses on events having a relevant impact on patients safety. We investigate the context of a blood-bank, which is one of the most critical hospital department, by comparing two different modeling approaches to perform a risk-aware business process management. Our main interest here is to discuss advantages and disadvantages of discrete-event and agent-based modeling approaches. We adopt two specific tools and collected feedback from modelers, staff and decision makers. We identify differences in the analysis of risks from the two perspectives, such as the possibility to include agents-environment interactions, as well as structured approaches to discover potential failures. Our results include assessment for risk management, shedding some light on practical applications of process modeling and simulation in healthcare.
645	nan
646	The efficiency of business processes within and across organizations is crucial to the success of Enterprise Systems (ESs). An appropriate process performance evaluation model can help enterprises improve the quality of business processes. However, process evaluation approach has not been sufficiently investigated. Moreover most studies and systems use one single evaluation value to forecast process performance. Such a simple process evaluation approach may not be able to reflect the processes performance history and prediction. To depict the status of business process exactly, therefore, a good BPM system requires more comprehensive performance evaluation. In this paper, a comprehensive evaluation approach is proposed to analyze business process performance for enterprise decision maker by providing several evaluation features. The experimental results indicate that the proposed approach is feasible.
647	It is considered for companies to make up new types of organization, adopt ICT technologies tailored to the features of company, or etc, as a plan for the company to survive in the competitive environment. Especially, Utilizing IT technologies, when companies do their business, can make companies share their information, and it leads to reduce their costs in the business process and shorten their work time. Namely, introducing and utilizing ICT collaborative system that can make companies collaborate on their business brings about economic collaborative performance for the companies. So, a mother company and its partner companies bring ICT collaborative systems in and share their information that is needed by each company to secure their future value, and also try to lead the competitiveness of companies in the maximum level by constructing the collaborative network between a mother company and its partner companies.In particular, the automobile industry has a great variety of steps such as materials, half-finished goods, work in process and product for producing the final product, and the number of the partner companies that supply half-finished goods is greater than other industries. In addition, type and number of its partner companies is diverse, and the parent company has a high level of reliance on its partner companies so that the need of the outsourcing collaborative system utilizing ICT is continuously increasing.There have been studies on the level of ICT utilization, the level of ICT collaboration, and so on. However, few writers have been able to draw on any structured research into the study, performance analysis depending on ICT collaboration.Therefore, in this study we tried to figure out the performance level measured from the ICT collaborative system constructed based on the business processes such as product development, demand forecasting, production planning, distribution, and logistics management in the automobile industry, and to analyze which factors influence the level of performance.In this study, we collected and analyzed basic data for the target of survey and business manager of the parent company but It is need to proceed analysis of business performance which is active and has validity from the step of business agreement to the step after the end of business rather than submit the data for performance tracking obligatorily for acquiring an objective performance data.Also, based on study result conducted in this study, It is need to proceed to study about having the effect of performance improvement with changed some factor after constructing IT collaboration system.
648	Integrated Information systems such as Enterprise Resource Planning (ERP) offer distinct advantages for the broadcasting industry by lowering operating costs, increasing productivity rate, reducing cycle times and increasing customer satisfaction. But the lack of empirical evidence that an integrated enterprise system will positively impact broadcasting processes has mooted this study. The paper aims to explore best practices in broadcasting, emanating from an ERP or Best of Breed (BoB) environment using the three core performance measures of productivity, flexibility and return on investment (ROI). The study moderated performance measures using the technological, organisational and environmental (TOE) factors of the business environment. The findings revealed that the utilisation of the ERP system would be the better practice in terms of productivity and ROI. Further, the study has also revealed that the environmental factor is not a significant moderating variable at implementing either the ERP or BoB system. The empirical evidence confirmed a number of benefits which could be derived from ERP systems particularly for business process management in the broadcasting industry. The implication from the study is that the findings provide a basis for broadcasting organisations to harness the potential of implementing ERP systems for effective business integration.
649	In the context of a single wafer lot semiconductor factory characterized by high levels of Research and Development (RD) work-in-progress (WIP), low levels of product-based lots and lengthy cycle times, this paper investigates the accuracy of capacity planning given the impact of dynamic changes in dedication. We delve into several critical aspects related to dedication planning, drawing insights from historical data and dispatch logic used. The experimental results show the improvement in model accuracy with the incorporation of dedication changes as distribution functions.
650	Purpose: Organizations introduce business intelligence (BI) to increase their performance, but often, this initiative is not aligned with the business process management (BPM) initiative, which also aims to improve organizational performance. Although some findings from the literature indicate that BI implementation has a positive impact on organizational performance, the impact seems to be indirect. Therefore, the purpose of this study is to enhance the understanding of how BI maturity is translated into organizational performance. Alignment of BI and BPM initiatives seems one possible way for creating business value with BI, particularly because BI enables process performance measurement and management, which allows the BI initiative to become more business focused. Design/methodology/approach: A questionnaire was prepared and used to collect data in Croatian and Slovenian organizations with more than 50 employees. A BI–BPM alignment measurement instrument was developed for the purpose of this study using the recommended process of scale development and validation. A total of 185 responses were analyzed by the structural equation modeling technique. Findings: Our results provide evidence that the effect of BI on organizational performance is fully mediated by alignment of BI and BPM initiatives, and therefore, BI business value can be generated through the use of common terminology and methodologies, as well as a strong communication between BI and BPM experts, managers and teams in order to coordinate the two initiatives. Originality/value: This study has responded to the call for better understanding of how the impact of BI on organization performance is realized. It confirmed that BI and BPM initiatives should be aligned in order to give BI a business value. © 2020, Emerald Publishing Limited.
651	Process executions generate event data that are typically stored in legacy information systems, such as databases. However, process discovery, which requires such event data, is performed in main memory. To bridge this gap, existing techniques must transform and extract event data, which can be expensive steps. This issue has been addressed by processing the event data directly in their origin. However, existing methods rely only on the simplest event data abstraction: the Directly Follows (DF) abstraction. This paper improves upon these existing works by considering another abstraction, the Minimum Self Distance (MSD) abstraction, which enables discovery of a larger class of models than the DF alone. That is, we propose IMw, a process discovery technique without logs and uses both the MSD and DF abstractions. Furthermore, this work proposes an approach to compute the MSD abstraction in-database, thus avoiding the need for transforming and moving event data. We evaluate IMw with real-life logs, and the experimental results show that IMw with in-database abstraction is faster than the traditional approach, aware of dynamic updates on event data, and able to discover models with pareto-optimal results, compared to existing techniques.
652	Abstract For almost 30 years, the way of building business process management maturity models (BPM MMs), the importance assigned to individual maturity levels, and the criteria and critical success factors chosen for BPM maturity assessment have not changed significantly, despite the fact that during those three decades, the business environment and organizations themselves have changed enormously. The impact of hyperautomation and the increasing pace of change require the integration of maturity assessment with the BPM implementation methodology, including the repetition of maturity assessment for selected groups of processes. This causes an urgent need to adapt both process maturity assessment methods and BPM MMs to changing working conditions and business requirements. This conceptual paper is based on a model approach. The framework presented in the article continues and at the same time clearly deviates from the tradition of building BPM MMs on the basis of the Capability Maturity Model (CMM). It proposes a two-stage comprehensive process of organizational process maturity assessment, fully integrated into the process of BPM implementation and further business process management. The presented framework makes it possible to assess the process maturity of Industry 4.0 organizations in which dynamic knowledge-intensive business processes (kiBPs) play a key role in creating value.
653	This paper proposes a model that integrates the knowledge management to the business processes management in order to improve the process performance. The proposal defines the knowledge management flow as an element that interacts with part workflows and provides rules and actions in the BPMN elements in order to improve the BPM. To achieve the aim, first, a survey was made in forty Colombian' companies in order to identify the state of the practice about business process management, knowledge management and their use through the workflows; then, different elements were identified and characterized in order to achieve the integration model proposed. This was experimented in forty business workflows of the companies analyzed. A use case shows how the interactions among model elements are, and how these can improve the process performance. This experience allowed to measuring the effect that the integration had in the business process management by means of a new metric that involve the knowledge management in the workflow. Finally, it was possible conclude that the knowledge management must be part to the BPM impacting directly the workflow, in order to improve the result offered to the organizational actors and customers.
654	The convergence of Internet of Things (IoT) and the Cloud has significantly facilitated the provision and management of services in large-scale applications, such as smart cities. With a huge number of IoT services accessible through clouds, it is very important to model and expose cloud-based IoT services in an efficient manner, promising easy and real-time delivery of cloud-based, data-centric IoT services. The existing work in this area has adopted a uniform and flat view to IoT services and their data, making it difficult to achieve the above goal. In this article, we propose a software framework, Context-driven And Real-time IoT (CARIoT) for real-time provisioning of cloud-based IoT services and their data, driven by their contextual properties. The main idea behind the proposed framework is to structure the description of data-centric IoT services and their real-time and historical data in a hierarchical form in accordance with the end-user application’s context model. CARIoT features design choices and software services to realize this service provisioning model and the supporting data structures for hierarchical IoT data access. Using this approach, end-user applications can access IoT services and subscribe to their real-time and historical data in an efficient manner at different contextual levels, e.g., from a municipal district to a street in smart city use cases. We leverage a popular cloud-based data storage platform, called Firebase, to implement the CARIoT framework and evaluate its efficiency. The evaluation results show that CARIoT’s hierarchical structure imposes no additional overhead with less data notification delay as compared to existing flat structures.
655	There is a growing need for empirical benchmarks that support researchers and practitioners in selecting the best machine learning technique for given prediction tasks. In this article, we consider the next event prediction task in business process predictive monitoring, and we extend our previously published benchmark by studying the impact on the performance of different encoding windows and of using ensemble schemes. The choice of whether to use ensembles and which scheme to use often depends on the type of data and classification task. While there is a general understanding that ensembles perform well in predictive monitoring of business processes, next event prediction is a task for which no other benchmarks involving ensembles are available. The proposed benchmark helps researchers to select a high-performing individual classifier or ensemble scheme given the variability at the case level of the event log under consideration. Experimental results show that choosing an optimal number of events for feature encoding is challenging, resulting in the need to consider each event log individually when selecting an optimal value. Ensemble schemes improve the performance of low-performing classifiers in this task, such as SVM, whereas high-performing classifiers, such as tree-based classifiers, are not better off when ensemble schemes are considered.
656	The optimization of processes of business guarantees the successes of informationization project. Although its importance is fully recognized, it never obtains sufficient study. This paper first discuss the current business process optimization methods, they are classified into three type: participation-type, principle-type and analytical-type. Then, architecture of process mining based business process optimization is proposed. According to this architecture, the subset of information that is relevant for process mining or analysis is extracted from a variety of business process system. This information is then modelled in certain of expression. Based on the model, hidden relationship and unknown knowledge about business processes are extracted and stored in the form of business knowledge model. With the help of the acquired business knowledge, business process can be optimized both on macro structure level through case based reasoning and on micro parameter level through process simulation and linear programming. Business process performance measurement system is employed in the architecture to check effect of optimization. Finally, key issues in this architecture are discussed.
657	Optimizing the process parameters with respect to the future environmental conditions is an immediate challenge for environment-sensitive process manufacturing industry to achieve more consistent production quality. In this paper, we propose a simulation-based quality variance control system consisted of three core components: an indoor environment calibration module, a quality prediction module and a simulation engine. We then demonstrate the use of this system by analyzing a typical manufacturing process consisted of four sub-processes. The studies show that the proposed system can achieve better performances by integrating a future indoor environment calibration module than that of without such module. In addition, the simulation-based method can provide more acceptable outcome which outperforms the collaborative filtering algorithm. Such system is feasible to be applied in real industry scenarios which are sensitive to environmental changes to precisely control the quality variances.
658	nan
659	The current drive towards Service Oriented Architecture (SOA) and Business Process Execution Language (BPEL) in enterprises will increase dependency on efficient businesses processes. In the current competitive environment, process efficiency gains are seen as a crucial factor for business success. However it is not sufficient to design a process that works well under normal conditions. Risk analysis and mitigation is an important activity that should be tackled systematically during process design and improvement. The process designer's job has thus become particularly complex, requiring tools that combine traditional business process management with operational risk analysis. In this paper we introduce a simulation environment that has been developed within British Telecommunications plc to simulate business process performance. The simulator incorporates a facility to simulate arbitrary risk effects on the performance of the process. Since risk analysis typically deals with qualitative values such as "high probability risk" or "low impact risk", measuring key risk indicators (KRIs) can be difficult. The simulator allows the process designer to formulate a fuzzy system of rules to define how risk is measured; these allow the user to produce KRIs that utilise the qualitative risk knowledge in addition to the ability to derive quantitative risk measures should they be needed. © ECMS.
660	nan
661	Purpose: The purpose of this paper is to illustrate and evaluate the semantic process benchmarking concept. Design/methodology/approach: The authors' approach includes the use of metamodels and ontologies, which make the process models syntactically and semantically comparable. Furthermore, a software prototype is presented to analyze and compare individual process models and their performance information. Thereafter, the technical, conceptual, and economic perspectives of the approach's evaluation are aligned with their respective outcomes. Findings: The evaluation proves that this approach is generally suitable to generate novel and useful information on different process models and their performance within the same problem domain. However, the initial set-up costs are high and will only pay off once process models are used regularly. Practical implications: The proposed approach depends strongly on the availability of appropriate metrics and ontologies, as well as on the annotation of these ontologies to process models, which is a time-consuming task. If large benchmarking clearing centers are established, the approach will be more cost-effective. The developed SEMAT prototype, that demonstrates and proves the proposed approach's general viability, supports cost-effective ontology engineering and annotation in the context of semantic process benchmarking initiatives. Originality/value: To date, process benchmarking has primarily been a manual process. In this article, the authors suggest an approach that allows time-consuming and costly process analysis to be partially automated, which makes the performance indicators, as well as qualitative differences between processes, apparent. © Emerald Group Publishing Limited.
662	This article suggests an approach which allows the costly analysis of processes, e.g., in service oriented architectures for benchmarking to be partially automated, so that the performance indicators, as well as qualitative differences between processes become apparent. The approach is based on using appropriate ontologies, which make the process models both syntactically and semantically comparable. In this article, we present a conceptual model for this new approach to process benchmarking, a framework, as well as a software prototype for analyzing and comparing individual process models. We provide an overview of our multi-method evaluation methodology and delineate the technical, conceptual, and economic evaluation perspectives with their respective outcomes. This analysis allowed us to determine whether our approach is generally suitable for generating novel and useful information on different process models that describe the same problem domain.
663	Abstract Risk-aware Business Process Management (R-BPM) has been addressed in research since more than a decade. However, the integration of the two independent research streams is still ongoing with a lack of research focusing on the conceptual modeling perspective. Such an integration results in an increased meta-model complexity and a higher entry barrier for modelers in creating conceptual models and for addressees of the models in comprehending them. Multi-view modeling can reduce this complexity by providing multiple interdependent viewpoints that, all together, represent a complex system. Each viewpoint only covers those concepts that are necessary to separate the different concerns of stakeholders. However, adopting multi-view modeling discloses a number of challenges particularly related to managing consistency which is threatened by semantic and syntactic overlaps between the viewpoints. Moreover, usability and efficiency of multi-view modeling have never been systematically evaluated. This paper reports on the conceptualization, implementation, and empirical evaluation of e-BPRIM, a multi-view modeling extension of the Business Process-Risk Management-Integrated Method (BPRIM). The findings of our research contribute to theory by showing, that multi-view modeling outperforms diagram-oriented modeling by means of usability and efficiency of modeling, and quality of models. Moreover, the developed modeling tool is openly available, allowing its adoption and use in R-BPM practice. Eventually, the detailed presentation of the conceptualization serves as a blueprint for other researchers aiming to harness multi-view modeling.
664	With increased adoption and resource spent for business performance management, it is interesting to inquire about its practice and performance. Based on the response from CFO's of the 38 leading Indian companies, we found that BPM is satisfying tactical purposes well, but lagged in strategic, top management and learning and development needs. The results compare well with Tonge et al. (2000), Malcolm (2006), Wiersma (2009), etc. When compared with Simmons (1995b) levers of control, we observe better performance on diagnosis and belief control system, while lagged as interactive control tool. Despite increasing use and importance of various non-financial measures, we observed lower satisfaction with its measurement quality and fewer linked those measures to compensation, comparable with Lingle and Schiemann (1996). Our findings are symptomatic of evolution of BPM to overcome the inadequacies of reliance on accounting-based performance measurement (RAPM) to strategic management system and more recently management learning and development tool. Copyright © 2011 Inderscience Enterprises Ltd.
665	Increasing market demand and technology in today's world has made change management an inevitable one. To remain competitive, organizations must be able to respond to change in a timely and cost effective manner. Although there are many change management issues and solutions, there is no proper support for efficient change evaluation and monitoring. Present change management works are done only in the web service interface such as WSDL Web Service Definition Language and there is no proper support for dynamic nature in them. In this paper, we propose a novel dependency analysis approach for evaluating the changes specified by the analyst in an effective manner and a FSM based model is utilized for exhibiting the dynamic nature. This measure of change evaluation ensures that the business analyst has a direct control over the changes he makes and provides an environment that notifies the analyst about the outcome in a meaningful way. We propose a set of five change factors based on which the dependency existing between the business rules, functions and parameters is analyzed. These change factors are also involved in the change evaluation that makes the changes to be specified in a precise and formal manner. We develop a prototype system of the proposed model to demonstrate its effectiveness. We also conduct an experimental study to assess the performance of the change management along with the change measure as an output.
666	Business logic might be constantly improved or changed in order to provide enhanced services or to reduce cost. As a result, the software applications employed must be continuously updated to comply with the changes in their functional features. Changes in business logic of the web service must be done very quickly within the given time constraint as the services consumed by the providers and clients must not be affected. The framework proposed in this paper responds these challenges in three fold: Firstly, it formats the request and discovers required service logic through rule manager. Secondly, extracted logics are built as a complete web service and FSM is constructed by the Business Logic model to state the logic flow. Thirdly, it ascertains the right way for evaluation by analyzing dependency between the service logics through FSM. This allows enterprises to carve up and assimilate the services dynamically without developer's intervention at any stage. Thus this can be used for any IT enterprises in modern service industry to reduce the threshold of development and operation of services.
667	Modern large-scale companies are facing the challenge of how to prioritize improvement projects for business processes. This article offers a concept on how to approach this challenge using quantitative process maps. For the process maps treemaps are used, visualizing the most important processes of a company and the degree of needed change. Inside the article, the way to build up the process map, deriving important processes from the strategy and evaluating them regarding risks, maturity level, key performance indicators and given improvement ideas from idea management, is described. The paper also offers a concept for building up responsibilities and structuring the yearly process for process optimization.
668	Mobile devices offer great potentials for business process change and reengineering. However, realizing these potentials in practice still faces serious problems. While technologies are now widely mature, the problems still lie in the adoption and usage of mobile technology. In this paper, we analyze the contribution of user participation to the successful improvement of business metrics. This paper presents results from five case studies conducted in the IT-Service sector. The paper gives an example of a process calculation before and after mobile tool integration. Major findings include (a) user participation leads to improvements in business metrics and, (b) faster adoption and payback periods.
669	This paper presents the successful use of index encoding and machine learning to predict the turnaround time of a complex business process – the credit card application process. Predictions are made on in-progress processes and refreshed when new information is available. The business process is complex, with each individual instance having different steps, sequence, and length. For instances predicted to have higher than normal turnaround time, model explain-ability is employed to identify the top reasons. This allows for intervention in the process to potentially reduce turnaround time before completion.
670	This research is devoted to the development of innovative technology for automation of the quality management system of enterprise in Kazakhstan and its adaptation to the management system of enterprise. This paper deals with quality, as an important strategic tool in business. System effectiveness evaluation of quality management enterprises is of a great importance connected with the formation of rational decisions in the management of quality management systems including specificity of quality indicators, multi-level system, necessity to choose the optimal number of performance indicators and system status evaluation. The objective and relevance of this research is connected with the need to: 1) solve the problems of quality management in the digital economy, following from the relevant National programs of the Government of the Republic of Kazakhstan, which are important at this step of in-depth scientific research; 2) guarantee the competitiveness of domestic enterprises with high quality requirements for products and services; 3) improve the efficiency of automated quality management systems; 4) saving resources (human and timing) in data processing. The method and model of automated enterprise quality management and intelligent automated system of quality management of enterprise integrated with ruling MICS subsystems (Management Information and Control System) are offered allowing to automate QMS implementation and support processes and increasing the validity, efficiency and effectiveness of management decisions by automated a number of functions of decision makers and personnel. © 2023 Little Lion Scientific.
671	A dry port is an inland region or intermodal facility that is linked directly to a seaport. Cikarang Dry Port, while being one of the best-performing dry ports in Indonesia, contributed just 18% of Tanjung Priok Port's loading and unloading volume. This research aims to determine the effect of supplier innovation and service stakeholder commitment on the performance of dry port businesses. The data was gathered through a questionnaire elicited 55 answers from Cikarang Dry port and marine logistics firms in Greater Jakarta. Multiple regression was used to test hypotheses. This research shows that Supplier Innovation and Stakeholder Commitment to Service have a beneficial effect on port company performance. This research inspires managers to identify the beneficial outcomes of Supplier Innovation amongst service stakeholder engagement organizations to enhance port performance throughout the port supply chain.
672	Marketing strategy is the most important factor to increase the visitor's number to an agritourism. Accordingly, the selection of the best marketing strategy is needed so it provides the maximum result. Failure of strategy implementation can cause income loss for agritourism operational. Hence, adequate system analysis and business process design are needed to reduce the possibility of failure. This paper aims to analyze the requirements of the system and to design the business process including identify and determine visitor preferences in agritourism facilities and determine association rules of the priority marketing strategy for improving pineapple agritourism. Analytical system entity construction was used to describe the requirements of the system, the Unified Modeling Language and Business Process Model and Notation 2.0 were used to design the business process. Due to the limited marketing budget, the top eight most interesting facilities based on visitor preferences were determined by RELIEF-F algorithm. Then, the actionable marketing rules were determined by ARM algorithm. The result of system analysis shows that the system requires facilities and visitor preferences as inputs, agritourism operational and visitor as stakeholders, to result in an output of association rules as improved marketing strategies. From the design, we obtained the top eight facilities are camping ground, photo spot, pineapple field tour, pineapple factory tour, culture attraction, bicycle track, gazebo, and playground. ARM results association rules design is composed of five facilities: pineapple factory, pineapple field, gazebo, playground, and photo spot. From the result, we can conclude that the agritourism operational should consider placing the facilities close to each other according to obtained association rules.
673	Purpose: Business intelligence (BI) systems and tools are deemed to be a transformative source with the potential to contribute to reshaping the way different healthcare organizations’ (HCOs) services are offered and managed. However, this emerging field of research still appears underdeveloped and fragmented. Hence, this paper aims to reconciling, analyzing and synthesizing different strands of managerial-oriented literature on BI in HCOs and to enhance both theoretical and applied future contributions. Design/methodology/approach: A literature-based framework was developed to establish and guide a three-stage state-of-the-art systematic literature review (SLR). The SLR was undertaken adopting a hybrid methodology that combines a bibliometric and a content analysis. Findings: In total, 34 peer-review articles were included. Results revealed significant heterogeneity in theoretical basis and methodological strategies. Nonetheless, the knowledge structure of this research’s stream seems to be primarily composed of five clusters of interconnected topics: (1) decision-making, relevant capabilities and value creation; (2) user satisfaction and quality; (3) process management, organizational change and financial effectiveness; (4) decision-support information, dashboard and key performance indicators; and (5) performance management and organizational effectiveness. Originality/value: To the authors’ knowledge, this is the first SLR providing a business and management-related state-of-the-art on the topic. Besides, the paper offers an original framework disentangling future research directions from each emerged cluster into issues pertaining to BI implementation, utilization and impact in HCOs. The paper also discusses the need of future contributions to explore possible integrations of BI with emerging data-driven technologies (e.g. artificial intelligence) in HCOs, as the role of BI in addressing sustainability challenges. © 2024, Emerald Publishing Limited.
674	nan
675	Business processes play a central role in today's smart applications. To become even smarter, they should be flexible, executable and measurable for adapting to changing demand, being enacted effectively and assessed precisely. Due to the fact that de-facto process modeling languages do not cover these properties, this limitation gives rise to substantial amount of work for the extensions of the mainstream process modeling languages. The existing extensions support to capture the other perspectives of processes (e.g., resource allocation, performance measurement). Focusing on data flow aspect, we propose a framework for augmenting a control flow process model to yield an artifact-centric process model based on the state machine and business artifacts. The proposed mechanism is presented with the help of a real-life case study provided by our industrial partners.
676	Human resources of several businesses worldwide are already active in metaverses. This has led Human Resource Management (HRM) professionals exploring and applying new methods and practices to manage this technological transformation in the workplace. However, despite the growing volume of research on metaverse work environments, there is still limited research on avatar performance management. The emergence of metaverse applications in the workplace brings new key performance indicators (KPIs) requirements that are different from those in conventional work environments. This article aims to fill this gap by identifying the key metrics for measuring and managing avatar performance. For this purpose, a systematic literature review is carried out based on the PRISMA methodology. In total, 357 articles were screened, from which 31 met the predefined inclusion criteria and were reviewed based on their risk of bias. As a result, the required KPIs suitable for a metaverse workplace are proposed. By contributing to knowledge on performance in virtual work environments, this article extends and advances theory and research on the Strategic Human Resource Management of metaverse workplaces.
677	nan
678	The aim of this article is to provide a comprehensive overview of the utilization rate of Business Process Management (BPM) and its components in Czech factories focused on goals that managers follow by the implementation of process management and the factors that are merged with a process-oriented company. The paper presents a part of current results of the research conducted by a questionnaire survey. The whole research was focused on several aspects of process management. Within this research, aspects of Business Process Management are understood with the meaning of the views or positions on the issues of Business Process Management with a focus on the objectives, factors, components, support, benefits and barriers to BPM implementation. The purpose of the research was to monitor the attitudes, opinions and judgments of managers of Czech firms to individual aspects of BPM. Since this is a subjective expression, which is subsequently necessary to evaluate statistically were used in this study a scaling method, based on a quantification of qualitative data. The meeting the objective of this article was conditioned by confirmation or refutation of the hypotheses aimed at extending the concept of BPM in the Czech Republic and its understanding, the utilization rate of BPM in the Czech manufacturing companies, the complexity of BPM components and the orientation of Czech managers to support management processes. The complete results of the research showed positive development in almost all observed aspects. The largest positive change occurred in the perception of the importance of process performance measurement. This shift can be evaluated very positively, because the performance measurement process is the basis and prerequisite for continuous improvement of processes, which helps to ensure that the established BPM is dynamic and does not involve redrawing of the existing processes into process maps only.
679	The paper deals with the new CQT methodology approach to the improvement of the process control in printed circuit board (PCB) manufacturing. The CQT methodology is based on the application of the selected methods and tools. The applied methods cover two key areas. The first area contains methods for description and modelling of processes. The second area contains methods for optimizing of processes. The used tools are focused on performance measurement and optimizing of process (optimizing of cost, process time and quality). This methodology supports process control towards quality improvement, cost and processes time reduction. The paper shows main features of the CQT methodology on the practical example of the PCB manufacturing.
680	nan
681	Business organizations have become heavily dependent on information technology (IT) services. The process of alignment is defined as the mutual synchronization of business goals and IT services. However, achieving mature alignment between business and IT is difficult due to the rapid changes in the business and IT environments. This article provides a systematic review of studies on the alignment of business and IT. The research articles reviewed are based on topics of alignment, the definition of alignment, history, alignment challenges, phases of alignment, alignment measurement approaches, the importance of alignment in business industries, how software engineering helps in better alignment, and the role of the business environment in aligning business with IT. It aims to present a thorough understanding of business-IT alignment and to provide a list of future research directions regarding alignment. To perform the systematic review, we used the guidelines developed by Kitchenham for reviewing the available research papers relevant to our topic.
682	nan
683	A business model provides a description or architecture of how a company creates, delivers, and captures value. Business model performance management refers to the continuous monitoring of performance indicators and changes in the environment to control business model performance and timely trigger business model (re-)design. The business processes of a company produce a wealth of data and information about a company's operational performance, which may be aggregated to a higher level, i.e., the tactical level of the business model. However, process data may not always be directly mappable to business models because a complex relationship exists between the two concepts. Existing studies provide little insight or guidance on how business model performance indicators can be defined and monitored. To address this knowledge gap, we will employ a design science research approach to develop a method for the definition and monitoring of business model performance indicators. This research aims to contribute to BPM research by exploring the relationship between business models and business processes. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
684	Abstract Organizations continuously adapt and innovate their business models to remain competitive. To support the management of business models throughout their lifecycle, Key Performance Indicators (KPIs) related to business models play an important role. However, the current research on business model KPIs is dispersed and lacks clarity on how they are defined, concretized, and managed throughout their lifecycle. Therefore, we conducted a systematic literature review to analyze and consolidate the current state of the research on KPIs for business models. We identified 35 relevant publications and classified them in a concept matrix consisting of five categories related to business models and KPI management. In addition, we synthesized the business model KPIs referred to in the literature into a catalog structured by business model dimensions. Based on our review and analysis, we formulate avenues for further research on KPIs for business models. Practitioners can use the overview of available approaches for business model KPI management and the catalog of business model KPIs to effectively manage and define KPIs for their organization’s business models.
685	Service-Oriented Architecture (SOA) constitutes a modern, standards-based and technology-independent paradigm and architectural style for distributed enterprise computing. The SOA style promotes the publishing, discovery, and binding of loosely-coupled, network-accessible software services. With SOA systems operating in distributed and heterogeneous execution environments, the engineers of such systems are confined by the limits of traditional software engineering. In this position paper, we scrutinize the fundamental tenets underpinning the development and maintenance of SOA systems. In particular, we introduce software service engineering as an emerging discipline that entails a departure from traditional software engineering disciplines, embracing the ‘open world assumption’. We characterize software service engineering via seven defining tenets. Lastly, we survey related research challenges.
686	Over the last decade, process mining emerged as a new research field that focuses on the analysis of processes using event data. Classical data mining techniques such as classification, clustering, regression, association rule learning, and sequence/episode mining do not focus on business process models and are often only used to analyze a specific step in the overall process. Process mining focuses on end-to-end processes and is possible because of the growing availability of event data and new process discovery and conformance checking techniques.Process models are used for analysis (e.g., simulation and verification) and enactment by BPM/WFM systems. Previously, process models were typically made by hand without using event data. However, activities executed by people, machines, and software leave trails in so-called event logs. Process mining techniques use such logs to discover, analyze, and improve business processes.Recently, the Task Force on Process Mining released the Process Mining Manifesto. This manifesto is supported by 53 organizations and 77 process mining experts contributed to it. The active involvement of end-users, tool vendors, consultants, analysts, and researchers illustrates the growing significance of process mining as a bridge between data mining and business process modeling. The practical relevance of process mining and the interesting scientific challenges make process mining one of the “hot” topics in Business Process Management (BPM). This article introduces process mining as a new research field and summarizes the guiding principles and challenges described in the manifesto.
687	nan
688	A framework for business process management facilitates the implementation, management and improvement of process-based organisations. In order to do so, organisations require new capabilities such as change roadmaps, knowledge management and balanced performance measures. © 1998 Elsevier Science Ltd. All rights reserved.
689	Ensuring reliable and timely customer deliveries is crucial to supply chain management. The ability to meet delivery commitments is essential for maintaining customer satisfaction. Despite the importance of delivery commitments, there is a lack of standard measurement techniques for evaluating their quality. Therefore, this paper introduces the term Commitment Measurement (CQ) and develops a CQ matrix that can be used to measure the quality of delivery commitments. The CQ matrix provides a comprehensive set of quantitative measures to evaluate different aspects of delivery commitments. Finally, a numerical example based on an order data sample from a semiconductor manufacturer is presented and discussed. The proposed framework aims to standardize the CQ, enhancing transparency in delivery commitments.
690	nan
691	nan
692	Process mining allows the discovery, monitoring, and improvement of processes through records of their executions. When used for discovery, models depicting the process behavior can be obtained and then analyzed through a performance perspective, focusing on performance indicators for the dimension of interest. In process mining, there has been scarce research on the analysis of some dimensions, such as the cost dimension. A systematic literature review has been conducted to identify the methods used for analyzing the cost dimension in process mining and other process-oriented disciplines, the dimensions considered jointly with costs, and how such a joint analysis is carried out. The review identified 68 publications. The results indicate ample research within distinct disciplines, like business process management and cost management, regarding the costs of performing processes, their reporting and forecasting. However, there is a need to further enrich their visualization and analysis, and to provide cost-aware operational support. Moreover, the utility of further researching cost analysis jointly with other dimensions, like time, flexibility, and quality, is also observed. These results provide a structured focal point of research that can be considered when analyzing costs from a process perspective and the identification of research gaps within this domain. © 2013 IEEE.
693	The Devil’s Quadrangle is a framework used in Business Process Management to describe the inherent process performance trade-offs regarding the time, costs, flexibility, and quality dimensions. In practice, improving a process through one of these dimensions might have a negative effect on the performance of the other dimensions. The dimensions considered by the Devil’s Quadrangle are often used for defining indicators that illustrate the overall performance of processes. From a Process Mining perspective, analyzing these dimensions at higher granularity levels, such as for every process instance, is of interest. To achieve this, this work proposes a method for defining Process Mining filters based on metrics related to performance indicators of the four Devil’s Quadrangle dimensions. The metrics are calculated for every process instance, which allows using the filters to observe differences in process behavior while considering constraints to the performance indicators and trade-offs among the four dimensions. It is expected that this visualization will be helpful during exploratory process analysis. It will facilitate the identification of process instances that conform to the filters applied to the performance indicators, as well as the dimensions where improvement is required while considering process instances that do not conform to the applied filters. A Celonis dashboard with the proposed filters has been generated to validate the method. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.
694	Knowledge-intensive processes (KiPs) cannot be fully specified at design time because not all information about the process is available prior to its execution. At runtime, new information emerges reflecting environment changes or unexpected outcomes. The structure of this kind of processes varies from case to case and it is defined step-by-step based on knowledge worker's decisions made after analyzing the current situation. These decisions rely on the knowledge worker's experience and available information. Current process management approaches still need to adequately address the complex characteristics of knowledge-intensive processes, such as their unpredictability, emergency, non-repeatability, and dynamism. This paper proposes a metamodel for representing KiPs aiming to help knowledge workers during the decision-making process. Domain and organizational knowledge are modeled by objectives and tactics. The metamodel supports the definition of objectives, metrics, tactics, goals and strategies at runtime according to a specific situation. Also, it includes concepts related to context and environment elements, business artifacts, roles and rules. The feasibility of our model was evaluated via a proof of concept in the medical domain.
695	Predictive business process monitoring methods exploit historical process execution logs to generate predictions about running instances (called cases) of a business process, such as the prediction of the outcome, next activity, or remaining cycle time of a given process case. These insights could be used to support operational managers in taking remedial actions as business processes unfold, e.g., shifting resources from one case onto another to ensure the latter is completed on time. A number of methods to tackle the remaining cycle time prediction problem have been proposed in the literature. However, due to differences in their experimental setup, choice of datasets, evaluation measures, and baselines, the relative merits of each method remain unclear. This article presents a systematic literature review and taxonomy of methods for remaining time prediction in the context of business processes, as well as a cross-benchmark comparison of 16 such methods based on 17 real-life datasets originating from different industry domains.
696	This article presents the results of a survey that ranked university entrepreneurship programs. The survey also explored how universities determined what courses constituted a program in entrepreneurship and how they determined the criteria that impact an entrepreneurship program's quality. We conclude the article with a discussion of the education pilot criteria for the Malcolm Baldrige National Quality Award that may be useful for measuring progress in entrepreneurship education. A mail survey was undertaken in late 1994. This survey was sent to deans at 941 business schools in the United States, 42 in Canada, and 270 overseas. Of the 311 replies, 233 came from U.S. business schools, 16 from Canadian schools, and 62 from schools in other countries. The top seven criteria suggested for ranking entrepreneurship programs were courses offered, faculty publications, impact on community, alumni exploits, innovations, alumni start-ups, and outreach to scholars. The most frequently offered entrepreneurship courses at both the undergraduate and graduate levels in the entrepreneurship programs surveyed were entrepreneurship or starting new firms, small business management, field projects/venture consulting, starting and running a firm, venture plan writing, and venture finance. The survey uncovered a number of problems with how academics ranked other entrepreneurship programs. Evaluators did not specify the criteria they used to rank entrepreneurship programs. Evaluators did not offer their specific weights for each criterion used to judge a program. Finally, evaluators were not asked to provide a judgment of their depth of knowledge of other programs. Since the criteria for determining what constitutes a high-quality entrepreneurship program is, at present, rather fluid and indeterminate, we thought it appropriate to borrow insights from a highly successful and visible evaluation effort in higher education, the education pilot criteria for the Malcolm Baldrige National Quality Award (MBNQA). For an MBNQA evaluation, organizations are assessed across 28 requirements that are embodied in seven categories. Leadership. This category examines senior administrators' commitment and involvement in creating and sustaining performance excellence that has a student focus, clear goals, and high expectations. In the context of entrepreneurship education, the leadership category entails describing the involvement and commitment of entrepreneurship program directors, business school deans, university administrators, advisory board members, and student representatives. Information and Analysis. This category examines how data and information are used to support the overall mission of the program. The focus of this category is towards identifying and specifying information and data that would be appropriate for evaluating the quality of an entrepreneurship program, as well as for making comparisons with other programs. We suggest that entrepreneurship programs begin to systematically collect information about issues such as demographic and performance measures of incoming students enrolling in entrepreneurship courses; comparative information on entrepreneurship, business school and university students; descriptions of the outcomes that specific entrepreneurship courses intend to generate and the measures of the efficacy of each course; and measures of the intended outcomes of the entrepreneurship program in terms of student performance, student satisfaction, and impact on the community (i.e., number of start-ups, students employed in new firms, students working in positions assisting new firms). Strategic and Operational Planning. This category focuses on how a program sets strategic directions and key planning requirements. For an entrepreneurship program, such a requirement would entail generating a strategic plan that specifies the purpose and mission of the program, key student and overall program performance requirements, external factors impacting the implementation of the plan, internal resources and university barriers to change, and key critical success factors. Human Resource Development and Management. This category examines how faculty and staff are supported and developed so as to satisfy the strategic goals of the program. While an entrepreneurship program might typically measure "faculty productivity" as an indicator of this category, the intention is actually towards specifying the resources and systems that impact the ability of staff and faculty to be productive. Educational and Business Process Management. This category specifies key aspects of the design and delivery of the educational research and service components of a program, as well as an examination of the processes involved in improving these components. Rather than programs being compared to each other by the quantity of courses offered, this category requires that programs be measured on the logic, coherency, and efficacy of the educational experience that entrepreneurship students undertake. School Performance Results. This category examines the outcomes of a program, such as student performance and improvement, improvement in services provided by the program, and faculty productivity. This category accounts for 23% of the total evaluation score. The primary focus of this category is determining the improvements in student performance. Such key measures might include student performance in specific courses, student demonstrations of key skills and knowledge through portfolios of original work that they create, measures of student satisfaction, and impact on the community (i.e., number of start-ups, students employed in new firms, students working in positions assisting new firms). Student Focus, and Student and Stakeholder Satisfaction. This category describes the process for determining student and stakeholder needs and expectations, as well as making comparisons of student and stakeholder satisfaction among other programs. This category accounts for 23% of the total evaluation score. The MBNQA evaluation scheme forces us to become aware of the implicit goals, objectives, and pedagogical perspectives of our programs. We must not lose sight of the fact that entrepreneurship programs are and will be evaluated, and that we must, therefore, be ready to offer criteria that we want our programs to be evaluated on. If university entrepreneurship educators do not step forward to assume leadership of our own field, others will surely come to the forefront to determine the rules of the game. © 1997 Elsevier Science Inc.
697	Abstract Process mining is a family of analytical techniques that extract insights from an event log and present them to an analyst. A key analysis task is to understand the distinctive features of different variants of the process and their impact on process performance. Techniques for log-delta analysis (or variant analysis) put a strong emphasis on automatically extracting explanations for differences between variants. A weakness of them is, however, their limited support for interactively exploring the dividing line between typical and atypical behavior. In this paper, we address this research gap by developing and evaluating an interactive technique for log-delta analysis, which we call InterLog . This technique is developed based on the idea that the analyst can interactively define filter ranges and that these filters are used to partition the log L into sub-logs \L_1\ L 1 for the selected cases and \L_2\ L 2 for the deselected cases. In this way, the analyst can step-by-step explore the log and manually separate the typical behavior from the atypical. We prototypically implement InterLog and demonstrate its application for a real-world event log. Furthermore, we evaluate it in a preliminary design study with process mining experts for usefulness and ease of use.
698	nan
699	Business Process Management (BPM) is an accepted discipline and its importance in increasing automation inside industrial environment is today recognized by all players. The complexity of modern management process will lead to chaos without a well-designed and effective BPM. Several BPM Suites were compared and BPM approach was applied to the case study of process management in a renewable energy power plant. Results both in process reduction and simplification and flow optimization obtained in the real case are discussed to state efficacy and efficiency of the adopted approach.
700	Organizations often face difficulty in the evaluation and prioritization of their business processes. Many performance measurement indicators are defined at the aggregate and not at the process level. Surabaya City Office for Population Administration & Civil Registration (COP ACR) is a local government agency which face these challenges. This paper attempts to solve COP ACR challenges by applying BPM approach. First, process performance measurement guideline is developed. Next, the business process selection stage is carried out. The last stage is composing performance measurement indicators. From the business process selection stage, the priorities for process improvement initiatives are application processes for Birth Certificate, Biodata Change on Family Cards with the KLAMPID Application, and (3) Indonesian Citizens Transfer Certificate of Inter-City/Regency/Province processes certificate. In addition, the development of performance measurement indicators results in 29 performance measurement indicators related to Birth Certificate business processes. © 2022 IEEE.
701	Business Intelligence and Analytics (BI&amp;A) is the process of extracting and predicting business-critical insights from raw data. Traditional BI focused on data collection, extraction, and organization to enable efficient query processing to derive insights from historical data. With sources of data sources growing steadily, traditional BI&amp;A are evolving to provide intelligence at different scales and perspectives: operational BI, situational BI, self-service BI. In this survey, we review the evolution of business intelligence systems from traditional settings. We focus on the changes in the back-end architecture that deals with the collection and organization of the data, as well as, the front-end applications, where analytics services and visualization are the core components. The survey provides a holistic view of Business Intelligence and Analytics for anyone interested to get a complete picture of the different pieces in the emerging next generation BI&amp;A solutions.
702	Service-oriented architectures offer promising means to flexibly organize business processes. At the same time, new challenges for management arise in order to realize these potentials. Given the technological opportunities, these challenges essentially lie in choosing the right mix of services on the basis of an appropriate infrastructure supporting value adding activities. In order to support this management perspective, a focus on service-oriented business processes is suggested in this article. Hence, a shift from technical aspects of designing service-oriented information systems to economic aspects of using them according to business needs is drawn. For this purpose, findings on the evaluation of financial performance of service-oriented business processes are presented in this paper. The objective is to develop a measurement system for decision support on the configuration of a company's service portfolio reflecting specific economic conditions relevant in a certain situation. Following a design science approach, general principles of a measurement system are worked out and structured in a comprehensive framework. Then, the application of a corresponding system is presented with a practical study. Finally, perspectives on the specification and implementation of the system are sketched. Copyright © 2007, Idea Group Inc.
703	The aim of this workshop was to further the discussion of the role of BPM for the sustainable development of organizations. Our intention was to provide thought leaders with a forum where they can contribute to defining and shaping this emergent, and arguably highly relevant, research domain. The workshop attracted 11 submissions of which 6 papers were selected for presentation after a highly competitive review process. Two out of the six papers tackle sustainability from a BPM perspective at a rather general level: Constantin Houy, Markus Reiter, Peter Fettke, and Peter Loos focus on the ecological dimension and discuss how BPM approaches can be leveraged to support sustainability and resource efficiency of IT supported business activities. Getachew Hailemariam and Jan vom Brocke conceptualize the sustainability of BPM initiatives per se, thus focusing on the economic dimension. The other four papers that were accepted pertain to sustainability measurement. Anne Cleven, Robert Winter, and Felix Wortmann propose an approach to process performance management with particular consideration of social, ecological, and economic dimensions. Nicole Zeise, Marco Link, and Erich Ortner also consider all three dimensions when they discuss how dynamic indicators can be used in order to control all levels of enterprise architectures. Jan Recker, Michael Rosemann, and Ehsan Roohi Gohar focus on the ecologic dimension and propose an approach to measure the carbon footprint caused during the execution of a business process. Finally, Wube Alemayehu and Jan vom Brocke discuss the role of ecological and social aspects in the performance measurement of an Ethiopian airline. © 2011 Springer-Verlag.
704	Business intelligence (BI) allows companies to analyze business information in order to support successful decision making. Currently, the research on the level of BI maturity in Croatian and Slovenian companies is limited. In addition, several BI maturity models have been developed, but most of them are not comprehensive. In order to shed some light to this issue, this paper is focused on two goals: (1) to investigate the impact of BI maturity on business process performance and (2) to explore the requirements for the alignment of two concepts, BI and business process management (BPM) within the organization. Paper presents the following: (i) investigation of BI and BI systems in general, (ii) adaption of the BI maturity model (called biMM) for the purpose of this research, (iii) results of the primary research on the sample of Croatian and Slovenian companies which has been conducted as one of the activities of the project financed by the Croatian Science Foundation: IP-2014-09-3729 Process and Business Intelligence for Business Excellence, (iv) level of BI maturity and the role of BI and business process alignment for the impact of BI maturity on business process performance in investigated companies.
705	Background: Social business process management is an integration of social software into the business process management (BPM). Its main goal is to overcome the limitations of classical BPM by applying social software principles within the BPM lifecycle. Since BPM is a holistic discipline it is important to also include cultural and social aspects into BPM studies. Objectives: The main aim of this paper is to examine the link between organizational culture, social software usage and BPM maturity in the observed company. Methods/Approach: A case study methodology has been used for this study. An interview has been conducted in combination with a survey approach. Results: Results of the research revealed a high usage of social BPM within the observed company in combination with a high level of BPM maturity and a clan organizational culture. Conclusions: The observed IT company has knowledge intensive processes and uses social BPM to deal with the process change and optimization. The clan culture is, by its characteristics, a favourable organizational culture for social BPM.
706	In simulation engineering, a system model mainly consists of an information model and a process model. In the fields of Information Systems and Software Engineering (IS/SE) there are widely used standards such as the Class Diagrams of the Unified Modeling Language (UML) for making information models, and the Business Process Modeling Notation (BPMN) for making process models. This tutorial presents a general approach how to use UML class diagrams and BPMN process diagrams at all three levels of model-driven simulation engineering: for making conceptual simulation models, for making platform-independent simulation design models, and for making platform-specific, executable simulation models. In our approach, object and event types are modeled as stereotyped classes and random variables are modeled as stereotyped operations constrained to comply with a specific probability distribution, while event rules/routines are modeled both as BPMN patterns and in pseudo-code.
707	Traditionally, Performance Management (PM) is considered one of the core functions of management accounting, focused on the results of business units and primarily based on financial measures. However, with the growing emphasis on process orientation and the implementation of Business Process Management (BPM), traditional PM needs to be adapted to measure what is managed, i. e. business processes. To achieve this, process-oriented organizations rely on a Process Performance Measurement System (PPMS), with Process Mining as the state-of-the-art tool for monitoring and improving processes. In theory, the Process Mining-supported PPMS should be well integrated into the PM System (PMS), and process performance should be measured holistically, i.e. by both quantitative and qualitative figures. However, in practice it remains unclear whether these criteria are being met and whether management accounting is involved in the utilization of Process Mining and the development of a holistic PPMS. To address this research gap, a multiple case study within the German energy industry was conducted. Drawing on data from 33 semi-structured interviews, this paper presents a five-stage maturity model for the implementation of a holistic, Process Mining-supported PPMS and examines how management accounting can promote progression along this path. Due to its interdisciplinary nature, this study further contributes to research by demonstrating that the involvement of management accounting is not only beneficial to the success of Process Mining and BPM, but also crucial to the management accounting profession itself. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
708	The theoretical basis and implementation solution of business process simulation and analysis system (BPSAS) is put forward in this paper. With workflow technology, Petri net theory and simulation technology, the workflow engine independent business process analyzing system is realized to provide Petri net based business process analysis. Further more, an example is illustrated to demonstrate how to analyze business process in order to select optimized model. And at the same time, as a business process analyzing tool, it supports the specified BPM (business process management) process.
709	nan
710	nan
711	This paper describes the port BI system combined with BPM, which enables port enterprises to perform an in depth data analysis to support decision making and to promote performance management. Based on illustrations of the BPM strategies of port enterprises, the BI system architecture is proposed, and some key points in the knowledge discovery process of the BI system are discussed, which are all aligned with existing port BPM strategies.
712	Business Process Management is a contemporary approach with the main purpose of deploying, executing and continuously optimizing the different types of business processes and thus improving the agility of the organization. In this paper, we propose an approach to business process improvement based on key performance indicators during the Business Process Management lifecycle. We started by highlighting the life cycle of key performance indicators. Then our proposal was at meta-modeling level, adding performance indicators as concepts of the Business Process Model and Notation meta-model. This brought us to a new extension of this meta-model based on key performance indicators. The particular case of the Scrum agile development process is then considered as a case study. In this context, key performance indicators are proposed for this process and are classified according to the elements of the Scrum method. The proposed approach was tested by taking the example of a company using ScrumWise tool for conducting scrum developments. The developed prototype allowed a performance evaluation of the Scrum process through key performance indicators and a set of recommendations were proposed to help managing tasks and improving the adopted process. © 2019 The Authors. Published by Elsevier B.V.
713	In recent years, there has been a growing need for active systems that can react automatically to events. Some events are generated externally and deliver data across distributed systems, while others are materialized by the active system itself. Event materialization is hampered by uncertainty that may be attributed to unreliable data sources and networks, or the inability to determine with certainty whether an event has actually occurred. Two main obstacles exist when designing a solution to the problem of event materialization with uncertainty. First, event materialization should be performed efficiently, at times under a heavy load of incoming events from various sources. The second challenge involves the generation of a correct probability space, given uncertain events. We present a solution to both problems by introducing an efficient mechanism for event materialization under uncertainty. A model for representing materialized events is presented and two algorithms for correctly specifying the probability space of an event history are given. The first provides an accurate, albeit expensive method based on the construction of a Bayesian network. The second is a Monte Carlo sampling algorithm that heuristically assesses materialized event probabilities. We experimented with both the Bayesian network and the sampling algorithms, showing the latter to be scalable under an increasing rate of explicit event delivery and an increasing number of uncertain rules (while the former is not). Finally, our sampling algorithm accurately and efficiently estimates the probability space.
714	nan
715	nan
716	Predictive business process monitoring (PBPM) techniques predict future process behaviour based on historical event log data to improve operational business processes. Concerning the next activity prediction, recent PBPM techniques use state-of-the-art deep neural networks (DNNs) to learn predictive models for producing more accurate predictions in running process instances. Even though organisations measure process performance by key performance indicators (KPIs), the DNN’s learning procedure is not directly affected by them. Therefore, the resulting next most likely activity predictions can be less beneficial in practice. Prescriptive business process monitoring (PrBPM) approaches assess predictions regarding their impact on the process performance (typically measured by KPIs) to prevent undesired process activities by raising alarms or recommending actions. However, none of these approaches recommends actual process activities as actions that are optimised according to a given KPI. We present a PrBPM technique that transforms the next most likely activities into the next best actions regarding a given KPI. Thereby, our technique uses business process simulation to ensure the control-flow conformance of the recommended actions. Based on our evaluation with two real-life event logs, we show that our technique’s next best actions can outperform next activity predictions regarding the optimisation of a KPI and the distance from the actual process instances. © Springer Nature Switzerland AG 2020.
717	Predictive business process monitoring (PBPM) deals with predicting a process's future behavior based on historical event logs to support a process's execution. Many of the recent techniques utilize a machine-learned model to predict which event type is the next most likely. Beyond PBPM, prescriptive BPM aims at finding optimal actions based on considering relevant key performance indicators. Existing techniques are geared towards the outcome prediction and deal with alarms for interventions or interventions that do not represent process events. In this paper, we argue that the next event prediction is insufficient for practitioners. Accordingly, this research-in-progress paper proposes a technique for determining next best actions that represent process events. We conducted an intermediate evaluation to test the usefulness and the quality of our technique compared to the most frequently cited technique for predicting next events. The results show a higher usefulness for process participants than a next most likely event. © Proceedings of the 15th International Conference on Business Information Systems 2020 "Developments, Opportunities and Challenges of Digitization", WIRTSCHAFTSINFORMATIK 2020.
718	In this report, we share our experience in developing a complex event processing architecture that bridges sensors networks to an energy management system used in the context of chain convenient stores. We analyze event data in real-time to generate immediate and predictive appliance/operation insights and enable instant response defined by simple business rules. For intuitive rule management, preprocessed events should be used in many cases instead of raw events collected from sensor network. We illustrate practical energy and operation management rules based on preprocessed events such as forecasted and classified events in addition to raw events.
719	nan
720	It is increasingly important that Service Level Agreements (SLAs) are taken into account when business processes are exposed as services in a Service Oriented Architecture. SLAs define expected service behavior and nonfunctional properties of the service. The fact that the service provider has to offer certain guarantees concerning SLA properties has an impact on the business process lifecycle. In this paper we introduce a stepwise approach for management of SLA-aware service compositions based on process performance requirements specified as Key Performance Indicators. The approach is based on the process lifecycle known from Business Process Management and comprises a modeling, configuration and execution phase. We incorporate existing work on SLA modeling, QoS aggregation, and QoS-based service selection, and identify several problems specific to SLA-aware business processes.
721	Business Activity Monitoring (BAM) enables continuous, real-time performance measurement of business processes based on key performance indicators (KPI). The performance information is employed by business users but prior support from IT engineers is required for setting up the BAM solution. Semantic Business Process Management (SBPM) tries to minimize the needed support from IT staff throughout the business process lifecycle. In this paper we introduce a framework for BAM as part of SBPM. We show how performance measurement related activities can be integrated into the semantic business process lifecycle. KPIs are modeled by business analysts exploiting semantic annotations of business processes. KPI models are automatically transformed to IT-level event-based models and used for real-time monitoring using reasoning technology. © 2008 Springer Berlin Heidelberg.
722	Business process monitoring in the area of service oriented computing is typically performed using business activity monitoring technology in an intra-organizational setting. Due to outsourcing and the increasing need for companies to work together to meet their joint customer demands, there is a need for monitoring of business processes across organizational boundaries. Thereby, partners in a choreography have to exchange monitoring data, in order to enable process tracking and evaluation of process metrics. In this paper, we describe an event-based monitoring approach based on BPEL4Chor service choreography descriptions. We show how to define monitoring agreements specifying events each partner in the choreography has to provide. We distinguish between resource events and complex events for calculation of process metrics using complex event processing technology. We present our implementation and evaluate the concepts based on a scenario.
723	Business activity monitoring enables continuous observation of key performance indicators (KPIs). However, if things go wrong, a deeper analysis of process performance becomes necessary. Business analysts want to learn about the factors that influence the performance of business processes and most often contribute to the violation of KPI target values, and how they relate to each other. We provide a framework for performance monitoring and analysis of WS-BPEL processes, which consolidates process events and Quality of Service measurements. The framework uses machine learning techniques in order to construct tree structures, which represent the dependencies of a KPI on process and QoS metrics. These dependency trees allow business analysts to analyze how the process KPIs depend on lower-level process metrics and QoS characterisitics of the IT infrastructure. Deeper knowledge about the structure of dependencies can be gained by drill-down analysis of single factors of influence.
724	Within the Business Process Improvement Program initiated at Placer Dome during 2003 was the Business Performance Management Project (BPM). BPM's aim has been to extract productivity improvements from individual business units by providing a model for implementing leading practice based management process within the Placer Dome Group, sharing management best practice, injecting new management techniques and instilling a continuous improvement culture. The installation of an underground dispatch system has been a key component of the BPM project at Osborne Mine. Information capture and analysis allows for corrective action to be planned and executed before there is a material impact on the performance of a business unit. This paper briefly describes the principles and practices of effective business performance management, the four processes of a management operating system namely; strategic and tactical planning, implementation and reporting. The identification of business drivers, their measures and associated key performance indicators is discussed. The benefits of an underground dispatch system, at Osborne with respect to safety, production and maintenance is described along with the installation process within the mining department that included its configuration, resourcing and roll out.
725	The Body &amp; Chassis Engineering Department of Ford Motor Company recently formulated plans for greatly increasing (from 155 to 476) the number of Fortune engineering-workstation computers. This increase represents a vital step in the implementation of an office automation system. Systems-analysis personnel of the Department used discrete simulation as a tool to quantify the impact of this increase on the workload of technical support personnel. In turn, Department management used the results of these simulations to formulate a hiring plan consistent with the planned rate of terminal acquisition.
726	In the emerald factory business, the crafting process plays a crucial role in driving the quality of products. However, such a process has limitations and difficulties in monitoring the working progress, determining the factory hours to complete the products, reporting the completed tasks, and reporting the defects. This causes cost and time inefficiency in managing this business. To reach this aim, this study, therefore, addresses such issues by employing business process management strategy to help analyze and redesign the existing crafting process for better performance, where the information system was developed to help improve the certain tasks. Hence, the swimlane diagram was used to visualize the business tasks and flows; moreover, the information system was developed and implemented for employees and managers accordingly. The overall structure and screenshots of the proposed system were presented in the paper. After being deployed on the cloud server, the system was used for weeks and evaluated by the users. The results show that both group of users highly accepted the system, while the managers had a significantly better attitude in analyzing and managing the emerald crafting process. Finally, the findings of this study shed light of the implications of understanding and redesigning the business process with the benefits of the information system to enhance business success.
727	With the continuous changes in the economic environment and the intensification of market competition, the accuracy of accounting budget forecasts has become increasingly important for corporate strategic planning and decision-making. Traditional forecasting methods often rely on historical data and linear models, but these methods may not provide sufficient accuracy and flexibility when facing complex and dynamic market environments. In recent years, adaptive algorithms have received widespread attention due to their advantages in dealing with complex systems and dynamic environments. This article explores the application of adaptive algorithms in accounting budget forecasting and verifies its effectiveness through empirical analysis. We use the financial statement data of 1,000 different listed companies in the "GlobalFinance" database over the past ten years, use adaptive algorithms to make predictions, and compare them with traditional prediction methods. The results show that the adaptive algorithm outperforms the traditional method in multiple performance indicators, showing its great potential in accounting budget forecasting. This article not only provides strong empirical support for the application of adaptive algorithms in the field of financial forecasting, but also provides theoretical basis and practical guidance for enterprises to adopt this advanced technology in actual operations.
728	In today's fast-paced business environment, we see an ongoing trend towards the need for analytics on the latest operational data. The data management layer of enterprise applications needs to adapt to this requirement and In-Memory Column Stores have been proposed as a new architecture that can handle such mixed workload scenarios. A thorough understanding of the resulting query workload is required to validate and optimize data management concepts for this new challenge. Consequently, this paper introduces Database Application Context (DAC) analysis—an holistic framework to analyze database workloads, data characteristics as well as access patterns on specific domain types. We present results for a productive enterprise resource planning system, as well as widely accepted database benchmarks for transactional and mixed workloads. In contrast to existing work, we have analyzed correlations between issued queries and the domain types of accessed attributes. Our main findings are (i) that enterprise workloads are read heavy, (ii) that specific database operators predominantly operate on attributes with a specific domain type, and (iii) that data characteristics differ depending on the data type. Furthermore, based on our analysis of trends in modern enterprise applications, we expect workloads with an increased runtime share of complex queries in the future. These findings help in designing and optimizing the data management layer of modern enterprise applications.
729	The Linac Coherent Light Source II (LCLS-II) is a free electron laser (FEL) light source. LCLS II will produce 0.5 to 77 Angstroms soft and hard x-rays [1]. In order to achieve this high level of performance, the beam position measurement system needs to be accurate so the electron beam can be stable. The LCLS-II stripline Beam Position Monitor (BPM) system has a dynamic range of 10pC to 1nC bunch charge. The system has a resolution requirement of 5μm [2]. The BPM system uses the MicroTCA (Micro Telecommunication Computing Architecture) physics platform that consists of an analog front-end (AFE) and a 16-bit analog to digital converter (ADC) module. This paper will discuss the hardware design, architecture, and performance measurements of this system using the SLAC LINAC. The hardware architecture includes a bandpass filter at 300MHz with 15 MHz bandwidth, and an automated BPM calibration process. Copyright © 2013 by JACoW.
730	nan
731	Process-aware information systems are valuable for automating business tasks leading to cost reduction and efficiency. This research aims to advance the state of the art in process management towards autonomic process performance improvement by contributing control-flow change recommendations for process instances that is supporting automatic change enactment as a response to predicted KPI violations. Towards that goal, the related literature has been investigated in two literature review studies and research gaps have been identified. The proposed generic architecture provides a feedback loop that enables evaluation of the resulting recommendations for future process instances. We also present the current state of the research and future plans. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
732	A Social Business Process (SBP) is the result of blending social computing (a.k.a. Web 2.0) with business process (BP). Despite the benefits of SBP to enterprises, several limitations continue to undermine them. In this paper, we address two specific limitations, namely the difficulty of capturing SBP's requirements and the lack of a definition for SBP. Thus, meta-modeling is used to capture requirements from organizational, technological, and management perspectives. In addition, we introduce a definition for SBP by enriching an existing BP meta-model with social concepts. To annotate the SBP model with its requirements, a BPMN extension is proposed. The proposed meta-models are evaluated in terms of completeness and clarity using the Bunge-Wand-Weber ontology.
733	nan
734	This article explores an increasingly important theme for all business sectors: sustainability and its linkage to business performance management, and proposes an operational framework based on the Balanced Scorecard model. Enterprise sustainability is a subject that is extensively being assessed and measured in various industries nowadays. We focus on Chilean SMEs and explore how a sustainability trend led by technology-related innovation and performance measurement systems can enable and allow to maintain sustainable enterprises through the today's volatile, uncertain and complex socio political and economic scenario. Worldwide, issues such as sustainability, innovation and social responsibility are driving business performance management (BPM) of thriving companies, many of which champion for greater social equity, business sustainability and fairness. This process entails a paradigm shift that is particularly noticeable in small and medium size enterprises or SMEs―the largest segment of Latin America's businesses, and especially so in Chile, a country which, according to OECD 2022's Table 8.2. Distribution of firms in Chile, 2018, SMEs account for over 90% of the enterprises in the country. © 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0) Peer-review under responsibility of the scientific committee of the Tenth International Conference on Information Technology and Quantitative Management.
735	In this paper, we propose an ontology-based approach for integrating clinical pathways into Clinical Decision Support Systems (CDSS) recognizing that flexible pathways are critical for the success of CDSS. Our approach is based on a better understanding of clinical context through ontologies, and bringing them to bear in deciding the right rules for a certain activity. We also describe an approach for integrating and instantiating context specific subprocess fragment into a clinical pathway on the fly based on the needs of a specific case. To illustrate the feasibility of our approach, we present a system architecture and prototype implementation, along with a case study for handling patients with heart disease. The role of semantic web technologies in integrating clinical pathways into CDSS is highlighted.
736	RTE is a new management paradigm on which core processes are executed and managed with the latest information. This concept is a needful concept to continuously strengthen corporate competitiveness in an era of unbridled competition with the collapse of traditional value chain and accelerated flow of information. Paradigm of AI (Artificial Intelligence), which is based on the assumption that existing business processing types or expertise in a predefined and limited management environment can help to make a right decision in the new future environment, and expert system should overcome rule based and model based limitations. In RTE, rather than existing business types or expertise, it is important to monitor the event or information at the present point of time that can provide support in the current situation.In this research, a model that integrates KM (Knowledge Management), BI (Business Intelligence) with business process is presented, which are essential for decision making in a real-time based corporate environment. Furthermore, in a dynamic management environment of real world, a decision making support model that can overcome three limitations that are posed by AI, Expert system paradigm shall be presented in this research.
737	Predictive Business Process Monitoring (BPPM) is an increasingly used technique to anticipate future events within organizations, based on the analysis of historical and real-time data. This article explores the application of a cumulative fact table model in a data warehouse to improve the accuracy and speed of predictions within the context of BPPM. Through a case study in the logistics sector, the proposed model significantly reduced the error rate in delivery time predictions and enabled faster anomaly detection compared to traditional methods. This approach has proven particularly effective for real-time monitoring of business processes, while also highlighting the need for a robust data infrastructure for its implementation.
738	In this paper we propose the performance evaluation based Information Control Nets (p-ICN) to achieve the full compliance with the international organization UN recommendation to get the performance evaluation all over the e-Government projects due to its nature of huge scale and long term project plan of IT investment. However, current real world there is not enough suitable and tangible method for decision makers to make sure rationality of such a huge IT investment. Thus, we studied and defined new method so called as the p-ICN to provide them suitable capability to evaluate the performance of any Enterprise Architectures. Moreover, proved its effectiveness to achieve a solution of the defined problem with well-known applied enterprise architecture as simple as possible.
739	Many companies are reporting astronomical increases in event activities in enterprise IT systems worldwide. IBM reports that 72 quadrillion unique business events are generated worldwide each day. Although it is still a daunting task to design and develop systems that are capable of handling this amount of events, this trend constitutes an opportunity to drive the study of efficient, fast, and reliable BPM solutions that give rise to the processing of events at that scale. Gartner's recent report projects that market for business intelligence (BI) and business activity monitoring (BAM) will have a compound annual growth rate of 7 to 8% by 2012, and that platforms for enriched event management and processing will be in high demand.
740	Abstract Nowadays, accounting departments highly rely on accounting information systems to make decisions based on current, updated, and contemporary data. And, most accounting practices can be enhanced by emerging technologies coupled with accounting information systems. Therefore, contemporary accounting information systems (AIS) coupled with emerging technologies is the highest priority in organizations to make decisions that can contribute to strategic flexibility and performance of the organizations. The objective of the study is to identify the role of information systems infrastructure integration (ISII) on strategic flexibility and innovation (SFI) through the mediated role of information systems (IS)-enabled strategic enterprise management (IS-SEM) practices and decision-making performance (DMP). The study is based on contemporary literature in the field of emerging technologies in accounting information systems particularly business intelligence and analytics (BI &A). Resource-based view had been applied to create novel constructs to test the research framework and hypothesis. The research framework and hypothesis are tested based on 388 organizations from Brazil and USA. The results reflect that information systems infrastructure integration impacts strategic flexibility and innovations in organizations. Further, there is no difference observed between North American and South American organizations. The results of the research suggest that accounting information systems (AIS) practitioners and researchers should look beyond emerging technologies investments and shift their attention to how information systems infrastructure integration (ISII) and information systems-enabled strategic enterprise management (IS-SEM) practices can leverage decision-making performance (DMP) and impact on strategic flexibility and innovation.
741	nan
742	Businesses today recognize the importance of business performance management (BPM) as an effective business strategy and practical solution to a robust supply chain management process. At the same time, businesses seek to deepen their footprints in global markets, to actively use critical metrics, KPIs (Key Performance Indicators), in business performance management, to make performance management compatible with strategic goals, up-to-date and sustainable. KPIs are priority indicators determined to achieve the strategic objectives of the enterprise. Updating the KPIs used to measure, monitor and analyze business performance also has a critical place in performance management. This article presents a case study of a novel approach to real-time updating and monitoring KPIs integrated into supply chain management (SCM) software. The proposed approach bridges the gap between measuring and implementing business performance. The study analyzes and aligns the relationships of duplicate KPIs. It systematically carries out the KPI weights of the managers in line with the strategic goals and improves performance management by eliminating the weakness in the KPI change. It also provides a framework for sustainable performance management and discusses the case study with implications of KPIs that affect performance management success.  © 2013 IEEE.
743	nan
744	Abstract Performance modeling of hospitals using data envelopment analysis (DEA) has received steadily increasing attention in the literature. As part of the traditional DEA framework, hospitals are generally assumed to be functionally similar and therefore homogenous. Accordingly, any identified inefficiency is supposedly due to the inefficient use of inputs to produce outputs. However, the disparities in DEA efficiency scores may be a result of the inherent heterogeneity of hospitals. Additionally, traditional DEA models lack predictive capabilities despite having been frequently used as a benchmarking tool in the literature. To address these concerns, this study proposes a framework for analyzing hospital performance by combining two complementary modeling approaches. Specifically, we employ a self-organizing map artificial neural network (SOM-ANN) to conduct a cluster analysis and a multilayer perceptron ANN (MLP-ANN) to perform a heterogeneity analysis and a best practice analysis. The applicability of the integrated framework is empirically shown by an implementation to a large dataset containing more than 1,100 hospitals in Germany. The framework enables a decision-maker not only to predict the best performance but also to explore whether the differences in relative efficiency scores are ascribable to the heterogeneity of hospitals.
745	Reference models play an important role in the knowledge management of the various complex collaboration domains (such as Supply Chain Networks). However, they often show a lack of semantic precision and, they are sometimes incomplete. In this paper, we present an approach to overcome semantic inconsistencies and incompleteness of the Supply Chain Operations Reference (SCOR) model and hence, improve its usefulness and expand the application domain. First, we describe a literal OWL specification of SCOR concepts (and related tools), built with intention to preserve the original approach in the classification of process reference model entities and hence, to enable effectiveness of usage in original contexts. Next, we demonstrate the system for its exploitation, in specific - tools for SCOR framework browsing and rapid supply chain process configuration. Then, we describe the SCOR-FULL ontology and its intended use. Finally, we elaborate the potential impact of the presented approach, to interoperability of systems in Supply Chain Networks.
746	Knowledge of business process analysis instruments and methods enhance the possibility to quantify process management decisions and to achieve organizations’ goals. While the amount of research on business process analysis and evaluation increases, there is a need to outline the intellectual structure of scientific research as embodied in business process scientific literature in order to define the streams of research. The purpose of this paper is to present actionable knowledge of business process performance analysis and evaluation, based on the framework, integrating business process research domains and levels of analysis. In order to establish a framework, integrating the domains of business process analysis, the research questions were formulated and the analysis of the scientific literature was carried out applying the method of structured literature review. Literature review was based on a research papers that were available through the EBSCO host, Academic search complete databases. References were searched using the keywords that are formed as combinations of words: business process, analysis, performance, evaluation. Research contributions, addressing the business process analysis topic, were selected by the keywords within the papers’ title, abstract and in the keywords specified in the article. After the initial evaluation of 677 papers, 62 articles were selected for in-depth analysis. This paper contributes to the business process management research by proposing the framework to integrate various business process analysis research streams and highlighting exploratory potential areas for future inquiry. © 2018 by author(s) and VsI Entrepreneurship and Sustainability Center.
747	Business Performance Management(BPM) is a new frontier in IT-enabled enterprise that supports the monitoring business operations. BPM solutions must be able to efficiently process business events, compute business metrics, detect business situations, and provide the real-time visibility of key performance indicators (KPIs) in dynamic environments, wherein sources of dynamicity are plentiful, including new strategies, operations, KPIs, etc. Therefore, BPM solutions need to adapt these changes by dynamic evolution. We propose a policy-driven approach, where evolution policies capture the evolution mechanism of BPM solutions. This frees solution developers from low-level programming concerns. We implemented a hybrid compilationinterpretation framework that enables execution of wide spectrums of evolution policies. Further, our framework enables execution of evolution policies in parallel with on going event processing and guarantees the integrity on both of them. © 2006 IEEE.
748	It is commonly agreed that accounts receivable (AR) can be a source of financial difficulty for firms when they are not efficiently managed and are underperforming. Experience across multiple industries shows that effective management of AR and overall financial performance of firms are positively correlated. In this paper we address the problem of reducing outstanding receivables through improvements in the collections strategy. Specifically, we demonstrate how supervised learning can be used to build models for predicting the payment outcomes of newly-created invoices, thus enabling customized collection actions tailored for each invoice or customer. Our models can predict with high accuracy if an invoice will be paid on time or not and can provide estimates of the magnitude of the delay. We illustrate our techniques in the context of real-world transaction data from multiple firms. Finally, simulation results show that our approach can reduce collection time up to a factor of four compared to a baseline that is not model-driven.
749	The service-oriented architecture (SOA) and the model-driven architecture (M DA) have been recognized as major evolutionary steps in enterprise integration (EI) in service-oriented computing environments. Service-oriented enterprise (SOE) networks (SOEN) are emerging with the significant advances of EI, SOA, and MDA. However, the implementation and optimization of SOEN is still lacking integrated SOA, MDA, and performance analysis and optimization (PAO) methods. This paper introduces an integrated solution of SOA and MDA with a simulation-based three-stage PAO method with stage 1 being an analytic hierarchy process (AHP)-based comprehensive performance calculation for service matching and binding, stage 2 being a simulation-based comprehensive performance evaluation for business process/service composition, and stage 3 being a business process simulation-based performance optimization for SOEN. The SOE architecture, performance analysis framework, performance indicators, and performance operators are discussed. The system uses MDA as the system development philosophy, SOA as the system implementation infrastructure, and the simulation-based PAO methods to analyze and optimize the SOEN performance. A case study of the SOEN illustrates the usage of the integrated solution.
750	The heterogeneous and dynamic execution context of service-based applications (SBA) makes the problem of adaptation critical. However in most cases the adaptation is not trivial due to the following facts. First, SBA has a complex layered system where the application is implemented through a composition of services, which in turn are provided by platforms and run on top of infrastructures. Second, as a result of this multi-level application system there exist several adaptation approaches isolated from each other, which focus on a specific concern of one level ignoring the overall impact of the adaptation on the whole service-based system. To tackle this problem we propose a cross-layer adaptation manager (CLAM) whose contribution is two-fold: (i) It provides a platform that integrates and coordinates existing analysis and adaptation tools, which target specific system concerns, to assess the impact of an adaptation at the different levels. (ii) Covering the whole system for the SBA, it provides an analysis algorithm that incrementally constructs consistent adaptation strategies starting from an initial adaptation trigger originated at any level. The paper introduces the proposed approach and presents its first implementation with concrete analysis and adaptation tools.
751	In spite of the recent advancement of machine learning research, modern machine learning systems are still far from easy to use, at least from the perspective of business users or even scientists without a computer science background. Recently, there is a trend toward pushing machine learning onto the cloud as a "service," a.k.a. machine learning clouds. By putting a set of machine learning primitives on the cloud, these services significantly raise the level of abstraction for machine learning. For example, with Amazon Machine Learning, users only need to upload the dataset and specify the type of task (classification or regression). The cloud will then train machine learning models without any user intervention.
752	Abstract Cloud computing has gained popularity in recent years, but with its rise comes concerns about data security. Unauthorized access and attacks on cloud-based data, applications, and infrastructure are major challenges that must be addressed. While machine learning algorithms have improved intrusion detection systems in cloud data security, they often fail to consider the entire life cycle of file processing, making it difficult to detect certain issues, especially insider attacks. To address these limitations, this paper proposes a novel approach to analyzing data file processing in multi-cloud environments using process mining. By generating a complete file processing event log from a multi-cloud environment, the proposed approach enables detection from both control flow and performance perspectives, providing a deeper understanding of the underlying file processing in its full life cycle. Through our case study, we demonstrate the power and capabilities of process mining for file security detection and showcase its ability to provide further insights into file security in multi-cloud environments.
753	Anomaly detection is assumed to be an efficient means of probing cyber-attacks upon business processes, and frequent pattern recognition (referred as interestingness) is complementary to anomaly detection for providing insights about processes. Current studies on anomalies and interestingness focus mostly on measurement design and discovery methods. However, parameterized evaluation from a time dimension has not been well-explored to satisfy personalized demands of edge users. To fill this gap, this article proposes to detect temporal anomalies and interestingness leveraging time-constrained and granularity-aware signatures. Specifically, a Timed Hierarchical Business Process Model (TH-BPM) is constructed by exploiting temporal constraints and granularities thoroughly, and composing activities from fine granularities to coarser ones. Temporal anomalies are estimated with prescribed signatures upon TH-BPM through parameterizing acceptance of deviant executions. Temporal interestingness, as the complement to temporal anomalies, is specified as the most probable execution time that is partitioned into user-defined granules and ranked by the probability leveraging the parameterized signatures. Consequently, various acceptance of anomaly deviations is allowed, and parameterized needs of interestingness detection can be satisfied. Experimental results upon real-life event logs and a real edge network demonstrate that our approach outperforms the state-of-the-art techniques in relevant performance metrics.  © 1988-2012 IEEE.
754	Predictive modeling is the art of building statistical models that forecast probabilities and trends of future events. It has broad applications in industry across different domains. Some popular examples include user intention predictions, lead scoring, churn analysis, etc. In this tutorial, we will focus on the best practice of predictive modeling in the big data era and its applications in industry, with motivating examples across a range of business tasks and relevance products. We will start with an overview of how predictive modeling helps power and drive various key business use cases. We will introduce the essential concepts and state of the art in building end-to-end predictive modeling solutions, and discuss the challenges, key technologies, and lessons learned from our practice, including case studies of LinkedIn feed relevance and a platform for email response prediction. Moreover, we will discuss some practical solutions of building predictive modeling platform to scale the modeling efforts for data scientists and analysts, along with an overview of popular tools and platforms used across the industry.
755	Achieving macroeconomic stability and sustainable economic growth in Russia is directly dependent on the efficiency of economic activities and strategic stability of individual enterprises. At the same time, the rapid development and variability of the external business environment and the conditions of severe market competition require modern progressive approaches to management and its information and analytical support, which make it possible to make high-quality strategic management decisions. Based on it, the analysis of economic activity, which is the basis for justifying economic decisions, has a strategic orientation.The task of strategic analysis of the market environment for agricultural enterprises is to provide a meaningful and formal description of the main market elements, identify their features, patterns and trends of development, and the degree of influence on the activities of the manufacturer.In our opinion, the strategic analysis of the market environment of agricultural enterprises should first of all determine the main factors that affect the development of the territorial market of food products as a whole. Despite the fact that the market of agricultural and food products in our country is characterized by very intensive development, it is still far from perfect. The purpose of this article is to specify the problem in the cancers of one enterprise and develop a strategic map of the balanced indicators system for an agricultural organization. The main task is to optimize the system of strategic analysis for agricultural enterprises.The novelty of the work is the application of balanced scorecard methods as an element of strategic analysis for managing an agricultural organization.
756	The need to create and deploy business application systems rapidly has sparked interest in using web services to compose them. When creating mission-critical business applications through web service compositions, in addition to ensuring that functional requirements are met, designers need to consider the end-to-end reliability, security, performance, and overall cost of the application. As the number of available coarse-grain business services grows, the problem of selecting appropriate services quickly becomes combinatorially explosive for realistic-sized business applications. This article develops a business-process-driven approach for composing service-oriented applications. We use a combination of weights to explore the entire QoS criteria landscape through the use of a multi-criteria genetic algorithm (GA) to identify a Pareto-optimal multidimensional frontier that permits managers to trade off conflicting objectives when selecting a set of services. We illustrate the effectiveness of the approach by applying it to a real-world drop-ship business application and compare its performance to another GA-based approach for service composition.
757	nan
